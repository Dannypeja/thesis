% !TeX document-id = {20a758e9-3325-489d-88bb-4096b1ed6a15}
% !TeX spellcheck = en-US
% !TeX encoding = utf8
% !TeX program = pdflatex
% !BIB program = biber
% -*- coding:utf-8 mod:LaTeX -*-


% vv  scroll down to line 200 for content  vv


\let\ifdeutsch\iffalse

\let\ifenglish\iftrue


\input{pre-documentclass}
\documentclass[
  %
  %ngerman, %%% Add if you write in German.
  %
  % fontsize=11pt is the standard
  a4paper,  % Standard format - only KOMAScript uses paper=a4 - https://tex.stackexchange.com/a/61044/9075
  twoside,  % we are optimizing for both screen and two-side printing. So the page numbers will jump, but the content is configured to stay in the middle (by using the geometry package)
  bibliography=totoc,
  %               idxtotoc,   %Index ins Inhaltsverzeichnis
  %               liststotoc, %List of X ins Inhaltsverzeichnis, mit liststotocnumbered werden die Abbildungsverzeichnisse nummeriert
  headsepline,
  cleardoublepage=empty,
  parskip=half,
  %               draft    % um zu sehen, wo noch nachgebessert werden muss - wichtig, da Bindungskorrektur mit drin
  draft=false
]{scrbook}
\input{config}


\usepackage[
  title={Trustworthiness of Synthetic Media in the Context of a Newscast}, % Do not forget to capitalize your title correctly, you may use the following page to help you: https://capitalizemytitle.com/
  author={Danilo Pejakovic},
  %orcid=0000-0000-0000-0000, % get your own ORCID via https://orcid.org/
  email={danilo.pejakovic@campus.lmu.de},
  type={Masterthesis},
  institute={Institute for Informatics}, % or other institute names - or just a plain string using {Demo\\Demo...}
  course={Mediainformatics},
  examiner={Prof.\ Dr.\ Sylvia Rothe, Christoph Weber},
  supervisor={Prof.\ Dr.\ Sylvia Rothe},
  startdate={October 4, 2023},
  enddate={April 4, 2024},
  % Falls keine Lizenz gewünscht wird bitte auf "none" setzen
  % Die Lizenz erlaubt es zu nichtkommerziellen Zwecken die Arbeit zu
  % vervielfältigen und Kopien zu machen. Dabei muss aber immer der Autor
  % angegeben werden. Eine kommerzielle Verwertung ist für den Autor
  % weiter möglich.
  copyright=ccbysa, % ccbysa, ccbynosa, cc0, none
  language=english
]{lmu-thesis-cover}

\input{acronyms}

\geometry{
  left=2.5cm,
  right=3.5cm,
  top=2cm,
  bottom=2cm
}

\makeindex

\begin{document}

\frontmatter
\pagenumbering{roman} % Seitennummerierung mit römischen Ziffern für den Vorspann
\setcounter{tocdepth}{2} % bis zur dritten Gliederungsebene Anzeigen



%tex4ht-Konvertierung verschönern
\iftex4ht
  % tell tex4ht to create picures also for formulas starting with '$'
  % WARNING: a tex4ht run now takes forever!
  \Configure{$}{\PicMath}{\EndPicMath}{}
  %$ % <- syntax highlighting fix for emacs
  \Css{body {text-align:justify;}}

  %conversion of .pdf to .png
  \Configure{graphics*}
  {pdf}
  {\Needs{"convert \csname Gin@base\endcsname.pdf
      \csname Gin@base\endcsname.png"}%
    \Picture[pict]{\csname Gin@base\endcsname.png}%
  }
\fi

%\VerbatimFootnotes %verbatim text in Fußnoten erlauben. Geht normalerweise nicht.

\input{commands}
%\pagenumbering{arabic}
\Coverpage
\Copyright
%Eigener Seitenstil fuer die Kurzfassung und das Inhaltsverzeichnis
\deftriplepagestyle{preamble}{}{}{}{}{}{\pagemark}
%Doku zu deftriplepagestyle: scrguide.pdf
\pagestyle{preamble}
\renewcommand*{\chapterpagestyle}{preamble}



%Kurzfassung / abstract
%auch im Stil vom Inhaltsverzeichnis

\section*{Abstract}

\todo{Short summary of the thesis. Here, the following questions should be answered:}
\todo{What is the specific problem addressed?}
\todo{What have you done?}
\todo{What did you find out?}
\todo{What are the implications on a larger scale?}
\todo{Should be around 0.5 pages. Not longer than 1 page.}

\cleardoublepage


% BEGIN: Verzeichnisse

\iftex4ht
\else
  \microtypesetup{protrusion=false}
\fi

%%%
% Literaturverzeichnis ins TOC mit aufnehmen, aber nur wenn nichts anderes mehr hilft!
% \addcontentsline{toc}{chapter}{Literaturverzeichnis}
%
% oder zB
%\addcontentsline{toc}{section}{Abkürzungsverzeichnis}
%
%%%

%Produce table of contents
%
%In case you have trouble with headings reaching into the page numbers, enable the following three lines.
%Hint by http://golatex.de/inhaltsverzeichnis-schreibt-ueber-rand-t3106.html
%
%\makeatletter
%\renewcommand{\@pnumwidth}{2em}
%\makeatother
%
\tableofcontents

% Bei einem ungünstigen Seitenumbruch im Inhaltsverzeichnis, kann dieser mit
% \addtocontents{toc}{\protect\newpage}
% an der passenden Stelle im Fließtext erzwungen werden.

\listoffigures
\listoftables


% Control List of Listings
\let\iflistings\iffalse
%Wird nur bei Verwendung von der lstlisting-Umgebung mit dem "caption"-Parameter benoetigt
%\lstlistoflistings
%ansonsten:
\iflistings
  \ifdeutsch
    \listof{Listing}{Verzeichnis der Listings}
  \else
    \listof{Listing}{List of Listings}
  \fi
\fi

% Control List of Algorithms
\let\ifalgorithms\iffalse
\ifalgorithms
  %mittels \newfloat wurde die Algorithmus-Gleitumgebung definiert.
  %Mit folgendem Befehl werden alle floats dieses Typs ausgegeben
  \ifdeutsch
    \listof{Algorithmus}{Verzeichnis der Algorithmen}
  \else
    \listof{Algorithmus}{List of Algorithms}
  \fi
  %\listofalgorithms %Ist nur für Algorithmen, die mittels \begin{algorithm} umschlossen werden, nötig
\fi

% Control Glossary
\let\ifglossary\iftrue
\ifglossary
  \printnoidxglossaries
\fi

\iftex4ht
\else
  %Optischen Randausgleich und Grauwertkorrektur wieder aktivieren
  \microtypesetup{protrusion=true}
\fi

% END: Verzeichnisse


% Headline and footline
\renewcommand*{\chapterpagestyle}{scrplain}
\pagestyle{scrheadings}
\pagestyle{scrheadings}
\ihead[]{}
\chead[]{}
\ohead[]{\headmark}
\cfoot[]{}
\ofoot[\usekomafont{pagenumber}\thepage]{\usekomafont{pagenumber}\thepage}
\ifoot[]{}


%% vv  scroll down for content  vv %%

\mainmatter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% Main content starts here
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\chapter{Introduction}
\label{chap:introduction}


%\todo{P1.1. What is the large scope of the problem?}
\begin{figure}[h]
  \centering
  \begin{subfigure}[b]{0.4\textwidth}
    \includegraphics[width=\textwidth]{./graphics/images/scheider-real.png}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.4\textwidth}
    \includegraphics[width=\textwidth]{./graphics/images/scheider-sd.png}
  \end{subfigure}
  \caption{A TV news anchor: real and synthetic adaptation}
  \label{fig:scheider-real-sd}
\end{figure}
\begin{quotation}
"Sophiscitcated AI systems are increasingly everywhere. [...] However, 2023 will likely prove to be a particularly critical moment in the history of AI" \citet{arguedasAutomatingDemocracyGenerative2023}.
\end{quotation}
This paper and corresponding study are being conducted in the very year 2023. As the previously quoted authors state, we might be experiencing a tippping point in AI development, as more and more tools become available to a broader user base. These developments are tightly linked to the rise of OpenAi's ChatGPT and other, widely adopted technologies like \gls{sd} based \gls{t2i} generators. An output example of how future media could  be produced is depicted in figure \ref{fig:scheider-real-sd}. A more detailed description about the relevant technologies will be provided in section \ref{chap:background} \nameref{chap:background}. \\
Current AI tools are often referred to as \gls{genai}: "Generative AI is an umbrella term used for AI systems that can generate new forms of data, often by applying machine learning to large quantities of training data" \citet{arguedasAutomatingDemocracyGenerative2023}. One could extend this definition with the following: Besides just generating new forms of data, \gls{genai} can be used to augment, reduce, manipulate and mix real data with the generated data in such a form, that it is impossible to distinguish between real, syntheticly generated (fake) data, or anything in between that spectrum. \\
%\todo{P1.2. What is the specific problem?}
In the context of media production and and media distribution the developments of \gls{genai} open up an important discussion about trust and credibility. Legitimate media, has always been using synthetic content for various purposes. One can just think of animated explainatory videos or other infographics. The difference is, that most illustrations made it quite clear, that these images were illustrations. This has now changed as generated images and videos can look perfectly authentic and real. At the same time these technologies are open to be used by anyone, sparking fear of fake news. Therefore the question for legitimate media outlets remains, of how synthetic content will be recieved among the audience. Additionally, just the term "AI" sparks criticism. These effects on audience, their mitigation, and at the same time, education of the broader public about technologic advancements are very interesting topics for media producers and outlets. Since the developments are quite recent only few research examples exist.

% Second Paragraph
% CORE MESSAGE OF THIS PARAGRAPH:
%\todo{P2.1. The second paragraph should be about what have others been doing}
For the sake of completeness, these discussions are not entirely new: So called DeepFakes (blend word of Deep learning and Fake News) have been around quite some time. First research papers like Facebook's 2014 DeepFace \cite{taigmanDeepFaceClosingGap2014} or the Face2Face approach by \citet{thiesFace2FaceRealtimeFace2020} date back to the year 2016. It took some time until the research gained traction among a the broader audience, but at latest in 2017, in the form of DeepFake pornography or revenge porn, DeepFakes hit the broader public \cite{coleAIAssistedFakePorn2017}. 
Or as \citet{westerlundEmergenceDeepfakeTechnology2019a} puts it: "After the introduction of celebrity porn deepfakes to Reddit by one user in late 2017, it only took a few months for a newly founded deepfake hobbyist community to reach 90,000 members".
Quickly afterwards discussions arose about the implications of these technologies in regards to the spread of fake news.
It took some time until the fears came true. \\
In the meantime DeepFakes remained very problematic present within pornography but also in entertainment and educational content: Jordan Peele Faked Obama (2018 \cite{vincentWatchJordanPeele2018}), Channel 4 emitted a fake Queen Elizabeth (2020 \cite{DeepfakeQueenDeliver2020}) and VFX Artist Chris Ume went viral with Tom Cruise Fakes (2021 \cite{vincentTomCruiseDeepfake2021}). \\
Despite the proliferation of payed and \gls{oss} solutions for faceswaps, like \gls{dfl} (2019) or the InsightFace Inswapper (2023), there are only a few known cases, where this technology has been used for one singular disinformation video with larger consequences. However, it goes without saying, that the effect in social networks, under the radar of public control, might be much bigger. Some studies about these hypothesis will be featured in section \ref{chap:rel-work}. \\
The first mentioning of a trust dissolving DeepFake happened in 2022: Fake news of President Zelensky surfaced (Figure \ref{fig:zelensky-deepfake}), where the fake demanded soldiers to lay down their weapons. Although the russian creators of the video later disputed their creation as "satire" this was certainly not clear within the original video. For what had been feared for quite some time had become reality. The technology had been used in a political context, probably the first time in history also in an armed conflict. Some might say it had been weaponized. Although the Video seemed to have no concrete consequences for the soldiers, its role in psychological warfare can't be unseen.
\begin{figure}[h]
  \centering
  \includegraphics[width=0.5\textwidth]{./graphics/images/Zelensky.jpg}
  \caption{left: DeepFake of President Zelensky; right: real image of Zelensky \cite{universityofvirginiaZelenskyySurrenderHoax2022}}
  \label{fig:zelensky-deepfake}
\end{figure}

%\todo{P2.2. Why is the problem important? Why was this work carried out?}
Progressing in time, in the second half of 2022 several things changed in the space of AI tools. The aforementioned \textit{simple} faceswaps are now in good company in a growing toolbox of AI services: 
\begin{enumerate}
  \item Excellent AI voices cloning tools became available
  \item Text to image generation was released in summer 2022
  \item GPT-enabled Chat Applications was released end of 2022
\end{enumerate}
The latter is less relevant in the audio-visual content, but fuels the public opinion about A.I. tools as it is probably most widely adopted. The first two have drastically improved the quality and possibilities of how and what kind of synthetic media can be created. In the recent months there have been several reports about their use with increasing frequency: 
The examples of fake voices and faceswaps on social media in 2023 are innumerable and can be traced back to the availability of online services such as Resemble.ai or Elevenlabs. This also lead to several nefarious use cases: To name some examples in German context, in September 2023 a primetime news host was recreated with a fake voice in order to advertise dubious financial products (figure: \ref{fig:sievers-fake}). By using Elevenlabs' checking tool, one can quickly tell, that the voice was likely created with their software.(figure: \ref{fig:sievers-11labs}). 
\begin{figure}[h]
  \centering
  \begin{subfigure}[b]{0.45\textwidth}
    \includegraphics[width=\textwidth]{./graphics/images/sievers.png}
    \caption{fake of Christian Sievers \cite{zdfDeepfakeMitZDFModerator}}
    \label{fig:sievers-fake}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.5\textwidth}
    \includegraphics[width=\textwidth]{./graphics/images/sievers-11labs.png}
    \caption{Elevenlabs audio analysis \cite{elevenlabsAISpeechClassifier}}
    \label{fig:sievers-11labs}
  \end{subfigure}
  \caption{Christian Sievers DeepFake and Elevenlabs audio analysis}
\end{figure}

In the end of November 2023 \textit{two} Videos of German chancellor Olaf Scholz were released, where his voice and lips were faked. One was part of a commercial campaign for a german yellow press newspaper \cite{dwdl.deSpringerTrommeltMit}. The second is part of an art/protest project \cite{zdfKunstinstallationDeepfakeScholzVerkuendet}. Example images for these cases are not included, as they don't make any sense without the audio. It is logical, to expect a further increasing frequency of such content, both in the case of legitimate and illegitimate content.
An environment where both categories of content coexist is very challenging in regards of trust. For legitimate news makers the questions arises how it can combat disinformation and at the same time use the advancements of \gls{genai} to improve production workflows. This is a dilemma that is yet to be solved. \\
The effects of these very recent technical capabilities have not yet been studied, which is why this work attempts in doing so. In a time where the very existence of \gls{genai} raises trust issues on every kind of content, specifically of those synthetically generated, any findings about synthetic media reception might be helpful in better addressing all the named issues.

% Third Paragraph
% CORE MESSAGE OF THIS PARAGRAPH:
%\todo{P3.1. What have you done?}
This paper tried to explore the effect on potential recipients of (partially) synthetically created or AI enhanced media in the specific context of a german \gls{psm} news show. To be more specific, the focus of the research questions were: 

\todo{Forschungsfragen final fixen}
\begin{enumerate}
  \item Trust and credibility in media with varying the degree of artificiality.
  \item Effects of a "generated with AI" watermark on the material.
  \item Correlation with participants' media and AI literacy
  \item Correlation with the used screen size.
  \item Finding the most significant of the aforementioned variables.
\end{enumerate}

\todo{fix duration of study and numbers}
The questions were answered with the help of an online survey. It has been conducted within 31 days from the 6\textsuperscript{th} of November 2023 until the 6\textsuperscript{th} of December 2023. During this timeframe 159 participants answered the questionnaire. The details and results will be described within section \ref{study}. \\
Before conducting such a study, the content itself needed to be created to ensure a high degree of controlability of certain variables. To accomplish this, several workflows had to be established which included several experiments with various \gls{oss} tools and chaining them together. In addition to the AI software, tradition video editing tools like \gls{prpro} and \gls{ae} came into play. The specific creation of the material is described in section \ref{implementation}. The author conducted the work in association of the german public broadcaster \gls{br} and the \gls{hff} and had an employment relationship with \gls{br} as a working student.

%\todo{P3.2. What is new about your work?}
The Methodology seeked to conduct a study about trustworthiness on various AI generated or assisted videos.
The tested videos were carefully designed by taking into account an extensive toolchain of available open source technology, making it (theoretically) possible for every media producer to recreate similar results implement (semi)automatic workflows for their media production and conduct further experiments. However the specific code implementation won't be directly shared as the risk of misuse of this project should be reduced. \\
As the tools are very recent developments, to our knowsledge, no comparable studies have been conducted yet.

% Fourth paragraph
% CORE MESSAGE OF THIS PARAGRAPH:
\todo{P4.1. What did you find out? What are the concrete results?}
\todo{P4.2. What are the implications? What does this mean for the bigger picture?}

\chapter{Background}
\label{chap:background}

This work focusses on the social aspects of synthetic media consumption, therefore related work is less technical as will be visible in section \ref{chap:rel-work}. However for the study and accompanying videos a lot of AI technologies have been implemented. To aid the overall understanding of the whole paper some technological background will be layed in this section.

\begin{quotation}
"Although it is difficult to pinpoint, the roots of AI can probably be traced back to the 1940s, specifically 1942, when the American Science Fiction writer Isaac Asimov published his short story \textit{Runaround}" \cite*{haenleinBriefHistoryArtificial2019}. 
\end{quotation}

On the other side of the imaginary, the pracitcal science was evolving during wartime. After Alan Turing famously engineered a computer to crack the Enigma cryptography he published his seminar article "Computer Machinery and Intelligence" where he described how to create intelligent machines and in particular how to test their intelligence \cite{haenleinBriefHistoryArtificial2019}. 
In the following years the term "artificial intelligence" rose to more prominence, most notably at Dartmouth College, where Marvin Minsky and John McCarthy hostet the \textit{Dartmouth Summer Research Project on Artificial Intelligence (DSRPAI)} in 1956 \cite{flasinskiHistoryArtificialIntelligence2016}. \\
The different times of where AI had its highs and lows are often refered to as the Fours Seasons of AI. Spring, representing the dawn of AI was followed by the Summer: After the events at Dartmouth college, a lot of funding by US Institutions suchs as DARPA or the RAND coorporation went into AI reasearch. Without going to much into the details of various developments, one can state that this first hype abruptly ended around 1973 where the high governmental spendings where cut. The first AI winter is often credited to Marvin Minsky and Seymour Papert, who published their famous book “Perceptrons” \cite{minskyPerceptronsIntroductionComputational2017} in 1969, in which they showed the strong limitations of perceptrons, e.g., the inability to compute some logical functions like XOR. As a result, many AI researchers concluded that the study of neural networks is not promising \cite{flasinskiHistoryArtificialIntelligence2016}. \\
\Citeauthor{haenleinBriefHistoryArtificial2019} state that, although the Japanese government began to heavily fund AI research in the 1980s, to which the U.S. DARPA responded by a funding increase as well, no further advances were made in the following years. This can only be partially held true, because some progress had to be made before the second AI summer came around: Notably multi-layer Perceptrons and therefore Deep Neural Networks in 1965, Backpropagation in 1970, Convolutional Neural Networks in 1979, Autoencoders in 1986, Generative Adversarial Networks 1990, to name just a few \cite{schmidhuberAnnotatedHistoryModern2022}.

\begin{figure}[h]
  \centering
  \includegraphics[width=0.9\textwidth]{./graphics/images/Timeline_of_generative_models_by_type.png}
  \caption{Timeline of generative models by type. \citet{garcia-penalvoWhatWeMean2023}}
  \label{fig:timeline-models}
\end{figure}

The AI summer arrives with \citet{krizhevskyImageNetClassificationDeep2012} and their significant advancements in image recognition using a convolutional neural network, "AlexNet". Their Network performed considerably better than the previous state-of-the-art. In 2015, AlphaGo followed with being the first AI to beat Grandmasters in the game Go. \\
Besides the image recognition domain, text and natural language processing received huge performance improvements with \citetitle{vaswaniAttentionAllYou2023} and their "Transformer" architecture in 2017. \gls{tts} also benefitted from transformer research with with major advancements in \citetitle{wangTacotronEndtoEndSpeech2017} in 2017 \cite{wangTacotronEndtoEndSpeech2017}. And to name one of the most recent advancements, diffusion based approaches are to be mentioned, which gave the powerful \gls{t2i} generator Stable diffusion its name. \cite{rombachHighResolutionImageSynthesis2022}. A chronological overview of the model developments can be depicted in figure \ref{fig:timeline-models}. \\
As the scientific advancements are numerous, so are their practical implementations. Those relevant to this work will be shortly described below.

\section{Generative AI}
\label{sec:genai}
The term \gls{genai} has been briefly mentioned in the introduction, but for better understanding the term shall be examined deeper to avoid misunderstanding in ambiguity. There is no globally agreed definition for "Generative AI" \cite{garcia-penalvoWhatWeMean2023}.

\begin{figure}[h]
  \centering
  \includegraphics[width=0.9\textwidth]{./graphics/images/gtrends_genAI_1712-2312.png}
  \caption{Google Trends of "generative AI" from December 2017 to December 2023 \cite{googletrendsGoogleTrendsQuery}}
  \label{fig:gtrend-genai}
\end{figure}
\begin{figure}[h]
  \centering
  \includegraphics[width=0.9\textwidth]{./graphics/images/gtrends_deepfake_1712-2312.png}
  \caption{Google Trends of "Deep Fakes" from December 2017 to December 2023 \cite{googletrendsGoogleTrendsQuerya}}
  \label{fig:gtrend-deepfakes}
\end{figure}

For the scientific community a generative model, as described with a \gls{gan}, refers to a specific subform of neural networc architecture. These are differentiated from discriminative models by their internal processes and the probabilities they estimate \cite{garcia-penalvoWhatWeMean2023} in \cite{gmComprehensiveSurveyAnalysis2020}. \\
It is unlikely, that the broader public refers to the same, deeply technological context. It is more likely that the meaning is less about technical implementations, but more of how and end user utilizes the software: If things can be generated using AI it is generative AI. This notion can be supported by google trends of "generative AI" as depicted in figure \ref{fig:gtrend-genai}. The search requests begin to rise in October of 2023 and then climb high from December 2023 onwards. This fits perfectly to the release of ChatGPT and the spread of image generation software and their media coverage. \\
In the following the term "\gls{genai}" will be used in the means of the broader public and not the narrow technical definition. If technical details are to be discussed, they will be elaborated further. 

\section{ChatGPT}
ChatGPT has been used at several points to conduct this research. Especially during the software development phase(section \ref{implementation}) and the study design (section \ref{study}) ChatGPT has been consulted to speed up the processes massively. \\ 
For study's content generation it did not play any role and thus won't be discussed as deeply as the other technologies. However we must consider the mere existence of ChatGPT in the context of the time this work is being conducted. As discussed in section \ref{sec:genai} the public attention towards AI tools has been tremendosly accelerated by the broad availibility of ChatGPT. When compared to the, in comparison slow and steady, increase of the google trends about DeepFakes in figure \ref{fig:gtrend-deepfakes} we can clearly see a more disruptive tendency on the timeline of ChatGPT.
The fact of how public education could influence the study shall be addressed in the study design by questioning the AI literacy among all participants. 

\section{Face Swapping}
\label{sec:face-swapping}
Similar to the previous section about ChatGPT, FaceSwaps have not been used directly within this project to create media but have played very important rule in shaping public opinion about synthetic media. As mentioned in the Introduction these FaceSwaps initially gave synthetic media the name \textit{Deep Fake} that is being used today. This fact often shifts synthetic media to have a negative connotation. \\
Besides an alerting problem with deepfake pornography and revenge porn, the first publicly recognized DeepFakes were those of Obama(Jordan Peele)\cite{vincentWatchJordanPeele2018} in 2018. \citet{hancockSocialImpactDeepfakes2021} state, that the Obama video is likely the most canonical, if not the original "deepfake" video.
Comparing it with figure \ref{fig:gtrend-deepfakes} this also fits into the timeline with the google trend search. These early DeepFakes are also responsible for the few research papers being conducted on that topic. They will be featured in chapter \ref{chap:rel-work} about the related work. Therefore this section will focus only on the technical side of FaceSwaps. \\
Prior to this paper, extensive experiments have been conducted with different FaceSwap toolkits. In the end, no FaceSwaps have been performed for the study examples. The reason for this decision lies in the study design: Briefly captured, a controlled environment was needed in order to rule out as many disruptive factors as possible. The TV-News setup was chosen as it provided a steady setting. In this case FaceSwaps were not needed. They could have been optionally used to improve the final quality of the rendered faces, but due to time constraints, this approach was not carried out. The idea will be picked up again in section \ref{sec:lips} when the quality of lip remapping is addressed.
Still, the findings about FaceSwaps are interesting as Background context of this work and thus will be included shortly in the following paragraphs.

\subsection{DeepFaceLab}
\begin{figure}[h]
  \centering
  \includegraphics[width=0.9\textwidth]{./graphics/images/dfl-demo.png}
  \caption{DeepFaceLab Test result from September 2021}
  \label{fig:dfl-sample}
\end{figure}
By far the leading Software for face swapping is DeepFaceLab or DFL for short. It encompasses a broad workflow in order to create high end face models. According to the commit history \gls{dfl} came into existance in June 2018 \cite{iperovCommitsIperovDeepFaceLab}. Without being able to say it with certainty, DFL's success might also lie in its proximinty to pornography. The reason for this suspection is that the main guide for how to work with \gls{dfl} is hosted as a subpage of \textit{mrdeepfakes.com}, which claims to the largest DeepFake porn site. To our knowledge these topics were rarely addressed by the authors of the software. As of November 2023 the software has been phased out of development into archive by the lead developer without providing any reasons. Probably this has to with the upcoming of newer, faster methods of face swapping discussed in section \ref{sec:roop}. For the high end workflow \gls{dfl} can still be used and there are other alternatives. \textit{FaceSwap}, actually being the first tool introduced in 2017, is under development. The standard workflow for creating a DFL model is as follows. \\ 
The terms \textit{target} and \textit{source} and to be understood in that way, that the target is the face that will be driving the final face. The source is the face that is being faked onto to target.
\textbf{Data gathering} involves finding the right material to train the models with. High resolution images of both, the target and the source are required but can be easily found online in videos. The final face resolution usually ranges from 128x128 up to 512x512 pixels. So the videos used for datagathering should be of such quality that the required face size can be extracted from the gathered videos. It is very important that the images cover a wide variety of facial angles, expressions and lighting situations. Usually around 8.000 face images are enough for a good fake.
During \textbf{extraction} faces of the wanted size get detected in video frames and extracted. Also facial alignment data gets embedded into the images as metadata as it is needed for the training process.
Afterwards \textbf{sorting and data refinement} is needed to ensure that face alignments have been correcly identified. This step also involves sorting out unwanted images. Exclusion criteria is blurriness or wrongly detected faces for example. Next, \textbf{mask segmentation} comes into play. Here the face gets masked out by a tool. This involves drawing manual face masks to fit the targets and sources face geometry needed for easier merging later on. In ths step obstructions in front of the face can be masked so that the model learns to mask these out as well during merging. After pre-processing is mostly finished and the \textbf{training} can begin. Training can take, depending on hardware, resolution and dataset size some days up to weeks or months to conclude. The training itself is departed into several stages where different hyperparameters have to be adjusted. After training, the final target can be \textbf{merged} with the synthetically generated face. One example of the generated quality can be seen in figure \ref{fig:dfl-sample}.
\begin{figure}[h]
  \centering
  \includegraphics[width=0.9\textwidth]{./graphics/images/df-model-arch.png}
  \caption{"DF" Model architecture diagram \cite{perovDeepFaceLabIntegratedFlexible2021}}
  \label{fig:df-model-diagram}
\end{figure}

\gls{dfl} faceswaps are based on an autoencoder architecture like depcited in figure \ref{fig:df-model-diagram} though in the meantime several subvariants have developed. Autoencoders are notoriously known for their inability to create sharp images. Because of that face upscaling GAN is added within the training process. \\
As can be seen \gls{dfl} is quite complex and time consuming. On the other side it provides a great degree of freedom compared to newer methods.

\subsection{Inswapper}
\label{sec:roop}
Developed on the foundations of the InsightFace Face Analysis Project \cite{insightfaceInsightFaceWebsite} \textit{Inswapper} provides a very easy way to swap faces without the need of any training before inference. The workflow is as simple as loading a target video into the GUI of \textit{roop} \cite{sangwanRoop2023} as well as a source image and wait for the software to create the final video. The used model in the background is closed source and thus cannot be retrained. Besides the enourmous acceleration of the whole process, the lack of customization is the biggest drawback in comparison to \gls{dfl}. Overall the quality of generated Inswapper faces is quite good. The quality of the generated faces drops significantly in situations where the face is ocluded or angled in profile towards the camera. Some examples are included in the appendix under chapter \ref{chap:insightface-demos}. \\
Although not stated specifically by the \gls{dfl} developers, such rapid advancements in faceswap technology might be the reason why \gls{dfl} was discontinued. 

\section{Stable Diffusion}
\begin{figure}[h]
  \centering
  \includegraphics[width=0.9\textwidth]{./graphics/images/latent-diffusion.png}
  \caption{Latent Diffusion Model \cite{rombachHighResolutionImageSynthesis2022}}
  \label{fig:ldm-arch}
\end{figure}
\citet{rombachHighResolutionImageSynthesis2022} released their Latent Diffusion Model (figure \ref{fig:ldm-arch}) in Summer of 2022 and started huge movement for computer graphics. It has been quickly adopted in multiple products and fuel several companies such as \textit{Midjourney, Pika-Labs, Runway, DI-D} and many more. Even more interesting than the appeareance of commercial solutions is the fact how quickly a huge Open Source community grew from the \gls{sd} project. Currently there are around a douzen different GUI projects available for \gls{sd}, some even featuring extensions within the GUI. To name the biggest, \textit{Automatic1111} lists \textbf{269} community extensions which massively extend the functionality in different directions, for example towards video generation. The project was initiated in August of 2022 has 22.500 forks and a 113.000 star rating which is an impressive rate of development \cite{AUTOMATIC1111StablediffusionwebuiStable}. \\
Midjourney, probably the best known commercial solution works over Discord interface and currently has around \textbf{17.3} Million registered users on their channel \cite{midjourneyJoinMidjourneyDiscord}. \\
Besides the development of image generator software there is also a thriving community for model development and finetuning so called \gls{lora} Models. These are then shared on platforms such as \textit{\gls{hf}} or prominently \textit{civitai.com}. While \gls{hf} is focussed on the developer side of models, civitai.com can also be seen as some sort of social network where user generated content in form of generated images is showcased. Civit hosts "thousands of high-quality Stable Diffusion models" as they currently state on their website \cite{CivitaiHomeOpenSource}. Especially \gls{lora}s are interesting as they are very small (several megabytes) compared to full fledged models (several gigabytes). LoRas help in finetuning the bigger models towards a specific goal. Because LoRas are so small they can be shared very easily within the community. It goes without saying that this sort of plug and play models are also well suited and used for pornographic purposes as well. Different to the earlier mention mrdeepfakes.com civitai.com features nudity filters and seeks to create a safer space for every kind of content. A public debate has already started if AI generated pornography will replace pornography and if that is an unwanted outcome. Surely the ethical concerns could fill a paper on their own and thus won't be discussed much further. However some will be mentioned as related work in chapter \ref{chap:rel-work}.\\
Latent Diffusion Models act not only as the core technology but also as a platform and the adoption speed and extensiability of both, the technology and also the community indicate a disruption is taking place here.
In context of this paper a stable diffusion workflow has been used to generate test videos in the style of a computer animation (figure \ref{fig:scheider-real-sd}). The used workflow will be featured later in section \ref{sec:sd-video}. 

\section{Lip Remapping}
\label{sec:lips}
After discarding the previously discussed whole FaceSwaps using \gls{dfl} as a meaningful tool for the study, lip remapping was chosen as one of the main visual technologies for this work. The base for many videos were real recordings from a news show. After creating a synthetic voice (refer to sections \ref{sec:tts} and \ref{sec:v2v}) the proper mouth movement needed to be recreated to make the videos somewhat convinceble. To accomplish a satisfying result, multiple tools needed to be chained together. First and foremost there is \textbf{\gls{w2l}}. Based on the research of \citet{prajwalLipSyncExpert2020} they provide a code implementation on GitHub \cite{mukhopadhyayWav2LipAccuratelyLipsyncing2023}. The code was adapted to fit the workflows for the creation of the study videos and explained in further detail in the implementation section \ref{implementation}.

\begin{figure}[h]
  \centering
  \includegraphics[width=0.9\textwidth]{./graphics/images/w2l-arch.png}
  \caption{Wav2Lip architecture}
  \label{fig:wav2lip-arch}
\end{figure}

The architecture (figure \ref{fig:wav2lip-arch}) is based on a GAN generator-discriminator approach, adding an additional "Lip-Sync Expert" discriminator which improved the results significantly in comparison to previous methods.
Unfortunately, the available public \gls{w2l} model has been trained on a face resolution of only 96x96 pixels which is insufficient for a convincing effect. To address this issue a face upsampling GAN was added to the workflow to increase the facial resolution. The upsampling was performed using the public \textbf{GFPGAN} implementation based on the works of \citet{wangNeuralSourcefilterbasedWaveform2019}. A result can be seen in figure \ref{fig:wav2lip-demo}: To the right one can see the original actor, the middle shows a \gls{w2l} result where the mouth region is blurry and the left depicts the GFPGAN upsampling. The GFPGAN workflow splits the blurry video into individual frames and upsamples each face individually. This introduces flickering artifacts in the face due to small inconsistancies after upsampling that look like flickering once played back with 25 \gls{fps}. This issue can be mitigated with further post production. \\
Overall the process of creating the lip remapping is rather slow. One 20 second video takes over 5 minutes to export. The additional post production and compositing all audio and video sources back together takes around 20 minutes after the workflow is repeated multiple times. \\
Using GFPGAN was not the only option to improve the face quality. As mentioned in section \ref{sec:face-swapping} we could have used \textbf{\gls{dfl}} on top of the \gls{w2l} output and sharpen the result with a full face swap. The method had been tested on other occasions and works quite well. It also does not have issues with face flickering. But on the counterside creating a \gls{dfl} Model is very time consuming, especially if it needs to be good. The processes within this work needed to be somewhat practical for everyday use in a media company. If every lip-remapped actor needs its own \gls{dfl} model trained this is not practical. One image swap solutions like the previously described Inswapper does not improve the quality of the \gls{w2l} outputs. \\
Ideally one would work with higher resolution \gls{w2l} or newer approaches like those from \citet{guptaGeneratingUltraHighResolution2023}. The authors state that their approach great results at 768x768 pixels compared to \gls{w2l}s 96x96 resolution. Unfortunately there was no available code implementation of the paper at the time and therefore couldn't be tested.

\begin{figure}[h]
  \centering
  \includegraphics[width=0.9\textwidth]{./graphics/images/wav2lip-demo.png}
  \caption{lip remapping Workflow, described from right to left}
  \label{fig:wav2lip-demo}
\end{figure}

\section{Text to Speech}
\label{sec:tts}
To cover the audio component of the videos \gls{tts} has been used. Although there are plenty of web-based solutions (\textit{elevenlabs.io, resemble.ai}) one goal of the project was to use \gls{oss} solutions only. Regarding \gls*{tts} the decision was made to use \textbf{CoquiTTS}. CoquiTTS is a library for Text-to-Speech generation with pretrained models in +1100 languages \cite{erenCoquiTTS2021}. CoquiTTS, which developed out of a mozilla project is also community driven but also provides a \gls{saas} called Coqui-Studio. In comparison to the earlier mentioned stable diffusion community coqui's community is not as big and the community support and documentation is worse. But at least there is some documentation about training a new voice and it could be done. The results were satisfying but certainly leave plenty of room for improvement, compared the state of the art commercial solutions. \\
One of the bigger challenges in implementing \gls{tts} was the gathering and pre-processing of training data: 
In exchange with the community a dataset size of around 4 hours of speech was required to get decent results. The difficulty did not lie in getting the raw data, this was easily obtainably from the archives of the \gls{br}. In order to train the \gls{tts} model the data needed to be structured in a special format: Audio segments needed to be under 10 seconds in length and each audiofile needs accompanying transcription in a text file. To solve these issues on a scale of 4 hours of content a toolkit has been developed which will be explained in detail in section \ref{sec:dvt}. \\ 
Usually \gls{tts} is accomplished by using multiple stages of training multiple models. Most architectures feature a spectrogram model that converts the input text to a mel spectrogram and a vocoder that translates the spectrogram to an audio file. However the development in the TTS domain is rapid and many other methods have been created. 
CoquiTTS lists several implemented approaches, such as 13 spectrogram models, 5 End-to-End Models, 6 attention methods, 2 speaker encoders and 8 vocoders. These won't be covered in depth as they are not in focus of this paper. If of any interest, please refer to the CoquiTTS documentation and corresponding papers.\\
For ease of use we decided to use the VITS End-to-End model for this project developed by \citet{kimConditionalVariationalAutoencoder2021}. In contrast to the traditional multi-model approaches VITS offers full TTS capabilites by training just a single model. This approach is faster and more reliable in most cases. A downside of using VITS is fewer granular control over the models. This project favoured speed over quality and opted for the easier workflow of VITS. Naturlly the state of the art changed quickly so the current approach migh as well soon be outdated.\\
Regarding training duration we first trained a first run with 90 minutes of training material for two weeks of a RTX 4090. The second run with 4 hours of material was conducted on A6000 took approximately one week until the loss values converged.

\section{Voice to Voice Conversion}
\label{sec:v2v}
Besides \gls{tts} another recently published approach should be tested: \gls{v2v} conversion. The main difference is that one does not input Text but actual speech into the converter and receives an audio file with the voice of the targeted voice. This approach can address the a problem with \gls{tts} where the synthesized voice sounds to monotonous. Because the tonality of the target speaker is retained after converting it to the other voice an actor can influence how the result should sound. On the counterside certain mannerisms in the actors voice will translate to the result. That can be an odd sounding pronounciation of the letter "S" or "R", hissing, or something else. \\
For accomplishing \gls{v2v} conversion the \gls{rvc} project was used \cite{RVCProjectRetrievalbasedVoiceConversionWebUI2023}. 
\begin{figure}[h]
  \centering
  \includegraphics[width=0.8\textwidth]{./graphics/images/RVC-UI.png}
  \caption{RVC Gradio User Interface}
  \label{fig:rvc-gradio}
\end{figure}
The project features a gradio.io user interface (figure \ref{fig:rvc-gradio}) for easy cloud deployment and is quite self expalinatory. Regarding the dataset requirements, approximately 10 minutes of a person's voice is required. The data pre-processing does not require any textfile transcription as with \gls{tts} but does need cutting up the voice samples in sections under 10 seconds to avoid an \gls{oom}. This can be easily achieve with the pre-processing toolkit developed for the \gls{tts} section of this work. The training itself takes approximately one hour on an A6000 GPU. \\
After training is completed inferencing the model is very fast. With \gls{rvc} it processes inputted audiofiles in near realime. It is to be noted, that there is an implementation of a real time voice changer for these models \cite{WokadaVoicechangerVoice}. One can use input from a file or microphone and the voice changes with very little delay (100ms on a suitable graphics card). The implications of such realtime voice fake capabilities are very interesting in the domain of DeepFakes and scams. There have been some reports that fake voices have been used to conduct scams. However these were often accomplished using \gls{tts} and prepring the sound snippets for playback. Combining such a technology with the real time FaceSwaps calls for caution and multifactorial security in videocall-based social interaction. \\
Interstingly these voice models are shared as well among creators on platform such as civitai but the technology has not yet had such an impact to broader society as stable diffusion had. \\
\gls{v2v} models could also be used to improve \gls{tts} quality in a similar fashion as suggested with Wav2Lip and FaceSwaps: One could train a faster but lower quality \gls{tts} model and then upsample the voice quality in realtime with \gls{v2v}. No experiments were conducted in this direction due to time constraints as that would have required a shift in the \gls{tts} approach.

\section{Game Engines and virtual Production}
\label{sec:bg-virtual-production}
A few years before the big leap in \gls{genai} virtual production methods started to gain traction within the film and broadcasting industry. Instead of filming in front of a greenscreen, \textit{The Mandalorian} (2019) famously used a large LED Panel around the whole studio walls and ceiling to shoot their movie (refer to figure \ref{fig:mando-vps}). That way many effects could be achieved "in camera" opposed to "in post production" as it is done usually.

\begin{figure}[h]
  \centering
  \includegraphics[width=1\textwidth]{./graphics/images/mandalorian-vp.jpg}
  \caption{\textit{The Mandalorian} Studio and LED-Volume "Stagecraft" \cite{landsiedelGamechanger2021}}
  \label{fig:mando-vps}
\end{figure}

The important shift in technology was not only the use of LED panels, but what drives the images on the screens. It is Software, usually found in the Gaming Industry: \gls{ue}, a so called \textbf{Game Engine}. The Engines capability to render photorealistic images in realtime made it the ideal driver for this novel movie production. Today \gls{ue} is can not only be used to generate environments, but humans as well. Their software \textit{Metahuman} creator allows an easy character creation. It is also possible to scan a face and transfer the geometry onto a metahuman. An example of such approach can be seen in figure \ref{fig:metahuman-comp} this process does not work perfectly well. 

\begin{figure}[h]
  \centering
  \begin{subfigure}[b]{0.45\textwidth}
    \includegraphics[width=\textwidth]{./graphics/images/photogrammetry.png}
    \caption{Photogrammetry scan}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.5\textwidth}
    \includegraphics[width=\textwidth]{./graphics/images/Metahuman.png}
    \caption{Metahuman based on photogrammetry scan}
  \end{subfigure}
  \caption{Mesh to Metahuman workflow}
  \label{fig:metahuman-comp}
\end{figure}

Already during the timeframe of creation of the videos the process for creating metahumans improved considerably. It is only a question of time until these metahumans get more advanced. Currently gaussian splatting seems to be a key technology to watch in these regards. \\
It has to be noted that \gls{ue} is a complicated tool that needs a lot of time to be mastered. In addition to \gls{ue} many other, more specialized tools need to be used to get the best possible output. These include modelling tools for environments and characters as well as texturing tools and many more. \gls{ue} in the end is good at combining all the assets, but to get high quality results a team needs expertize in many different areas of traditional computer animation. Espcially the metahuman characters fall into the uncanny valley, which makes the results unsuitable for a good study. It was explored to improve the faces quality using a \gls{dfl} model. Unfortunately the uncanny part of the face is not the appeareance of the face, but its movements. This most likely has to do with how the face is animated. The facial performance capture is being accomplished using and iPhones FaceID camera which has limitations in how many facial landmarks it can track and therefore reduces face movement fidality. Because of that the face movements do not look very natural and because the movements translate to the \gls{dfl} face as well it is of no use. \\
Even though the quality of the metahuman result was not compelling, they were included  within the study as will be elaborated in section \ref{study}. 

\chapter{Related Work}
\label{chap:rel-work}
% Introduction
While Chapter \ref{chap:background} served the purpose of giving some background on the technical side and establish a general understanding of how the used technologies can be applied. Now we want to present some related work in the domain of psychological and sociological research, which has been done in the context of (synthetic) media trust and credibility and the effects of fake news in general. 

\begin{quotation}
  "[...] We urge researchers to begin to study the social issues surrounding deepfake technology. The studies in this volume do a fantastic job of mapping out the research questions, applying theory to the phenomenon, and creating new tools to apply to future research. But this study is preliminary, and we urge scholars to build upon this study as deepfake use continues to grow." \cite{hancockSocialImpactDeepfakes2021}
\end{quotation}

With this call to action, "Cyberpsychology, Behavior, and Social Networking" (volume 24, issue 3) published several articles that can be summarized as "the social impact of DeepFakes". This was in 2021, three years after DeepFake FaceSwaps have become dominant. To begin with, \citet{hancockSocialImpactDeepfakes2021} raised a few questions about DeepFakes: Does exposure to deepfakes undermine trust in the media? How might deepfakes be used during social interactions? Are there strategies for debunking or countering deepfakes? They concluded that empirical research on the social impact of DeepFakes is scarce and therefore referenced to neighbouring fields. \\
In an introduction to the topic as a whole, \citet{hancockSocialImpactDeepfakes2021} cite studies on "false memory aquisition" by \citet{garryActuallyPictureWorth2005}. These experiments often involve some doctored footage of participants, often created with tools of 3D Animation, and prove, that it is possible to induce false memories with that approach. \\
\citet{hancockSocialImpactDeepfakes2021} also mention deception research and conclude that people perform only slightly above chance when evaluating a message as either true or deceptive \cite{bondAccuracyDeceptionJudgments2006}. To quote: "Studies have shown that deception detection is approximately the same whether the message is conveyed through text (e.g., a court transcript, an Internet chat log), an audio recording (e.g., a voicemail, a radio program), or a video (e.g., an interrogation video)" \cite{hancockSeeNoEvil2010} cited in \cite{hancockSocialImpactDeepfakes2021}. \\
The references by \citet{hancockSocialImpactDeepfakes2021} show how far research in the field can reach out. In the following we will present further examples. We decided to divide the related work in three categories: In \ref{sec:hist-context} we want to provide some context about the environment in which the papers were written. In \ref{sec:rel-secondary} we shed some light on methods which don't study participants responds directly in a study, but analyze secondary indicators such as newspaper articles, forum blogposts and video comments. In \ref{sec:rel-studypart} we name controled studies, which were conducted with individual participants who consumed some kind of synthetic content. Our own paper should fall under the latter category as well. And in \ref{sec:rel-work-counteringdf} we added some works about countering maleficent synthetic media.

\section{Historical and socio-geographical Context}
\label{sec:hist-context}
As stated in the Introduction, synthetic media is a rather new trend, mainly driven by the advance of \gls{genai}. It can be dated back to earliest of 2017 when DeepFake FaceSwaps surfaced to the broader public. It is remarkable, that the term \textit{Fake News} is also a very young topic on its own and developed around the same time as DeepFake FaceSwaps around 2016. For completeness it should be noted that the \citet{merriam-websterdictionaryRealStoryFake} dates the first use of Fake news back to the year 1890. Surely skepticism has always existed towards politics and media, but it surely wasn't as a big of a topic until Donald Trump entered his presidential campaign in 2016 as can be seen in the Google trend analysis in figure \ref{fig:gtrend-fake-news} and \ref{fig:trust-us}. That said, it wouldn't make much sense to look for related work earlier than 2016/2017. Therefore we focussed our attention to the timeframe where DeepFakes came into existance and Fake News became a publicly relevant topic.
\begin{figure}[h]
  \centering
  \includegraphics[width=1\textwidth]{./graphics/images/gtrends_fakenews_1011-2311.png}
  \caption{Google Trends of the term "Fake News" 2004-2023}
  \label{fig:gtrend-fake-news}
\end{figure}
\begin{figure}[h]
  \centering
  \centering
  \includegraphics[width=0.75\linewidth]{./graphics/images/trust-america mainstream.png}
  \caption{Trust in American Mainstream Media 1996-2017 \cite{allcottSocialMediaFake2017}}
  \label{fig:trust-us}
\end{figure}
\begin{figure}[h]
  \centering
  \includegraphics[width=0.9\linewidth]{./graphics/images/FGW-Trust-in-ARDZDF.png}
  \caption{Question: How high is your trust in \gls{psm} ARD \& ZDF? (2015-2023) \cite{zdf-politbarometerVertrauenGlaubwuerdigkeitBerichterstattung2023}}
  \label{fig:trust-ger}
\end{figure}
In our study we investigate a german-speaking population. Therefore we want to add, that papers which are focussed on a certain terretory (mostly US in relation of Trump) can only be included with the caviat that they might not directly apply to the german cultural space as well. To illustrate one difference we can refer to figure \ref{fig:trust-ger} in comparison to \ref{fig:trust-us}. While trust among american public decreased around 2016, no impact can be seen in Germany at this time. It took until the years of the Covid19 Pandemic to experience a decline in Germany as well. It remains to be seen how this trend will continue in the following years.

Surely its impossible pinpoint one signular event, person or technology as the starting point for trust issues towards media within a society. We chose to orinate this research from a technological view. And while we define DeepFakes as the umbrella term for all synthetically generated Fake News, we will chronologically encounter FaceSwaps first as they are the oldest of the relevant technologies. Please bare in mind that literature published before the \gls{genai} boom of 2022 refers to DeepFakes as FaceSwaps in most cases, simply because other technologies where non-existant or irrelevant to the public until very recently. The term DeeFake was used analogously with FaceSwaps until other technologies advanced such as synthetic voices, lip-remapping and todays image generators.

\section{Measurements through secondary Indicators} 
\label{sec:rel-secondary}
\citet{westerlundEmergenceDeepfakeTechnology2019a} provide a literature review on "emerging scholary literature" in addition to publicly available news articles. They used this data to reflect on benefits, threats and examples of current DeepFakes and how to combat them. The authors list several benefits in the regions of media production,educational media and digitalcommunications, games and entertainment, socialmedia and healthcare, material science, and various business fields, such as fashion and ecommerce. As examples they name several entertaining DeepFakes of famous actors or a museum installation that brought Salvador Dali back to life. \Citeauthor{westerlundEmergenceDeepfakeTechnology2019a} also conclude: "According to our study, deepfakes are a major threat to society, the political system and businesses[...]". They reached this conclusion based on the existance of countless pornographic DeepFakes, and multiple polical Fakes. The Obama/Peele Fake is quoted again, but also a viral video of the american politician Nancy Pelosi and another Fake of Donald Trump. The authors evaluated these videos to have had limited poitcal influencing, but they also provide two examples where they had consequences. In one case from 2018, a DeepFake of Gabon's long-unseen president Ali Bongo, who was believed in poor health or dead, was cited as the trigger for an unsuccessgul coup by the Gabonese military. In the other case a viral clip from Malaysia showed a man's confession to having sex with a local cabinet minister and caused political controversy. \\
About a possible solution \Citeauthor{westerlundEmergenceDeepfakeTechnology2019a} name four fields: "1) legislation and regulation, 2) corporate policies and voluntary action, 3) education and training, and 4) anti-deepfake technology". Section \ref{sec:rel-work-counteringdf} will give further insight in some countermeasures.

The works of \citeauthor{leeBelieveNotBelieve2021} took a different approach and move closer to the corupus delicti. They picked the top 10 DeepFake Videos on Youtube and provided a content analysis of their audience comments.  

\todo{analysis of Reddit mining} Brooks

% Reviews with studies on actual people
\section{Measurements with study participants}
\label{sec:rel-studypart}
Whether people indeed “fall for” deepfakes is unclear and understudied, but not unimaginable \cite{dobberMicrotargetedDeepfakesHave2021}. In an evaluation of the Obama/Peele Fake \citet{vaccariDeepfakesDisinformationExploring2020} conclude: "We have shown that political deepfakes may not necessarily deceive individuals, but they may sow uncertainty which may, in turn, reduce trust in news on social media." They also add these detrimental tendencies can lead to a downward spiral of trust loss in media and news in general. But it's important to add that these cases might not even need manipulated video to spread fake news. Text can also suffice to spread misinformation, as could be seen during the Covid19 pandemic and often mentioned social media channels \cite{naeemExplorationHowFake2021}. Another awful example of how powerful just text can be, is the Q-Anon movement: \cite{zeeuwTracingNormieficationCrossplatform2020} investigated "[...] how ideas and objects travel from fringe online subcultures to large audiences on mainstream platforms and news outlets". \\
\citet{dobberMicrotargetedDeepfakesHave2021} particularly investigated what effect deepfakes can have when amplified through microtargeting in a fictional scenario. Their results indicate that it is indeed possible to stage a political scandal with a deepfake. Intestingly their findings differed to earlier authors, who found no effects of disinformation on political behavior and attitudes. They state: "[...] indeed deepfakes are a more powerful mode of disinformation in comparison with the false news stories studied by Guess et al. (2018) and the Russian Twitter trolls studied by Bail et al. (2020)" \cite{dobberMicrotargetedDeepfakesHave2021}.

\todo{Heiselberg Lene}
\todo{Toff}


\section{Countermeasures}
\label{sec:rel-work-counteringdf}
Technical countermeasures
It must be mentioned, that anti-deepfake technology always will have its boundries. The efficacy will always depend on the technologies ability to detect deepfakes. With better detection come better methods for generation. It's an arms race that improves both parties and gives \gls{gan} its name. Because of that, other solutions in the domain of \textbf{media provinence} could provide more safety, than forensic detection. In this context, "Project Origin" has be mentioned. An alliance of media producers and broadcasters want to develop a "technical provenance approach, in conjunction with media education and synthetic media detection techniques [and] help to establish a foundation for trust in media" \cite{ProjectOrigin}. The alliance includes organisations such as \textit{BBC, Radio Canada, New York Times and Microsoft}. This lead to the creation of the \gls{c2pa}, the formulation of a technical standard to achieve to goals forumlated earlier. This project is today backed by major hardware (\textit{Canon, Nikon, Sony, Leica, Panasonic, ARM}) and software companies (\textit{Adobe, Microsoft, AWS, AVID}), media resellers distributors and providers\textit{BBC, Radio Canada, dpa, france-tv, shutterstock, universal music}. \gls{c2pa} is currently being implemented by the industry.


\todo{combating Deepfakes with media literacy programs} Hwang et al.





We conclude that research involving \gls{genai} created media is still scarce. This is understandable due to the novelty of the technologies, their complexity and the availability of tools for creation. In order to conduct research one first has be be able to create such material that is comparable to material "in the wild". This is even more true in the advent of \gls{genai} as more more content is getting produced and consumed.



To name a positive example: 
\todo{Wu et al from cyberpsychology}


\todo{Trust towards AI program influencers} Weisman 
Uncanny valley und stuff.

\todo{policymaking ideas}








Generative AI is advancing at such a rate that it's impossible keep all developments in sight. Research has just caught up with the outcome from FaceSwap DeepFakes which today look antiquated in the light of ChatGPT and \gls{sd}. 
It is obvious that the researching community has to continue to follow the call from \citet{hancockSocialImpactDeepfakes2021} and study what they called . A call that the authors of this paper were happy to comply.


\todo{identify gaps}
\todo{reception of media}
\todo{synthetic media reception}
\todo{lawsuits}

\chapter{Methodology}
\section{implemented Technologies}
\label{implementation}
Docker based deployment, CI/CD. Remote work on HFF Workstation

\subsection{Voice Cloning Toolkit}
\label{sec:dvt}
\subsubsection{Preparation and Pre-Processing}
Whisper, Premier, Nemo
\subsubsection{Text To Speech}
\subsubsection{Retrieval Based Voice Conversion}
\subsection{Lip remapping}
Wav2Lip

\subsection{stable Diffusion + Video}
\label{sec:sd-video}
Extact workflow for the video creation 
Controlenet was state of the art and is now already outdated. 

\subsection{Game-Engine: Unreal Engine}
Einzelpraktikum stuff

\section{Study}

for each case: state hypothesis and dependent/independent variables, control conditions, \textbf{randomization check??}

\label{study}
\subsection{Study Design}
Spectrum of artificiality.
Randomization.
AB Groups. 
Sequence bias.
Basic Questions: Media usage, media trust, ai usage and trust

\subsection{Procedure and Participants}
Online survey, spread via various channels.

\subsection{Results}

\subsubsection{Normal Distribution}
Most of the things are normal?
Shapiro Wilk Test
Histogram
Case Trust
Case Videos

\subsubsection{Significance}
Quality, artificiality

\subsubsection{AI marking significance}

\subsubsection{Quality and Trust}

\subsubsection{Education}







\chapter{Discussion}

\chapter{Conclusion}
\label{sec:conclusion}

Future implementation und Haushandlungsprozess. Was wichtig ist:) 

To close the circle with the beginning. This work might be too early. The disruptive process has just begun, the developments can happen rather quickly. It therefore might remain interesting to closely monitor how the credibility and trust toward media, both synthetic and real, unfolds in the next years. 





\todo{Outlook}

\printbibliography
All links were last followed on \today{}.

\appendix
\chapter{Inswapper examples}
\label{chap:insightface-demos}
The following tests were created using the \textit{roop} inswapper implementation. One image of the author's face was used for all faceswaps. The included example images include Stills from these movies and music videos: \textit{Barbie} (2023), \textit{Oppenheimer} (2023), \textit{Iron Man} (2008), \textit{Juju feat. Henning May: Vermissen} (2019), \textit{Gotye: Somebody that I used to know} (2011).
These stills were chosen in order to test multiple lighting situations, angles etc. The results are very impressive in most situations. However Close-up shots often don't work due to Inswappers resolution of only 128x128 pixels. Also the masking of objects in front of the face is often inferior to those of \gls{dfl}.

\begin{figure}[h]
  \centering
  \includegraphics[width=1\textwidth]{./graphics/images/inswapper/multiple1.png}
  \includegraphics[width=1\textwidth]{./graphics/images/inswapper/multiple2.png}
  \caption{Tested multiple faces at once, male and female}
\end{figure}
\begin{figure}[h]
  \centering
  \includegraphics[width=1\textwidth]{./graphics/images/inswapper/oppenheimer2.png}
  \includegraphics[width=1\textwidth]{./graphics/images/inswapper/kimbra.png}
  \caption{Color transfer to the target works great}
\end{figure}
\begin{figure}[h]
  \centering
  \includegraphics[width=1\textwidth]{./graphics/images/inswapper/iron-man-too-close.png}
  \caption{CloseUp: Resolution does not suffice anymore for FullHD Material}
\end{figure}
\begin{figure}[h]
  \centering
  \includegraphics[width=1\textwidth]{./graphics/images/inswapper/oppenheimer1.png}
  \caption{Side view of faces often does not work}
\end{figure}

% \input{latexhints/latexhints-english}

\pagestyle{empty}
\renewcommand*{\chapterpagestyle}{empty}
\Affirmation
\end{document}
