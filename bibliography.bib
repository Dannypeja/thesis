@article{ahmedFooledFakesCognitive2021a,
  title = {Fooled by the Fakes: {{Cognitive}} Differences in Perceived Claim Accuracy and Sharing Intention of Non-Political Deepfakes},
  shorttitle = {Fooled by the Fakes},
  author = {Ahmed, Saifuddin},
  date = {2021-11-01},
  journaltitle = {Personality and Individual Differences},
  shortjournal = {Personality and Individual Differences},
  volume = {182},
  pages = {111074},
  issn = {0191-8869},
  doi = {10.1016/j.paid.2021.111074},
  url = {https://www.sciencedirect.com/science/article/pii/S0191886921004517},
  urldate = {2023-11-24},
  abstract = {We examine how individual differences influence perceived accuracy of deepfake claims and sharing intention. Rather than political deepfakes, we use a non-political deepfake of a social media influencer as the stimulus, with an educational and a deceptive condition. We find that individuals are more likely to perceive the deepfake claim to be true when informative cues are missing along with the deepfake (compared to when they are present). Also, individuals are more likely to share deepfakes when they consider the fabricated claim to be accurate. Moreover, we find that cognitive ability plays a moderating role such that when informative cues are present (educational condition), individuals with high cognitive ability are less trustful of deepfake claims. Unexpectedly, when the informative cues are missing (deceptive condition), these individuals are more likely to consider the claim to be true and share them. The findings suggest that adding corrective labels can help reduce inadvertent sharing of disinformation. Also, user biases should be considered in understanding public engagement with disinformation.},
  keywords = {Claim accuracy,Cognitive ability,Deep fakes,Disinformation,Social media},
  file = {/Users/dape/Zotero/storage/UHZAG4DE/Ahmed - 2021 - Fooled by the fakes Cognitive differences in perc.pdf;/Users/dape/Zotero/storage/Y25K2969/S0191886921004517.html}
}

@article{allcottSocialMediaFake2017,
  title = {Social {{Media}} and {{Fake News}} in the 2016 {{Election}}},
  author = {Allcott, Hunt and Gentzkow, Matthew},
  date = {2017-05},
  journaltitle = {Journal of Economic Perspectives},
  volume = {31},
  number = {2},
  pages = {211--236},
  issn = {0895-3309},
  doi = {10.1257/jep.31.2.211},
  url = {https://www.aeaweb.org/articles?id=10.1257%2Fjep.31.2.211&fbclid=IwAR04My3aiycypMJKSI58e84gDvdrodsB9fqCycH9YfepWDDDwT--fZnVPvo;%20https://www.nyu.edu/about/news-publications/news/2019/january/fake-news-shared-by-very-few--but-those-over-65-more-likely-to-p.html},
  urldate = {2023-12-11},
  abstract = {Following the 2016 US presidential election, many have expressed concern about the effects of false stories ("fake news"), circulated largely through social media. We discuss the economics of fake news and present new data on its consumption prior to the election. Drawing on web browsing data, archives of fact-checking websites, and results from a new online survey, we find: 1) social media was an important but not dominant source of election news, with 14 percent of Americans calling social media their "most important" source; 2) of the known false news stories that appeared in the three months before the election, those favoring Trump were shared a total of 30 million times on Facebook, while those favoring Clinton were shared 8 million times; 3) the average American adult saw on the order of one or perhaps several fake news stories in the months around the election, with just over half of those who recalled seeing them believing them; and 4) people are much more likely to believe stories that favor their preferred candidate, especially if they have ideologically segregated social media networks.},
  langid = {english},
  keywords = {Economic Anthropology,Language,{Media, Economic Sociology},{Political Processes: Rent-Seeking, Lobbying, Elections, Legislatures, and Voting Behavior, Entertainment},Social and Economic Stratification},
  file = {/Users/dape/Zotero/storage/KFNZB9BP/Allcott und Gentzkow - 2017 - Social Media and Fake News in the 2016 Election.pdf}
}

@online{andrewHowDoesStable2022,
  title = {How Does {{Stable Diffusion}} Work?},
  author = {{Andrew}},
  date = {2022-12-26T22:25:42-05:00},
  url = {https://stable-diffusion-art.com/how-stable-diffusion-work/},
  urldate = {2023-12-17},
  abstract = {Stable Diffusion is a latent diffusion model that generates AI images from text. Instead of operating in the high-dimensional image space, it first compresses the image into the latent space.},
  langid = {american},
  file = {/Users/dape/Zotero/storage/YFP6T3K4/how-stable-diffusion-work.html}
}

@article{arguedasAutomatingDemocracyGenerative2023,
  title = {Automating Democracy: {{Generative AI}}, Journalism, and the Future of Democracy},
  shorttitle = {Automating Democracy},
  author = {Arguedas, A. R. and Simon, F. M.},
  date = {2023},
  publisher = {{Balliol Interdisciplinary Institute, University of Oxford}},
  url = {https://ora.ox.ac.uk/objects/uuid:0965ad50-b55b-4591-8c3b-7be0c587d5e7},
  urldate = {2023-11-24},
  abstract = {{$<$}p{$>$}Sophisticated AI systems are increasingly everywhere. In many ways, we have already been affected by the rollout of AI systems into more and more areas of life, from insurance and law to healthcare and the media \&ndash; often without really noticing. However, 2023 will likely prove to be a particularly critical moment in the history of AI. Ever since the public release of ChatGPT, a so-called Large Language Model (LLM), in December 2022 by the US start-up OpenAI, we are witnessing a proliferation of a form of AI that has been labelled \&lsquo;Generative AI\&rsquo; due to the ability of these systems to create seemingly everything from realistic text to images. ChatGPT reached 100 million users in just two months and has now been built into Microsoft\&rsquo;s Bing search engine. Various applications rely on the system, which is increasingly integrated into other software, too. Meanwhile, the \&lsquo;AI race\&rsquo; is heating up, with Google releasing its own chatbot and other technology companies vying to get a piece of the cake by building and releasing their own models.{$<$}br /{$>$}Powerful and technologically impressive as some of these developments are, they also raise important questions about their democratic impact. Up until now, we could take for granted humans\&rsquo; central role in shaping democratic deliberation and culture. But what does it mean for the future of democracy, if humans are increasingly side-lined by AI? Does it matter if news articles, policy briefs, lobbying pieces, and entertainment are no longer created solely by humans? How will an increasingly automated journalism and media culture affect democratic participation and deliberation? How can we protect democratic values, like public deliberation and self-governance, in societies which stand to be reshaped through AI? And how might these new technologies be used to promote democratic values?{$<$}/p{$>$} {$<$}p{$>$}To investigate this situation and to gauge the opinions of experts and academics, the Balliol Interdisciplinary Institute project \&lsquo;Automating Democracy: Generative AI, Journalism, and the Future of Democracy\&rsquo; convened a group of experts for a public symposium at Balliol College Oxford, in collaboration with the Institute for Ethics in AI and the Oxford Internet Institute. The aim of the symposium, organised jointly by Dr Linda Eggert, an Early Career Fellow in Philosophy, and Felix M. Simon, a communication researcher and DPhil student at the Oxford Internet Institute, was to identify key issues in this space and start a conversation among academics, industry experts, and the public about the questions outlined above. The symposium featured three panel discussions on \&lsquo;The Technology, Context, and Socioeconomics of LLMs,\&rsquo; \&lsquo;How Generative AI is Impacting the News Media,\&rsquo; and on \&lsquo;Regulating Generative AI Democratically and Globally.\&rsquo; {$<$}br /{$>$}Speakers included leading experts on AI, the news, and democratic theory: Hannah Kirk, an AI researcher and DPhil student at the Oxford Internet Institute; Hal Hodson, a special projects writer and technology journalist at The Economist; Laura Ellis, the BBC\&rsquo;s Head of Technology Forecasting; Gary Rogers, co-founder of news agency RADAR and Senior Newsroom Strategy Consultant at Fathm; Dr Gemma Newlands, Departmental Research Lecturer in AI and Work at the Oxford Internet Institute; Polly Curtis, the Chief Executive of think tank Demos; Prof John Tasioulas, Director of the Institute for Ethics in AI and Professor of Ethics and Legal Philosophy at the University of Oxford; and Prof H\&eacute;l\&egrave;ne Landemore, Professor of Political Science at Yale University.{$<$}/p{$>$} {$<$}p{$>$}After briefly introducing and defining LLMs and Generative AI, this report provides a summary of the main themes that emerged during the symposium and outlines a list of open questions to be addressed in future research and discussions.{$<$}/p{$>$}},
  langid = {english},
  file = {/Users/dape/Zotero/storage/GGHHDPBB/Arguedas und Simon - 2023 - Automating democracy Generative AI, journalism, a.pdf}
}

@online{AUTOMATIC1111StablediffusionwebuiStable,
  title = {{{AUTOMATIC1111}}/Stable-Diffusion-Webui: {{Stable Diffusion}} Web {{UI}}},
  url = {https://github.com/AUTOMATIC1111/stable-diffusion-webui},
  urldate = {2023-12-07},
  file = {/Users/dape/Zotero/storage/HK6JFGFA/stable-diffusion-webui.html}
}

@inproceedings{aythora2020multi-stakeholder,
  title = {Multi-Stakeholder Media Provenance Management to Counter Synthetic Media Risks in News Publishing},
  booktitle = {International Broadcasting Convention ({{IBC}})},
  author = {Aythora, J. and Burke‐Agüero, R. and Chamayou, Amaury and Clebsch, Sylvan and Costa, Manuel and Earnshaw, N. and Ellis, L. and England, Paul and Fournet, Cédric and Gaylor, M. and Halford, C. and Horvitz, Eric and Jenks, A. and Kane, Kevin and Lavallee, M. and Lowenstein, S. and MacCormack, B. and Malvar, Rico and O\&\#39;Brien, S. and Parnall, J. and Redmiles, E. M. and Shamis, Alex and Sharma, I. and Stokes, Jay and Wenker, S. and Zaman, A.},
  date = {2020-09},
  url = {https://www.microsoft.com/en-us/research/publication/multi-stakeholder-media-provenance-management-to-counter-synthetic-media-risks-in-news-publishing/},
  abstract = {The rise of indirect content distribution via third party social media platforms has introduced a new conduit for synthetic or manipulated content. That content purports to be legitimate news, or to come from legitimate news sources, and can present the consumer with apparent brand integrity markings, which convey authority. Three major global news organizations and a leading technology provider have come together to demonstrate a mechanism to tackle this problem that can operate at scale. The BBC, The New York Times Company, and CBC/Radio‐Canada in cooperation with Microsoft have developed a proposed open standards approach which can be used by large and small news organizations to protect the provenance of news stories in audio/visual/textual media.},
  file = {/Users/dape/Zotero/storage/6Q56HGJ4/Aythora et al. - MULTI-STAKEHOLDER MEDIA PROVENANCE MANAGEMENT TO C.pdf}
}

@incollection{blockEntwurfEuropaeischenKIVerordnung2023,
  title = {Entwurf einer europäischen KI-Verordnung},
  booktitle = {Deepfakes und Recht: Einführung in den deutschen Rechtsrahmen für synthetische Medien},
  author = {Block, Martina},
  editor = {Block, Martina},
  date = {2023},
  series = {essentials},
  pages = {29--34},
  publisher = {{Springer}},
  location = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-662-67427-7_5},
  url = {https://doi.org/10.1007/978-3-662-67427-7_5},
  urldate = {2023-11-25},
  abstract = {Am 21. April 2021 veröffentlichte die Europäische Kommission einen Entwurf für eine Verordnung über Künstliche Intelligenz. Dieser enthält in Art. 52 Abs. 3 eine Transparenzpflicht für Deepfakes.},
  isbn = {978-3-662-67427-7},
  langid = {ngerman},
  file = {/Users/dape/Zotero/storage/JGT77TQ7/Block - 2023 - Entwurf einer europäischen KI-Verordnung.pdf}
}

@article{bondAccuracyDeceptionJudgments2006,
  title = {Accuracy of {{Deception Judgments}}},
  author = {Bond, Charles F. and DePaulo, Bella M.},
  date = {2006-08-01},
  journaltitle = {Personality and Social Psychology Review},
  shortjournal = {Pers Soc Psychol Rev},
  volume = {10},
  number = {3},
  pages = {214--234},
  publisher = {{SAGE Publications Inc}},
  issn = {1088-8683},
  doi = {10.1207/s15327957pspr1003_2},
  url = {https://doi.org/10.1207/s15327957pspr1003_2},
  urldate = {2023-12-12},
  abstract = {We analyze the accuracy of deception judgments, synthesizing research results from 206 documents and 24,483 judges. In relevant studies, people attempt to discriminate lies from truths in real time with no special aids or training. In these circumstances, people achieve an average of 54\% correct lie-truth judgments, correctly classifying 47\% of lies as deceptive and 61\% of truths as nondeceptive. Relative to cross-judge differences in accuracy, mean lie-truth discrimination abilities are nontrivial, with a mean accuracy d of roughly .40. This produces an effect that is at roughly the 60th percentile in size, relative to others that have been meta-analyzed by social psychologists. Alternative indexes of lie-truth discrimination accuracy correlate highly with percentage correct, and rates of lie detection vary little from study to study. Our meta-analyses reveal that people are more accurate in judging audible than visible lies, that people appear deceptive when motivated to be believed, and that individuals regard their interaction partners as honest. We propose that people judge others' deceptions more harshly than their own and that this double standard in evaluating deceit can explain much of the accumulated literature.},
  langid = {english},
  file = {/Users/dape/Zotero/storage/33WPJWXQ/Bond und DePaulo - 2006 - Accuracy of Deception Judgments.pdf}
}

@article{brooksDeepFakeItsEnabling2022,
  title = {{{DeepFake}} and Its {{Enabling Techniques}}: {{A Review}}},
  shorttitle = {{{DeepFake}} and Its {{Enabling Techniques}}},
  author = {Brooks, Rachael and Yuan, Yefeng and Liu, Yuhong and Chen, Haiquan},
  date = {2022},
  journaltitle = {APSIPA Transactions on Signal and Information Processing},
  shortjournal = {SIP},
  volume = {11},
  number = {2},
  issn = {2048-7703},
  doi = {10.1561/116.00000024},
  url = {http://www.nowpublishers.com/article/Details/SIP-2022-0024},
  urldate = {2023-12-12},
  abstract = {Deepfake technology has been undoubtedly growing at a rapid pace since 2017. Particularly since using GAN architecture was popularized, research in this area has grown and seems to only be gaining momentum. One interesting area is animating images of full body humans using deep learning. This paper looks at the research done in this area and research that can influence it by looking at papers regarding human pose transfer, human motion transfer, and human motion generation. All of these types of papers have similar requirements, where a target pose must be abstracted to a skeleton and combined with appearance data from a source image to generate a result. The primary difference in the three types of research is whether or not there is motion in the result and whether that motion is given as an input or generated by the model. Overall, the research in this area is still new, and with the potential applications of this technology, both good and bad, there are many avenues of potential future research in this area in both creation and detection.},
  langid = {english},
  file = {/Users/dape/Zotero/storage/XFFCT23P/Brooks et al. - 2022 - DeepFake and its Enabling Techniques A Review.pdf}
}

@article{brooksPopularDiscourseDeepfakes2021,
  title = {Popular {{Discourse Around Deepfakes}} and the {{Interdisciplinary Challenge}} of {{Fake Video Distribution}}},
  author = {Brooks, Catherine Francis},
  date = {2021-03},
  journaltitle = {Cyberpsychology, Behavior, and Social Networking},
  volume = {24},
  number = {3},
  pages = {159--163},
  publisher = {{Mary Ann Liebert, Inc., publishers}},
  issn = {2152-2715},
  doi = {10.1089/cyber.2020.0183},
  url = {https://www.liebertpub.com/doi/10.1089/cyber.2020.0183},
  urldate = {2023-12-12},
  abstract = {This research interrogates the discourses that frame our understanding of deepfakes and how they are situated in everyday public conversation. It does so through a qualitative analysis of popular news and magazine outlets. This project analyzes themes in discourse that range from individual threat to societal collapse. This article argues how the deepfake problem discursively framed impacts the solutions proposed for stemming the prevalence of deepfake videos online. That is, if fake videos are framed as a technical problem, solutions will likely involve new systems and tools. If fake videos are framed as a social, cultural, or as an ethical problem, solutions needed will be legal or behavioral ones. As a conclusion, this article suggests that a singular solution is inadequate because of the highly interrelated technical, social, and cultural worlds, in which we live today.},
  keywords = {disinformation campaigns,fake news,information accuracy,information credibility,information literacy,misinformation},
  file = {/Users/dape/Zotero/storage/5RGLJAA8/Brooks - 2021 - Popular Discourse Around Deepfakes and the Interdi.pdf}
}

@article{carifioTenCommonMisunderstandings2007,
  title = {Ten {{Common Misunderstandings}}, {{Misconceptions}}, {{Persistent Myths}} and {{Urban Legends}} about {{Likert Scales}} and {{Likert Response Formats}} and Their {{Antidotes}}},
  author = {Carifio, James and Perla, Rocco J.},
  date = {2007-09-30},
  journaltitle = {Journal of Social Sciences},
  shortjournal = {JSS},
  volume = {3},
  number = {3},
  pages = {106--116},
  issn = {1558-6987},
  doi = {10.3844/jssp.2007.106.116},
  url = {https://thescipub.com/abstract/jssp.2007.106.116},
  urldate = {2024-01-19},
  langid = {english},
  file = {/Users/dape/Zotero/storage/E2WFVR5P/Carifio und Perla - 2007 - Ten Common Misunderstandings, Misconceptions, Pers.pdf}
}

@inproceedings{chenSingingVoiceConversion2019,
  title = {Singing {{Voice Conversion}} with {{Non-parallel Data}}},
  booktitle = {2019 {{IEEE Conference}} on {{Multimedia Information Processing}} and {{Retrieval}} ({{MIPR}})},
  author = {Chen, Xin and Chu, Wei and Guo, Jinxi and Xu, Ning},
  date = {2019-03},
  pages = {292--296},
  doi = {10.1109/MIPR.2019.00059},
  url = {https://ieeexplore.ieee.org/abstract/document/8695368},
  urldate = {2023-11-24},
  abstract = {Singing voice conversion is a task to convert a song sang by a source singer to the voice of a target singer. In this paper, we propose using a parallel data free, many-to-one voice conversion technique on singing voices. A phonetic posterior feature is first generated by decoding singing voices through a robust Automatic Speech Recognition Engine (ASR). Then, a trained Recurrent Neural Network (RNN) with a Deep Bidirectional Long Short Term Memory (DBLSTM) structure is used to model the mapping from person-independent content to the acoustic features of the target person. F0 and aperiodic are obtained through the original singing voice, and used with acoustic features to reconstruct the target singing voice through a vocoder. In the obtained singing voice, the targeted and sourced singers sound similar. To our knowledge, this is the first study that uses non parallel data to train a singing voice conversion system. Subjective evaluations demonstrate that the proposed method effectively converts singing voices.},
  eventtitle = {2019 {{IEEE Conference}} on {{Multimedia Information Processing}} and {{Retrieval}} ({{MIPR}})},
  file = {/Users/dape/Zotero/storage/XGUH7T8U/Chen et al. - 2019 - Singing Voice Conversion with Non-parallel Data.pdf;/Users/dape/Zotero/storage/NJA24YUP/8695368.html}
}

@article{chenWavLMLargeScaleSelfSupervised2022,
  title = {{{WavLM}}: {{Large-Scale Self-Supervised Pre-Training}} for {{Full Stack Speech Processing}}},
  shorttitle = {{{WavLM}}},
  author = {Chen, Sanyuan and Wang, Chengyi and Chen, Zhengyang and Wu, Yu and Liu, Shujie and Chen, Zhuo and Li, Jinyu and Kanda, Naoyuki and Yoshioka, Takuya and Xiao, Xiong and Wu, Jian and Zhou, Long and Ren, Shuo and Qian, Yanmin and Qian, Yao and Wu, Jian and Zeng, Michael and Yu, Xiangzhan and Wei, Furu},
  date = {2022-10},
  journaltitle = {IEEE Journal of Selected Topics in Signal Processing},
  shortjournal = {IEEE J. Sel. Top. Signal Process.},
  volume = {16},
  number = {6},
  eprint = {2110.13900},
  eprinttype = {arxiv},
  eprintclass = {cs, eess},
  pages = {1505--1518},
  issn = {1932-4553, 1941-0484},
  doi = {10.1109/JSTSP.2022.3188113},
  url = {http://arxiv.org/abs/2110.13900},
  urldate = {2023-11-24},
  abstract = {Self-supervised learning (SSL) achieves great success in speech recognition, while limited exploration has been attempted for other speech processing tasks. As speech signal contains multi-faceted information including speaker identity, paralinguistics, spoken content, etc., learning universal representations for all speech tasks is challenging. To tackle the problem, we propose a new pre-trained model, WavLM, to solve full-stack downstream speech tasks. WavLM jointly learns masked speech prediction and denoising in pre-training. By this means, WavLM does not only keep the speech content modeling capability by the masked speech prediction, but also improves the potential to non-ASR tasks by the speech denoising. In addition, WavLM employs gated relative position bias for the Transformer structure to better capture the sequence ordering of input speech. We also scale up the training dataset from 60k hours to 94k hours. WavLM Large achieves state-of-the-art performance on the SUPERB benchmark, and brings significant improvements for various speech processing tasks on their representative benchmarks. The code and pre-trained models are available at https://aka.ms/wavlm.},
  keywords = {Computer Science - Computation and Language,Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing},
  file = {/Users/dape/Zotero/storage/VU5ZV7TJ/Chen et al. - 2022 - WavLM Large-Scale Self-Supervised Pre-Training fo.pdf;/Users/dape/Zotero/storage/3PYB9VXH/2110.html}
}

@book{christianAlignmentProblemMachine2020,
  title = {The {{Alignment Problem}}: {{Machine Learning}} and {{Human Values}}},
  shorttitle = {The {{Alignment Problem}}},
  author = {Christian, Brian},
  date = {2020-10-06},
  eprint = {Lh_WDwAAQBAJ},
  eprinttype = {googlebooks},
  publisher = {{W. W. Norton \& Company}},
  abstract = {A jaw-dropping exploration of everything that goes wrong when we build AI systems and the movement to fix them. Today’s “machine-learning” systems, trained by data, are so effective that we’ve invited them to see and hear for us—and to make decisions on our behalf. But alarm bells are ringing. Recent years have seen an eruption of concern as the field of machine learning advances. When the systems we attempt to teach will not, in the end, do what we want or what we expect, ethical and potentially existential risks emerge. Researchers call this the alignment problem. Systems cull résumés until, years later, we discover that they have inherent gender biases. Algorithms decide bail and parole—and appear to assess Black and White defendants differently. We can no longer assume that our mortgage application, or even our medical tests, will be seen by human eyes. And as autonomous vehicles share our streets, we are increasingly putting our lives in their hands. The mathematical and computational models driving these changes range in complexity from something that can fit on a spreadsheet to a complex system that might credibly be called “artificial intelligence.” They are steadily replacing both human judgment and explicitly programmed software. In best-selling author Brian Christian’s riveting account, we meet the alignment problem’s “first-responders,” and learn their ambitious plan to solve it before our hands are completely off the wheel. In a masterful blend of history and on-the ground reporting, Christian traces the explosive growth in the field of machine learning and surveys its current, sprawling frontier. Readers encounter a discipline finding its legs amid exhilarating and sometimes terrifying progress. Whether they—and we—succeed or fail in solving the alignment problem will be a defining human story. The Alignment Problem offers an unflinching reckoning with humanity’s biases and blind spots, our own unstated assumptions and often contradictory goals. A dazzlingly interdisciplinary work, it takes a hard look not only at our technology but at our culture—and finds a story by turns harrowing and hopeful.},
  isbn = {978-0-393-63583-6},
  langid = {english},
  pagetotal = {459},
  keywords = {Computers / Artificial Intelligence / General,Computers / Social Aspects,Science / Cognitive Science,Science / Philosophy \& Social Aspects}
}

@article{ciechanowskiShadesUncannyValley2019a,
  title = {In the Shades of the Uncanny Valley: {{An}} Experimental Study of Human–Chatbot Interaction},
  shorttitle = {In the Shades of the Uncanny Valley},
  author = {Ciechanowski, Leon and Przegalinska, Aleksandra and Magnuski, Mikolaj and Gloor, Peter},
  date = {2019-03},
  journaltitle = {Future Generation Computer Systems},
  shortjournal = {Future Generation Computer Systems},
  volume = {92},
  pages = {539--548},
  issn = {0167739X},
  doi = {10.1016/j.future.2018.01.055},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0167739X17312268},
  urldate = {2023-11-23},
  abstract = {This project has been carried out in the context of recent major developments in botics and more widespread usage of virtual agents in personal and professional sphere. The general purpose of the experiment was to thoroughly examine the character of the human–non-human interaction process. Thus, in the paper, we present a study of human–chatbot interaction, focusing on the affective responses of users to different types of interfaces with which they interact. The experiment consisted of two parts: measurement of psychophysiological reactions of chatbot users and a detailed questionnaire that focused on assessing interactions and willingness to collaborate with a bot. In the first quantitative stage, participants interacted with a chatbot, either with a simple text chatbot (control group) or an avatar reading its responses in addition to only presenting them on the screen (experimental group. We gathered the following psychophysiological data from participants: electromyography (EMG), respirometer (RSP), electrocardiography (ECG), and electrodermal activity (EDA). In the last, declarative stage, participants filled out a series of questionnaires related to the experience of interacting with (chat)bots and to the overall human–(chat)bot collaboration assessment. The theory of planned behaviour survey investigated attitude towards cooperation with chatbots in the future. The social presence survey checked how much the chatbot was considered to be a ‘‘real’’ person. The anthropomorphism scale measured the extent to which the chatbot seems humanlike. Our particular focus was on the so-called uncanny valley effect, consisting of the feeling of eeriness and discomfort towards a given medium or technology that frequently appears in various kinds of human–machine interactions. Our results show that participants were experiencing lesser uncanny effects and less negative affect in cooperation with a simpler text chatbot than with the more complex, animated avatar chatbot. The simple chatbot have also induced less intense psychophysiological reactions. Despite major developments in botics, the user’s affective responses towards bots have frequently been neglected. In our view, understanding the user’s side may be crucial for designing better chatbots in the future and, thus, can contribute to advancing the field of human–computer interaction.},
  langid = {english},
  file = {/Users/dape/Zotero/storage/GDEYWGZM/Ciechanowski et al. - 2019 - In the shades of the uncanny valley An experiment.pdf}
}

@online{CivitaiHomeOpenSource,
  title = {Civitai: {{The Home}} of {{Open-Source Generative AI}}},
  url = {https://civitai.com/},
  urldate = {2023-12-08},
  file = {/Users/dape/Zotero/storage/WPU475Y3/civitai.com.html}
}

@article{cochranDeepfakesAwarenessConcerns2021,
  title = {Deepfakes: {{Awareness}}, {{Concerns}}, and {{Platform Accountability}}},
  shorttitle = {Deepfakes},
  author = {Cochran, Justin D. and Napshin, Stuart A.},
  date = {2021-03},
  journaltitle = {Cyberpsychology, Behavior, and Social Networking},
  volume = {24},
  number = {3},
  pages = {164--172},
  publisher = {{Mary Ann Liebert, Inc., publishers}},
  issn = {2152-2715},
  doi = {10.1089/cyber.2020.0100},
  url = {https://www.liebertpub.com/doi/10.1089/cyber.2020.0100},
  urldate = {2023-12-12},
  abstract = {A 61 question survey was used to examine issues around “deepfake” technology. In total, 319 respondents answered questions around awareness, concerns, and the responsibility of online platforms around deepfakes. Awareness of deepfakes varies by intensity and type of social media use. Concerns about deepfakes are pronounced, but not uniform. A regression model examines the factors impacting the perceived responsibility of online platforms to regulate deepfakes. General concerns and the impacts people believe deepfakes will make are significant. However, the more humorous aspects of deepfakes and a perception of individual responsibility negatively impact the perceived need for platforms to address the risks of deepfakes. There is little confidence in the ability of technology to solve the problem of deepfakes, but this does not reduce the desire for online platforms to implement a deepfake identification technology. This research has implications for users of social media, social media platforms, technology developers, and broader society.},
  keywords = {authenticity,deepfake videos,identification technology,platform accountability,social media},
  file = {/Users/dape/Zotero/storage/R7IRESJW/Cochran und Napshin - 2021 - Deepfakes Awareness, Concerns, and Platform Accou.pdf}
}

@online{coleAIAssistedFakePorn2017,
  title = {{{AI-Assisted Fake Porn Is Here}} and {{We}}’re {{All Fucked}}},
  author = {Cole, Samantha},
  date = {2017-12-11T19:18:46},
  url = {https://www.vice.com/en/article/gydydm/gal-gadot-fake-ai-porn},
  urldate = {2023-11-26},
  abstract = {Someone used an algorithm to paste the face of 'Wonder Woman' star Gal Gadot onto a porn video, and the implications are terrifying.},
  langid = {english},
  organization = {{Vice}},
  keywords = {AI,Artificial Intelligence,Face Swap,Face2face,Motherboard,Porn,Tech}
}

@article{DeepfakeQueenDeliver2020,
  entrysubtype = {newspaper},
  title = {Deepfake Queen to Deliver {{Channel}} 4 {{Christmas}} Message},
  date = {2020-12-23},
  journaltitle = {BBC News},
  url = {https://www.bbc.com/news/technology-55424730},
  urldate = {2023-11-29},
  abstract = {Channel 4 will use deepfake technology for its alternative to the traditional Christmas broadcast.},
  journalsubtitle = {Technology},
  langid = {british},
  file = {/Users/dape/Zotero/storage/6MPXR7YV/technology-55424730.html}
}

@article{dobberMicrotargetedDeepfakesHave2021,
  title = {Do ({{Microtargeted}}) {{Deepfakes Have Real Effects}} on {{Political Attitudes}}?},
  author = {Dobber, Tom and Metoui, Nadia and Trilling, Damian and Helberger, Natali and family=Vreese, given=Claes, prefix=de, useprefix=true},
  date = {2021-01-01},
  journaltitle = {The International Journal of Press/Politics},
  volume = {26},
  number = {1},
  pages = {69--91},
  publisher = {{SAGE Publications Inc}},
  issn = {1940-1612},
  doi = {10.1177/1940161220944364},
  url = {https://doi.org/10.1177/1940161220944364},
  urldate = {2023-11-24},
  abstract = {Deepfakes are perceived as a powerful form of disinformation. Although many studies have focused on detecting deepfakes, few have measured their effects on political attitudes, and none have studied microtargeting techniques as an amplifier. We argue that microtargeting techniques can amplify the effects of deepfakes, by enabling malicious political actors to tailor deepfakes to susceptibilities of the receiver. In this study, we have constructed a political deepfake (video and audio), and study its effects on political attitudes in an online experiment (N = 278). We find that attitudes toward the depicted politician are significantly lower after seeing the deepfake, but the attitudes toward the politician’s party remain similar to the control condition. When we zoom in on the microtargeted group, we see that both the attitudes toward the politician and the attitudes toward his party score significantly lower than the control condition, suggesting that microtargeting techniques can indeed amplify the effects of a deepfake, but for a much smaller subgroup than expected.},
  langid = {english},
  file = {/Users/dape/Zotero/storage/LS4MZDLE/Dobber et al. - 2021 - Do (Microtargeted) Deepfakes Have Real Effects on .pdf}
}

@online{dwdl.deSpringerTrommeltMit,
  title = {Springer Trommelt Mit {{KI-Scholz}} Für Die "{{Bild}}"-{{Zeitung}}},
  author = {family=DWDL.de, given=DWDL, given-i=DWDL, prefix=de, useprefix=false},
  url = {https://www.dwdl.de/nachrichten/95358/springer_trommelt_mit_kischolz_fuer_die_bildzeitung/},
  urldate = {2023-11-27},
  abstract = {Unter dem Motto "Bild bleibt Bild" hat Axel Springer eine umfassende Kampagne für seine Boulevardzeitung aufgesetzt. Mit dabei sind Augenzwinker-Motive, aber auch ein KI-generierter Bundeskanzler, der für das Versprechen der Zeitung wirbt.},
  langid = {english},
  organization = {{DWDL.de}},
  file = {/Users/dape/Zotero/storage/4TV7GH4Y/springer_trommelt_mit_kischolz_fuer_die_bildzeitung.html}
}

@online{elevenlabsAISpeechClassifier,
  title = {{{AI Speech Classifier}} - {{AI Voice Cloning Detector}}},
  author = {Elevenlabs},
  url = {https://elevenlabs.io/ai-speech-classifier},
  urldate = {2023-11-27},
  file = {/Users/dape/Zotero/storage/2UPF8A89/ai-speech-classifier.html}
}

@software{erenCoquiTTS2021,
  title = {Coqui {{TTS}}},
  author = {Eren, Gölge and {The Coqui TTS Team}},
  date = {2021-01},
  doi = {10.5281/zenodo.6334862},
  url = {https://github.com/coqui-ai/TTS},
  urldate = {2023-12-09},
  abstract = {🐸💬 - a deep learning toolkit for Text-to-Speech, battle-tested in research and production},
  version = {1.4}
}

@article{etienneFutureOnlineTrust2021,
  title = {The Future of Online Trust (and Why {{Deepfake}} Is Advancing It)},
  author = {Etienne, Hubert},
  date = {2021-11-01},
  journaltitle = {AI and Ethics},
  shortjournal = {AI Ethics},
  volume = {1},
  number = {4},
  pages = {553--562},
  issn = {2730-5961},
  doi = {10.1007/s43681-021-00072-1},
  url = {https://doi.org/10.1007/s43681-021-00072-1},
  urldate = {2023-11-28},
  abstract = {Trust has become a first-order concept in AI, urging experts to call for measures ensuring AI is ‘trustworthy’. The danger of untrustworthy AI often culminates with Deepfake, perceived as unprecedented threat for democracies and online trust, through its potential to back sophisticated disinformation campaigns. Little work has, however, been dedicated to the examination of the concept of trust, what undermines the arguments supporting such initiatives. By investigating the concept of trust and its evolutions, this paper ultimately defends a non-intuitive position: Deepfake is not only incapable of contributing to such an end, but also offers a unique opportunity to transition towards a framework of social trust better suited for the challenges entailed by the digital age. Discussing the dilemmas traditional societies had to overcome to establish social trust and the evolution of their solution across modernity, I come to reject rational choice theories to model trust and to distinguish an ‘instrumental rationality’ and a ‘social rationality’. This allows me to refute the argument which holds Deepfake to be a threat to online trust. In contrast, I argue that Deepfake may even support a transition from instrumental to social rationality, better suited for making decisions in the digital age.},
  langid = {english},
  keywords = {AI ethics,Deepfake,Disinformation,Fake news,Trust},
  file = {/Users/dape/Zotero/storage/39HGEC5R/Etienne - 2021 - The future of online trust (and why Deepfake is ad.pdf}
}

@article{fengExaminingImpactProvenanceEnabled2023,
  title = {Examining the {{Impact}} of {{Provenance-Enabled Media}} on {{Trust}} and {{Accuracy Perceptions}}},
  author = {Feng, K. J. Kevin and Ritchie, Nick and Blumenthal, Pia and Parsons, Andy and Zhang, Amy X.},
  date = {2023-09-28},
  journaltitle = {Proceedings of the ACM on Human-Computer Interaction},
  shortjournal = {Proc. ACM Hum.-Comput. Interact.},
  volume = {7},
  pages = {1--42},
  issn = {2573-0142},
  doi = {10.1145/3610061},
  url = {https://dl.acm.org/doi/10.1145/3610061},
  urldate = {2023-11-24},
  abstract = {In recent years, industry leaders and researchers have proposed to use technical provenance standards to address visual misinformation spread through digitally altered media. By adding immutable and secure provenance information such as authorship and edit date to media metadata, social media users could potentially better assess the validity of the media they encounter. However, it is unclear how end users would respond to provenance information, or how to best design provenance indicators to be understandable to laypeople. We conducted an online experiment with 595 participants from the US and UK to investigate how provenance information altered users' accuracy perceptions and trust in visual content shared on social media. We found that provenance information often lowered trust and caused users to doubt deceptive media, particularly when it revealed that the media was composited. We additionally tested conditions where the provenance information itself was shown to be incomplete or invalid, and found that these states have a significant impact on participants' accuracy perceptions and trust in media, leading them, in some cases, to disbelieve honest media. Our findings show that provenance, although enlightening, is still not a concept well-understood by users, who confuse media credibility with the orthogonal (albeit related) concept of provenance credibility. We discuss how design choices may contribute to provenance (mis)understanding, and conclude with implications for usable provenance systems, including clearer interfaces and user education.},
  issue = {CSCW2},
  langid = {english},
  file = {/Users/dape/Zotero/storage/D86XEQWY/Feng et al. - 2023 - Examining the Impact of Provenance-Enabled Media o.pdf}
}

@incollection{flasinskiHistoryArtificialIntelligence2016,
  title = {History of {{Artificial Intelligence}}},
  booktitle = {Introduction to {{Artificial Intelligence}}},
  author = {Flasiński, Mariusz},
  editor = {Flasiński, Mariusz},
  date = {2016},
  pages = {3--13},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-319-40022-8_1},
  url = {https://doi.org/10.1007/978-3-319-40022-8_1},
  urldate = {2023-12-04},
  abstract = {Many fundamental methodological issues of Artificial Intelligence have been of great importance in philosophy since ancient times. Such philosophers as Aristotle, St. Thomas Aquinas, William of Ockham, René Descartes, Thomas Hobbes, and Gottfried W. Leibniz have asked the questions: “What are basic cognitive operations?”, “What necessary conditions should a (formal) language fulfill in order to be an adequate tool for describing the world in a precise and unambiguous way?”, “Can reasoning be automatized?”.},
  isbn = {978-3-319-40022-8},
  langid = {english},
  keywords = {Chinese Character,Cognitive Architecture,Generative Grammar,Knowledge Representation,Natural Language Processing},
  file = {/Users/dape/Zotero/storage/JIJC63FS/Flasiński - 2016 - History of Artificial Intelligence.pdf}
}

@online{foongIntroductionControlNetStable2023,
  title = {Introduction to {{ControlNet}} for {{Stable Diffusion}}},
  author = {Foong, Ng Wai},
  date = {2023-03-29T07:55:45},
  url = {https://ngwaifoong92.medium.com/introduction-to-controlnet-for-stable-diffusion-ea83e77f086e},
  urldate = {2023-12-28},
  abstract = {Better control for text-to-image generation},
  langid = {english},
  organization = {{Medium}},
  file = {/Users/dape/Zotero/storage/ELRNHWSF/introduction-to-controlnet-for-stable-diffusion-ea83e77f086e.html}
}

@article{franksSexLiesVideotape2018,
  title = {Sex, {{Lies}}, and {{Videotape}}: {{Deep Fakes}} and {{Free Speech Delusions}}},
  shorttitle = {Sex, {{Lies}}, and {{Videotape}}},
  author = {Franks, Mary Anne and Waldman, Ari Ezra},
  date = {2018/2019},
  journaltitle = {Maryland Law Review},
  shortjournal = {Md. L. Rev.},
  volume = {78},
  pages = {892},
  url = {https://heinonline.org/HOL/Page?handle=hein.journals/mllr78&id=916&div=&collection=},
  file = {/Users/dape/Zotero/storage/JHTGBU5X/Franks und Waldman - Sex, Lies, and Videotape Deep Fakes and Free Spee.pdf;/Users/dape/Zotero/storage/N5AXU99W/LandingPage.html}
}

@article{garcia-penalvoWhatWeMean2023,
  title = {What {{Do We Mean}} by {{GenAI}}? {{A Systematic Mapping}} of {{The Evolution}}, {{Trends}}, and {{Techniques Involved}} in {{Generative AI}}},
  shorttitle = {What {{Do We Mean}} by {{GenAI}}?},
  author = {García-Peñalvo, Francisco and Vázquez-Ingelmo, Andrea},
  date = {2023-07},
  publisher = {{International Journal of Interactive Multimedia and Artificial Intelligence}},
  issn = {1989-1660},
  doi = {10.9781/ijimai.2023.07.006},
  url = {https://reunir.unir.net/handle/123456789/15134},
  urldate = {2023-12-04},
  abstract = {Artificial Intelligence has become a focal point of interest across various sectors due to its ability to generate creative and realistic outputs. A specific subset, generative artificial intelligence, has seen significant growth, particularly in late 2022. Tools like ChatGPT, Dall-E, or Midjourney have democratized access to Large Language Models, enabling the creation of human-like content. However, the concept 'Generative Artificial Intelligence lacks a universally accepted definition, leading to potential misunderstandings. While a model that produces any output can be technically seen as generative, the Artificial Intelligent research community often reserves the term for complex models that generate high-quality, human-like material. This paper presents a literature mapping of AI-driven content generation, analyzing 631 solutions published over the last five years to better understand and characterize the Generative Artificial Intelligence landscape. Our findings suggest a dichotomy in the understanding and application of the term "Generative AI". While the broader public often interprets "Generative AI" as AI-driven creation of tangible content, the AI research community mainly discusses generative implementations with an emphasis on the models in use, without explicitly categorizing their work under the term "Generative AI".},
  langid = {english},
  annotation = {Accepted: 2023-08-28T12:17:56Z},
  file = {/Users/dape/Zotero/storage/DMAQMAND/García-Peñalvo und Vázquez-Ingelmo - 2023 - What Do We Mean by GenAI A Systematic Mapping of .pdf}
}

@article{garryActuallyPictureWorth2005,
  title = {Actually, a Picture Is Worth Less than 45 Words: {{Narratives}} Produce More False Memories than Photographs Do},
  shorttitle = {Actually, a Picture Is Worth Less than 45 Words},
  author = {Garry, Maryanne and Wade, Kimberley A.},
  date = {2005-04-01},
  journaltitle = {Psychonomic Bulletin \& Review},
  shortjournal = {Psychonomic Bulletin \& Review},
  volume = {12},
  number = {2},
  pages = {359--366},
  issn = {1531-5320},
  doi = {10.3758/BF03196385},
  url = {https://doi.org/10.3758/BF03196385},
  urldate = {2023-12-12},
  abstract = {Most memory “implantation” studies have elicited false memories by using fake narratives. Recently, Wade, Garry, Read, and Lindsay (2002) showed that doctored photographs can be used to create false childhood memories in adults. Fifty percent of Wade et al.’s sample reported details of taking a childhood hot air balloon ride, although they had never been in a balloon. In this experiment, we investigated whether photos or narratives influence memory more than the other. We exposed subjects to either a fake photograph or a fake narrative of a childhood hot air balloon ride. Subjects tried to remember the false event and three real events over 1 week. Narratives were more likely to produce false memory reports than were photos. We offer a fluency-based account of our results and suggest that narratives promote more familiarity in subjects than do photographs.},
  langid = {english},
  keywords = {Autobiographical Memory,False Event,False Memory,Memory Category,Narrative Group},
  file = {/Users/dape/Zotero/storage/PLBKDMNU/Garry und Wade - 2005 - Actually, a picture is worth less than 45 words N.pdf}
}

@article{gmComprehensiveSurveyAnalysis2020,
  title = {A Comprehensive Survey and Analysis of Generative Models in Machine Learning},
  author = {Gm, Harshvardhan and Gourisaria, Mahendra Kumar and Pandey, Manjusha and Rautaray, Siddharth Swarup},
  date = {2020-11-01},
  journaltitle = {Computer Science Review},
  shortjournal = {Computer Science Review},
  volume = {38},
  pages = {100285},
  issn = {1574-0137},
  doi = {10.1016/j.cosrev.2020.100285},
  url = {https://www.sciencedirect.com/science/article/pii/S1574013720303853},
  urldate = {2023-12-04},
  abstract = {Generative models have been in existence for many decades. In the field of machine learning, we come across many scenarios when directly learning a target is intractable through discriminative models, and in such cases the joint distribution of the target and the training data is approximated and generated. These generative models help us better represent or model a set of data by generating data in the form of Markov chains or simply employing a generative iterative process to do the same. With the recent innovation of Generative Adversarial Networks (GANs), it is now possible to make use of AI to generate pieces of art, music, etc. with a high extent of realism. In this paper, we review and analyse critically all the generative models, namely Gaussian Mixture Models (GMM), Hidden Markov Models (HMM), Latent Dirichlet Allocation (LDA), Restricted Boltzmann Machines (RBM), Deep Belief Networks (DBN), Deep Boltzmann Machines (DBM), and GANs. We study their algorithms and implement each of the models to provide the reader some insights on which generative model to pick from while dealing with a problem. We also provide some noteworthy contributions done in the past to these models from the literature.},
  keywords = {Bayesian inference,Deep learning,Generative models,Machine learning,Neural networks},
  file = {/Users/dape/Zotero/storage/I4NV3WWE/S1574013720303853.html}
}

@online{googletrendsGoogleTrendsQuery,
  title = {Google Trends query: "generative AI" December 2017-2023},
  author = {Google Trends},
  url = {https://trends.google.com/trends/explore?date=2017-05-11%202023-12-05&q=generative%20AI&hl=de},
  urldate = {2023-12-05},
  abstract = {Suchinteresse für "generative AI" nach Zeitraum, Ort und Beliebtheit bei Google Trends erkunden},
  langid = {ngerman},
  organization = {{Google Trends}},
  file = {/Users/dape/Zotero/storage/EB2V6LXU/explore.html}
}

@online{googletrendsGoogleTrendsQuerya,
  title = {Google Trends query: "Deep Fakes" December 2017-2023},
  author = {Google Trends},
  url = {https://trends.google.com/trends/explore?date=2017-05-11%202023-12-05&q=Deep%20Fakes&hl=de},
  urldate = {2023-12-05},
  abstract = {Suchinteresse für "Deepfake" nach Zeitraum, Ort und Beliebtheit bei Google Trends erkunden},
  langid = {ngerman},
  organization = {{Google Trends}},
  file = {/Users/dape/Zotero/storage/TELHFC6U/explore.html}
}

@report{guessSelectiveExposureMisinformation2018,
  type = {Report},
  title = {Selective Exposure to Misinformation: {{Evidence}} from the Consumption of Fake News during the 2016 {{U}}.{{S}}. Presidential Campaign},
  shorttitle = {Selective Exposure to Misinformation},
  author = {Guess, Andrew and Nyhan, Brendan and Reifler, Jason},
  date = {2018-01-08},
  institution = {{Dartmouth College}},
  url = {https://apo.org.au/node/126961},
  urldate = {2023-12-14},
  abstract = {This research report has been promoted as~the first scientific, data-based study of Americans’ exposure to fake news in the month surrounding the 2016 U.S. election.},
  langid = {english},
  file = {/Users/dape/Zotero/storage/NGUH44H9/Guess et al. - 2018 - Selective exposure to misinformation Evidence fro.pdf}
}

@online{guMediumVCAnytoanyVoice2021,
  title = {{{MediumVC}}: {{Any-to-any}} Voice Conversion Using Synthetic Specific-Speaker Speeches as Intermedium Features},
  shorttitle = {{{MediumVC}}},
  author = {Gu, Yewei and Zhang, Zhenyu and Yi, Xiaowei and Zhao, Xianfeng},
  date = {2021-10-06},
  eprint = {2110.02500},
  eprinttype = {arxiv},
  eprintclass = {eess},
  doi = {10.48550/arXiv.2110.02500},
  url = {http://arxiv.org/abs/2110.02500},
  urldate = {2023-12-09},
  abstract = {To realize any-to-any (A2A) voice conversion (VC), most methods are to perform symmetric self-supervised reconstruction tasks (Xi to Xi), which usually results in inefficient performances due to inadequate feature decoupling, especially for unseen speakers. We propose a two-stage reconstruction task (Xi to Yi to Xi) using synthetic specific-speaker speeches as intermedium features, where A2A VC is divided into two stages: any-to-one (A2O) and one-to-Any (O2A). In the A2O stage, we propose a new A2O method: SingleVC, by employing a noval data augment strategy(pitch-shifted and duration-remained, PSDR) to accomplish Xi to Yi. In the O2A stage, MediumVC is proposed based on pre-trained SingleVC to conduct Yi to Xi. Through such asymmetrical reconstruction tasks (Xi to Yi in SingleVC and Yi to Xi in MediumVC), the models are to capture robust disentangled features purposefully. Experiments indicate MediumVC can enhance the similarity of converted speeches while maintaining a high degree of naturalness.},
  pubstate = {preprint},
  keywords = {Electrical Engineering and Systems Science - Audio and Speech Processing},
  file = {/Users/dape/Zotero/storage/MRDLAX9C/Gu et al. - 2021 - MediumVC Any-to-any voice conversion using synthe.pdf;/Users/dape/Zotero/storage/DCHSDWII/2110.html}
}

@inproceedings{guptaGeneratingUltraHighResolution2023,
  title = {Towards {{Generating Ultra-High Resolution Talking-Face Videos}} with {{Lip}} Synchronization},
  booktitle = {2023 {{IEEE}}/{{CVF Winter Conference}} on {{Applications}} of {{Computer Vision}} ({{WACV}})},
  author = {Gupta, Anchit and Mukhopadhyay, Rudrabha and Balachandra, Sindhu and Khan, Faizan Farooq and Namboodiri, Vinay P. and Jawahar, C. V.},
  date = {2023-01},
  pages = {5198--5207},
  publisher = {{IEEE}},
  location = {{Waikoloa, HI, USA}},
  doi = {10.1109/WACV56688.2023.00518},
  url = {https://ieeexplore.ieee.org/document/10030232/},
  urldate = {2023-12-08},
  eventtitle = {2023 {{IEEE}}/{{CVF Winter Conference}} on {{Applications}} of {{Computer Vision}} ({{WACV}})},
  isbn = {978-1-66549-346-8},
  langid = {english},
  file = {/Users/dape/Zotero/storage/9H6NQNVV/Gupta et al. - 2023 - Towards Generating Ultra-High Resolution Talking-F.pdf}
}

@article{haenleinBriefHistoryArtificial2019,
  title = {A {{Brief History}} of {{Artificial Intelligence}}: {{On}} the {{Past}}, {{Present}}, and {{Future}} of {{Artificial Intelligence}}},
  shorttitle = {A {{Brief History}} of {{Artificial Intelligence}}},
  author = {Haenlein, Michael and Kaplan, Andreas},
  date = {2019-08-01},
  journaltitle = {California Management Review},
  volume = {61},
  number = {4},
  pages = {5--14},
  publisher = {{SAGE Publications Inc}},
  issn = {0008-1256},
  doi = {10.1177/0008125619864925},
  url = {https://doi.org/10.1177/0008125619864925},
  urldate = {2023-12-04},
  abstract = {This introduction to this special issue discusses artificial intelligence (AI), commonly defined as “a system’s ability to interpret external data correctly, to learn from such data, and to use those learnings to achieve specific goals and tasks through flexible adaptation.” It summarizes seven articles published in this special issue that present a wide variety of perspectives on AI, authored by several of the world’s leading experts and specialists in AI. It concludes by offering a comprehensive outlook on the future of AI, drawing on micro-, meso-, and macro-perspectives.},
  langid = {english},
  file = {/Users/dape/Zotero/storage/65UHJUMN/Haenlein und Kaplan - 2019 - A Brief History of Artificial Intelligence On the.pdf}
}

@article{hancockSeeNoEvil2010,
  title = {See {{No Evil}}: {{The Effect}} of {{Communication Medium}} and {{Motivation}} on {{Deception Detection}}},
  shorttitle = {See {{No Evil}}},
  author = {Hancock, Jeffrey T. and Woodworth, Michael T. and Goorha, Saurabh},
  date = {2010-07-01},
  journaltitle = {Group Decision and Negotiation},
  shortjournal = {Group Decis Negot},
  volume = {19},
  number = {4},
  pages = {327--343},
  issn = {1572-9907},
  doi = {10.1007/s10726-009-9169-7},
  url = {https://doi.org/10.1007/s10726-009-9169-7},
  urldate = {2023-12-12},
  abstract = {The present study reports an experiment that examines the role of communication medium and liar motivation on deception detection. Participants were randomly assigned to one of two dyadic communication conditions, text-based, computer-mediated environment or face-to-face, and to one of two motivation conditions, high or low. Participants engaged in a discussion of four topics, in which one participant was deceptive during two topics and truthful during the other two. No main effect of communication medium or motivation level was observed. However, an interaction effect suggests that highly motivated liars interacting in a text-based, computer- mediated environment were the most successful in deceiving their partners. The implications of these results are discussed both in terms of the elimination of non- verbal cues, as well as the potential advantages to the motivated liar offered by text-based media.},
  langid = {english},
  keywords = {Computer-mediated communication,Deception,Deception detection,Interpersonal communication,Lying,Motivation},
  file = {/Users/dape/Zotero/storage/JZ3MWQ47/Hancock et al. - 2010 - See No Evil The Effect of Communication Medium an.pdf}
}

@article{hancockSocialImpactDeepfakes2021,
  title = {The {{Social Impact}} of {{Deepfakes}}},
  author = {Hancock, Jeffrey T. and Bailenson, Jeremy N.},
  date = {2021-03},
  journaltitle = {Cyberpsychology, Behavior, and Social Networking},
  volume = {24},
  number = {3},
  pages = {149--152},
  publisher = {{Mary Ann Liebert, Inc., publishers}},
  issn = {2152-2715},
  doi = {10.1089/cyber.2021.29208.jth},
  url = {https://www.liebertpub.com/doi/full/10.1089/cyber.2021.29208.jth},
  urldate = {2023-11-24},
  file = {/Users/dape/Zotero/storage/55AVKSZ8/Hancock und Bailenson - 2021 - The Social Impact of Deepfakes.pdf}
}

@software{harperEndtoEndToolkitVoice2023,
  title = {An {{End-to-End Toolkit}} for {{Voice Datasets}}},
  author = {Harper, Rio},
  date = {2023-12-20T04:18:14Z},
  origdate = {2023-01-11T21:14:18Z},
  url = {https://github.com/rioharper/VocalForge},
  urldate = {2023-12-22},
  abstract = {Your one-stop solution for voice dataset creation},
  keywords = {artificial-intelligence,audio,audio-processing,dataset,dataset-generation,python,speech-recognition,speech-to-text,toolkit}
}

@article{heiselbergAutomatedNewsReading2022,
  title = {Automated {{News Reading}} in the {{Neural Age}}: {{Audience Reception}} and {{Perceived Credibility}} of a {{News Broadcast Read By}} a {{Neural Voice}}},
  shorttitle = {Automated {{News Reading}} in the {{Neural Age}}},
  author = {Heiselberg, L. and Blom, J. N. and family=Dalen, given=A., prefix=van, useprefix=true},
  date = {2022-06-11},
  journaltitle = {Journalism Studies},
  volume = {23},
  number = {8},
  pages = {896--914},
  publisher = {{Routledge}},
  issn = {1461-670X},
  doi = {10.1080/1461670X.2022.2052346},
  url = {https://doi.org/10.1080/1461670X.2022.2052346},
  urldate = {2023-11-23},
  abstract = {Automated journalism is rapidly developing in the news industry. Among the most recent and promising technological potentials are neural voices, i.e., text-to-speech technology powered by neural networks. Based on a reception analysis with in-depth qualitative interviews (N = 12), this study explores how Danish radio listeners receive a full news broadcast read by a neural voice and perceive the credibility of the neural reader and the news content. Results show that the participants divide into two types: the perspicacious listeners who realize or suspect that the news reading is artificially synthesized and, to some degree, are annoyed by it, and the oblivious listeners who believe the news is read by a human and are predominantly positive towards it. Participants from both groups pay particular attention to voice emotionality when evaluating the appropriateness of the neural news reader. Also, they tend to attribute human characteristics to the neural news reader. The participants single out the news messages as well as the media organization behind the news broadcast, rather than the neural voice itself as critical components constituting credibility. Transparency is of great importance when applying a neural voice in a news broadcast, since it is a prerequisite for credibility.},
  keywords = {anthropomorphism,automated journalism,credibility,Eliza effect,neural voices,Text-to-speech (TTS)},
  file = {/Users/dape/Zotero/storage/LXFGMYET/Heiselberg et al. - 2022 - Automated News Reading in the Neural Age Audience.pdf}
}

@inproceedings{higginsAscendingValleyCan2021,
  title = {Ascending from the Valley: {{Can}} State-of-the-Art Photorealism Avoid the Uncanny?},
  shorttitle = {Ascending from the Valley},
  booktitle = {{{ACM Symposium}} on {{Applied Perception}} 2021},
  author = {Higgins, Darragh and Egan, Donal and Fribourg, Rebecca and Cowan, Benjamin and McDonnell, Rachel},
  date = {2021-09-16},
  pages = {1--5},
  publisher = {{ACM}},
  location = {{Virtual Event France}},
  doi = {10.1145/3474451.3476242},
  url = {https://dl.acm.org/doi/10.1145/3474451.3476242},
  urldate = {2023-11-23},
  eventtitle = {{{SAP}} '21: {{ACM Symposium}} on {{Applied Perception}} 2021},
  isbn = {978-1-4503-8663-0},
  langid = {english},
  file = {/Users/dape/Zotero/storage/FQW8KTRW/Higgins et al. - 2021 - Ascending from the valley Can state-of-the-art ph.pdf}
}

@article{higginsSympathyDigitalInfluence2022,
  title = {Sympathy for the Digital: {{Influence}} of Synthetic Voice on Affinity, Social Presence and Empathy for Photorealistic Virtual Humans},
  shorttitle = {Sympathy for the Digital},
  author = {Higgins, Darragh and Zibrek, Katja and Cabral, Joao and Egan, Donal and McDonnell, Rachel},
  date = {2022-05-01},
  journaltitle = {Computers \& Graphics},
  shortjournal = {Computers \& Graphics},
  volume = {104},
  pages = {116--128},
  issn = {0097-8493},
  doi = {10.1016/j.cag.2022.03.009},
  url = {https://www.sciencedirect.com/science/article/pii/S0097849322000474},
  urldate = {2023-11-24},
  abstract = {In this paper, we investigate the effect of a realism mismatch in the voice and appearance of a photorealistic virtual character in both immersive and screen-mediated virtual contexts. While many studies have investigated voice attributes for robots, not much is known about the effect voice naturalness has on the perception of realistic virtual characters. We conducted the first experiment in Virtual Reality (VR) with over two hundred participants investigating the mismatch between realistic appearance and unrealistic voice on the feeling of presence, and the emotional response of the user to the character expressing a strong negative emotion. We predicted that the mismatched voice would lower social presence and cause users to have a negative emotional reaction and feelings of discomfort towards the character. We found that the concern for the virtual character was indeed altered by the unnatural voice, though interestingly it did not affect social presence. The second experiment was conducted with a view towards heightening the appearance realism of the same character for the same scenarios, with an additional lower level of voice realism employed to strengthen the mismatch of perceptual cues. While voice type did not appear to impact reports of empathic responses towards the character, there was an observed effect of voice realism on reported social presence, which was not detected in the first study. There were also significant results on affinity and voice trait measurements that provide evidence in support of perceptual mismatch theories of the Uncanny Valley.},
  keywords = {Perception,Synthetic voice,Virtual humans,Virtual reality},
  file = {/Users/dape/Zotero/storage/IBNESBY6/Higgins et al. - 2022 - Sympathy for the digital Influence of synthetic v.pdf;/Users/dape/Zotero/storage/Q3WZIMU2/S0097849322000474.html}
}

@article{hodgePhraseCompletionScales2007,
  title = {Phrase {{Completion Scales}}},
  author = {Hodge, David R. and Gillespie, David},
  date = {2007-06-22},
  journaltitle = {Journal of Social Service Research},
  shortjournal = {Journal of Social Service Research},
  volume = {33},
  pages = {1--12},
  doi = {10.1300/J079v33n04_01},
  abstract = {Valid and reliable measures are fundamental to advancing social science. Phrase completion scales were designed to provide enhanced psychometrics compared to Likert scales by more closely conforming to foundational measurement and statistical assumptions. This article tests the two approaches by examining responses (N = 134) to items formatted using the Likert approach with comparable items formatted using the phrase completion approach. An assessment of the written comments, Cronbach's alphas, inter-item correlations, factor scores, and SEM coefficients suggested that items constructed in the phrase completion format may yield higher validity and reliability relative to Likert constructed items. The advantages of phrase completion scales may be particularly pronounced when measuring attitudes that fall at all points along the underlying attitudinal continuum.},
  file = {/Users/dape/Zotero/storage/I3RGFZPY/Hodge und Gillespie - 2007 - Phrase Completion Scales.pdf}
}

@article{hwangEffectsDisinformationUsing2021,
  title = {Effects of {{Disinformation Using Deepfake}}: {{The Protective Effect}} of {{Media Literacy Education}}},
  shorttitle = {Effects of {{Disinformation Using Deepfake}}},
  author = {Hwang, Yoori and Ryu, Ji Youn and Jeong, Se-Hoon},
  date = {2021-03},
  journaltitle = {Cyberpsychology, Behavior, and Social Networking},
  volume = {24},
  number = {3},
  pages = {188--193},
  publisher = {{Mary Ann Liebert, Inc., publishers}},
  issn = {2152-2715},
  doi = {10.1089/cyber.2020.0174},
  url = {https://www.liebertpub.com/doi/10.1089/cyber.2020.0174},
  urldate = {2023-12-12},
  abstract = {This research examines (a) the negative impact of disinformation including a deepfake video and (b) the protective effect of media literacy education. We conducted an experiment using a two disinformation message type (deepfake video present vs. absent) by three media literacy education (general disinformation vs. deepfake-specific vs. no literacy) factorial design. In the general disinformation (vs. deepfake-specific) literacy condition, participants were informed about (a) the definition of disinformation (vs. deepfake), (b) some examples of disinformation (vs. deepfake), and (c) the social consequences of disinformation (vs. deepfake). Results showed that disinformation messages including a deepfake video resulted in greater vividness, persuasiveness, credibility, and intent to share the message. Media literacy education reduced the effects of disinformation messages.},
  keywords = {deepfake,disinformation,media literacy,visual},
  file = {/Users/dape/Zotero/storage/BAALQTD3/Hwang et al. - 2021 - Effects of Disinformation Using Deepfake The Prot.pdf}
}

@article{iacobucciDeepfakesUnmaskedEffects2021,
  title = {Deepfakes {{Unmasked}}: {{The Effects}} of {{Information Priming}} and {{Bullshit Receptivity}} on {{Deepfake Recognition}} and {{Sharing Intention}}},
  shorttitle = {Deepfakes {{Unmasked}}},
  author = {Iacobucci, Serena and De Cicco, Roberta and Michetti, Francesca and Palumbo, Riccardo and Pagliaro, Stefano},
  date = {2021-03},
  journaltitle = {Cyberpsychology, Behavior, and Social Networking},
  volume = {24},
  number = {3},
  pages = {194--202},
  publisher = {{Mary Ann Liebert, Inc., publishers}},
  issn = {2152-2715},
  doi = {10.1089/cyber.2020.0149},
  url = {https://www.liebertpub.com/doi/10.1089/cyber.2020.0149},
  urldate = {2023-12-12},
  abstract = {The study aims to test whether simple priming of deepfake (DF) information significantly increases users' ability to recognize DF media. Although undoubtedly fascinating from a technological point of view, these highly realistic artificial intelligent (AI)-generated fake videos hold high deceptive potential. Both practitioners and institutions are thus joining forces to develop debunking strategies to counter the spread of such difficult-to-recognize and potentially misleading video content. On this premise, this study addresses the following research questions: does simple priming with the definition of DFs and information about their potentially harmful applications increase users' ability to recognize DFs? Does bullshit receptivity, as an individual tendency to be overly accepting of epistemically suspect beliefs, moderate the relationship between such priming and DF recognition? Results indicate that the development of strategies to counter the deceitfulness of DFs from an educational and cultural perspective might work well, but only for people with a lower susceptibility to believe willfully misleading claims. Finally, through a serial mediation analysis, we show that DF recognition does, in turn, negatively impact users' sharing intention, thus limiting the potential harm of DFs at the very root of one of their strengths: virality. We discuss the implications of our finding that society's defense against DFs could benefit from a simple reasoned digital literacy intervention.},
  keywords = {bullshit receptivity,deception,deepfake,sharing intention},
  file = {/Users/dape/Zotero/storage/RG7RNKL6/Iacobucci et al. - 2021 - Deepfakes Unmasked The Effects of Information Pri.pdf}
}

@online{insightfaceInsightFaceWebsite,
  title = {{{InsightFace Website}}},
  author = {InsightFace},
  url = {https://insightface.ai/},
  urldate = {2023-12-06},
  abstract = {InsightFace: an open source 2D\&3D deep face analysis library},
  langid = {english},
  file = {/Users/dape/Zotero/storage/3UWZ8QFC/insightface.ai.html}
}

@online{iperovCommitsIperovDeepFaceLab,
  title = {Commits · Iperov/{{DeepFaceLab}}},
  author = {{iperov}},
  url = {https://github.com/iperov/DeepFaceLab/commits/master?after=46fc2397c582b9fc375a023418257924112e292b+1294&branch=master&qualified_name=refs%2Fheads%2Fmaster},
  urldate = {2023-12-06},
  file = {/Users/dape/Zotero/storage/BK8XGJB6/master.html}
}

@online{jayashankarSelfSupervisedRepresentationsSinging2023,
  title = {Self-{{Supervised Representations}} for {{Singing Voice Conversion}}},
  author = {Jayashankar, Tejas and Wu, Jilong and Sari, Leda and Kant, David and Manohar, Vimal and He, Qing},
  date = {2023-03-21},
  eprint = {2303.12197},
  eprinttype = {arxiv},
  eprintclass = {eess},
  doi = {10.48550/arXiv.2303.12197},
  url = {http://arxiv.org/abs/2303.12197},
  urldate = {2023-11-24},
  abstract = {A singing voice conversion model converts a song in the voice of an arbitrary source singer to the voice of a target singer. Recently, methods that leverage self-supervised audio representations such as HuBERT and Wav2Vec 2.0 have helped further the state-of-the-art. Though these methods produce more natural and melodic singing outputs, they often rely on confusion and disentanglement losses to render the self-supervised representations speaker and pitch-invariant. In this paper, we circumvent disentanglement training and propose a new model that leverages ASR fine-tuned self-supervised representations as inputs to a HiFi-GAN neural vocoder for singing voice conversion. We experiment with different f0 encoding schemes and show that an f0 harmonic generation module that uses a parallel bank of transposed convolutions (PBTC) alongside ASR fine-tuned Wav2Vec 2.0 features results in the best singing voice conversion quality. Additionally, the model is capable of making a spoken voice sing. We also show that a simple f0 shifting scheme during inference helps retain singer identity and bolsters the performance of our singing voice conversion model. Our results are backed up by extensive MOS studies that compare different ablations and baselines.},
  pubstate = {preprint},
  keywords = {Electrical Engineering and Systems Science - Audio and Speech Processing},
  file = {/Users/dape/Zotero/storage/DXANKNWJ/Jayashankar et al. - 2023 - Self-Supervised Representations for Singing Voice .pdf;/Users/dape/Zotero/storage/I8DDZPGP/2303.html}
}

@online{jemineGitHubCorentinJRealTimeVoiceCloning,
  title = {{{GitHub}} - {{CorentinJ}}/{{Real-Time-Voice-Cloning}}: {{Clone}} a Voice in 5 Seconds to Generate Arbitrary Speech in Real-Time},
  author = {Jemine, Corentin},
  url = {https://github.com/CorentinJ/Real-Time-Voice-Cloning},
  urldate = {2023-12-22},
  file = {/Users/dape/Zotero/storage/4YWYHHQG/Real-Time-Voice-Cloning.html}
}

@article{jemineRealTimeVoiceCloning2019,
  title = {Real-{{Time Voice Cloning}}},
  author = {Jemine, Corentin},
  date = {2019-06-25T22:00:00Z},
  publisher = {{Université de Liège, Liège, Belgique}},
  url = {https://matheo.uliege.be/handle/2268.2/6801},
  urldate = {2023-12-22},
  abstract = {Recent advances in deep learning have shown impressive results in the domain of text-to-speech. To this end, a deep neural network is usually trained using a corpus of several hours of professionally recorded speech from a single speaker. Giving a new voice to such a model is highly expensive, as it requires recording a new dataset and retraining the model. A recent research introduced a three-stage pipeline that allows to clone a voice unseen during training from only a few seconds of reference speech, and without retraining the model. The authors share remarkably natural-sounding results, but provide no implementation. We reproduce this framework and open-source the first public implementation of it. We adapt the framework with a newer vocoder model, so as to make it run in real-time.},
  langid = {english},
  annotation = {Accepted: 2019-07-04T02:06:24Z},
  file = {/Users/dape/Zotero/storage/KKJL9QFH/Jemine und Info - 2019 - Real-Time Voice Cloning.pdf}
}

@article{jinAssessingPerceivedCredibility2023a,
  title = {Assessing the Perceived Credibility of Deepfakes: {{The}} Impact of System-Generated Cues and Video Characteristics},
  shorttitle = {Assessing the Perceived Credibility of Deepfakes},
  author = {Jin, Xinyi and Zhang, Zhuoyue and Gao, Bowen and Gao, Shuqing and Zhou, Wenbo and Yu, Nenghai and Wang, Guoyan},
  date = {2023-09-25},
  journaltitle = {New Media \& Society},
  pages = {14614448231199664},
  publisher = {{SAGE Publications}},
  issn = {1461-4448},
  doi = {10.1177/14614448231199664},
  url = {https://doi.org/10.1177/14614448231199664},
  urldate = {2023-11-24},
  abstract = {The adverse effects of deepfakes are becoming apparent; however, less is known about what affects individuals’ credibility judgments concerning deepfakes. This article conducted two randomized controlled 2\,×\,2\,×\,2 experiments (N\,=\,518) to explore the influence of heuristic cues (including the number of followers, popularity, and description as variables) generated by the system and video characteristics (including definition, duration, and editing as variables). The results suggest that the number of the source’s followers and the video’s popularity are positively associated with perceived credibility. Moreover, high-definition deepfakes are more efficient at deceiving viewers. Interestingly, an interaction effect indicates that it is not easy for users to detect editing traces in relatively long videos (greater than 30\,s). Our study is an initial step to better understand how individuals assess video credibility and lay the grounds for approaches to combat the negative effects of deepfakes.},
  langid = {english},
  file = {/Users/dape/Zotero/storage/HNW4DZ58/Jin et al. - 2023 - Assessing the perceived credibility of deepfakes .pdf}
}

@article{karasavvaRealThreatDeepfake2021,
  title = {The {{Real Threat}} of {{Deepfake Pornography}}: {{A Review}} of {{Canadian Policy}}},
  shorttitle = {The {{Real Threat}} of {{Deepfake Pornography}}},
  author = {Karasavva, Vasileia and Noorbhai, Aalia},
  date = {2021-03},
  journaltitle = {Cyberpsychology, Behavior, and Social Networking},
  volume = {24},
  number = {3},
  pages = {203--209},
  publisher = {{Mary Ann Liebert, Inc., publishers}},
  issn = {2152-2715},
  doi = {10.1089/cyber.2020.0272},
  url = {https://www.liebertpub.com/doi/10.1089/cyber.2020.0272},
  urldate = {2023-12-12},
  abstract = {Deepfakes may refer to algorithmically synthesized material wherein the face of a person is superimposed onto another body. To date, most deepfakes found online are pornographic, with the people depicted in them rarely consenting to their creation and publicization. Deepfakes leave anyone with an online presence vulnerable to victimization. As a testament to policy often being reactionary to antisocial behavior, current Canadian legislation offers no clear recourse to those who are victimized by deepfake pornography. We aim to provide a critical review of the legal mechanisms and remedies in place, including criminal charges, defamation, copyright infringement laws, and injunctive relief that could be applied in deepfake pornography cases. To combat deepfake pornography, we suggest current laws to be expanded to include language specific to falsely created pornography without the explicit consent of all depicted persons. We also discuss the extent to which host websites are responsible for vetting the uploaded content on their platforms. Finally, we present a call for action on a societal and research level to deal with deepfakes and better support victims of deepfake pornography.},
  keywords = {deepfakes,image based sexual abuse,policy,pornography,technology facilitated sexual violence},
  file = {/Users/dape/Zotero/storage/BE2AFLAA/Karasavva und Noorbhai - 2021 - The Real Threat of Deepfake Pornography A Review .pdf}
}

@online{kerungaJournalismCredibilityDigital2020,
  type = {SSRN Scholarly Paper},
  title = {Journalism {{Credibility}} in the {{Digital Age}} – {{Examining Shifts}} in {{Paradigms}}},
  author = {Kerunga, Joseph and Rowe, Evan and Gondwe, Gregory},
  date = {2020-07-02},
  number = {3641943},
  location = {{Rochester, NY}},
  doi = {10.2139/ssrn.3641943},
  url = {https://papers.ssrn.com/abstract=3641943},
  urldate = {2023-11-24},
  abstract = {This paper set out to explore the dominant measures of media credibility that have stood as a hallmark since the 1930s. By investigating their origins, the paper appends an old, and yet overlooked measure - “the local context”, to the already existing ones: source, message, medium, and web credibility. The paper highlights historical antecedents that support the claim and the argument that credibility, and especially in the digital age requires an extended understanding that includes the context or environment. By so doing, we would be able to explain why people choose to believe in inaccurate or false information. Predominantly, the paper interrogates why individuals in echo-chambers believe that a particular source, message, medium, or web is credible regardless of the content of the message.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Journalism,local context,media credibility,medium,message,source,web},
  file = {/Users/dape/Zotero/storage/2HBTALTE/Kerunga et al. - 2020 - Journalism Credibility in the Digital Age – Examin.pdf}
}

@online{kimConditionalVariationalAutoencoder2021,
  title = {Conditional {{Variational Autoencoder}} with {{Adversarial Learning}} for {{End-to-End Text-to-Speech}}},
  author = {Kim, Jaehyeon and Kong, Jungil and Son, Juhee},
  date = {2021-06-10},
  eprint = {2106.06103},
  eprinttype = {arxiv},
  eprintclass = {cs, eess},
  doi = {10.48550/arXiv.2106.06103},
  url = {http://arxiv.org/abs/2106.06103},
  urldate = {2023-11-24},
  abstract = {Several recent end-to-end text-to-speech (TTS) models enabling single-stage training and parallel sampling have been proposed, but their sample quality does not match that of two-stage TTS systems. In this work, we present a parallel end-to-end TTS method that generates more natural sounding audio than current two-stage models. Our method adopts variational inference augmented with normalizing flows and an adversarial training process, which improves the expressive power of generative modeling. We also propose a stochastic duration predictor to synthesize speech with diverse rhythms from input text. With the uncertainty modeling over latent variables and the stochastic duration predictor, our method expresses the natural one-to-many relationship in which a text input can be spoken in multiple ways with different pitches and rhythms. A subjective human evaluation (mean opinion score, or MOS) on the LJ Speech, a single speaker dataset, shows that our method outperforms the best publicly available TTS systems and achieves a MOS comparable to ground truth.},
  pubstate = {preprint},
  keywords = {Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing},
  file = {/Users/dape/Zotero/storage/BJQ8P2H2/Kim et al. - 2021 - Conditional Variational Autoencoder with Adversari.pdf;/Users/dape/Zotero/storage/FP5D8XKR/2106.html}
}

@online{kimConditionalVariationalAutoencoder2021a,
  title = {Conditional {{Variational Autoencoder}} with {{Adversarial Learning}} for {{End-to-End Text-to-Speech}}},
  author = {Kim, Jaehyeon and Kong, Jungil and Son, Juhee},
  date = {2021-06-10},
  eprint = {2106.06103},
  eprinttype = {arxiv},
  eprintclass = {cs, eess},
  url = {http://arxiv.org/abs/2106.06103},
  urldate = {2023-12-09},
  abstract = {Several recent end-to-end text-to-speech (TTS) models enabling single-stage training and parallel sampling have been proposed, but their sample quality does not match that of two-stage TTS systems. In this work, we present a parallel end-to-end TTS method that generates more natural sounding audio than current two-stage models. Our method adopts variational inference augmented with normalizing flows and an adversarial training process, which improves the expressive power of generative modeling. We also propose a stochastic duration predictor to synthesize speech with diverse rhythms from input text. With the uncertainty modeling over latent variables and the stochastic duration predictor, our method expresses the natural one-to-many relationship in which a text input can be spoken in multiple ways with different pitches and rhythms. A subjective human evaluation (mean opinion score, or MOS) on the LJ Speech, a single speaker dataset, shows that our method outperforms the best publicly available TTS systems and achieves a MOS comparable to ground truth.},
  pubstate = {preprint},
  keywords = {Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing},
  file = {/Users/dape/Zotero/storage/Q57N4JMB/Kim et al. - 2021 - Conditional Variational Autoencoder with Adversari.pdf;/Users/dape/Zotero/storage/52374R32/2106.html}
}

@inproceedings{kimCrepeConvolutionalRepresentation2018,
  title = {Crepe: {{A Convolutional Representation}} for {{Pitch Estimation}}},
  shorttitle = {Crepe},
  booktitle = {2018 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}} ({{ICASSP}})},
  author = {Kim, Jong Wook and Salamon, Justin and Li, Peter and Bello, Juan Pablo},
  date = {2018-04},
  pages = {161--165},
  issn = {2379-190X},
  doi = {10.1109/ICASSP.2018.8461329},
  url = {https://ieeexplore.ieee.org/document/8461329},
  urldate = {2023-11-24},
  abstract = {The task of estimating the fundamental frequency of a monophonic sound recording, also known as pitch tracking, is fundamental to audio processing with multiple applications in speech processing and music information retrieval. To date, the best performing techniques, such as the pYIN algorithm, are based on a combination of DSP pipelines and heuristics. While such techniques perform very well on average, there remain many cases in which they fail to correctly estimate the pitch. In this paper, we propose a data-driven pitch tracking algorithm, CREPE, which is based on a deep convolutional neural network that operates directly on the time-domain waveform. We show that the proposed model produces state-of-the-art results, performing equally or better than pYIN. Furthermore, we evaluate the model's generalizability in terms of noise robustness. A pre-trained version of CREPE is made freely available as an open-source Python module for easy application.},
  eventtitle = {2018 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}} ({{ICASSP}})},
  file = {/Users/dape/Zotero/storage/7BW4VWSQ/Kim et al. - 2018 - Crepe A Convolutional Representation for Pitch Es.pdf;/Users/dape/Zotero/storage/9XJ4G34M/8461329.html}
}

@article{kimElizaUncannyValley2019,
  title = {Eliza in the Uncanny Valley: Anthropomorphizing Consumer Robots Increases Their Perceived Warmth but Decreases Liking},
  shorttitle = {Eliza in the Uncanny Valley},
  author = {Kim, Seo Young and Schmitt, Bernd H. and Thalmann, Nadia M.},
  date = {2019-03-01},
  journaltitle = {Marketing Letters},
  shortjournal = {Mark Lett},
  volume = {30},
  number = {1},
  pages = {1--12},
  issn = {1573-059X},
  doi = {10.1007/s11002-019-09485-9},
  url = {https://doi.org/10.1007/s11002-019-09485-9},
  urldate = {2023-11-23},
  abstract = {Consumer robots are predicted to be employed in a variety of customer-facing situations. As these robots are designed to look and behave like humans, consumers attribute human traits to them—a phenomenon known as the “Eliza Effect.” In four experiments, we show that the anthropomorphism of a consumer robot increases psychological warmth but decreases attitudes, due to uncanniness. Competence judgments are much less affected and not subject to a decrease in attitudes. The current research contributes to research on artificial intelligence, anthropomorphism, and the uncanny valley phenomenon. We suggest to managers that they need to make sure that the appearances and behaviors of robots are not too human-like to avoid negative attitudes toward robots. Moreover, managers and researchers should collaborate to determine the optimal level of anthropomorphism.},
  langid = {english},
  keywords = {Anthropomorphism,Competence,Consumer robots,Uncanny valley,Warmth},
  file = {/Users/dape/Zotero/storage/KZ3UIQ4C/Kim et al. - 2019 - Eliza in the uncanny valley anthropomorphizing co.pdf}
}

@article{kimPerceivedCredibilityAI2022,
  title = {Perceived Credibility of an {{AI}} Instructor in Online Education: {{The}} Role of Social Presence and Voice Features},
  shorttitle = {Perceived Credibility of an {{AI}} Instructor in Online Education},
  author = {Kim, Jihyun and Merrill Jr., Kelly and Xu, Kun and Kelly, Stephanie},
  date = {2022-11-01},
  journaltitle = {Computers in Human Behavior},
  shortjournal = {Computers in Human Behavior},
  volume = {136},
  pages = {107383},
  issn = {0747-5632},
  doi = {10.1016/j.chb.2022.107383},
  url = {https://www.sciencedirect.com/science/article/pii/S0747563222002059},
  urldate = {2023-11-24},
  abstract = {Technological advancements have made AI instructors, or more broadly machine teachers, a lived reality. However, limited information is available about how students will perceive an AI instructor that provides educational content. Thus, the present study examines the effects of an AI instructor's voice and expertise on the perceived credibility of an AI instructor through an online experiment with a 2 (voice: machinelike vs. humanlike) x 2 (expertise: novice vs. expert) between-subjects design. Findings indicate that students perceive greater credibility of an AI instructor with a humanlike voice than those with a machinelike voice. The study also finds that social presence mediates the relationship between the voice of an AI instructor and the perceived credibility of the AI instructor. Finally, the perceived credibility of an AI instructor positively influences students' intentions to enroll in future AI instructor-based online courses. These findings highlight the importance of developing AI instructors that are perceived as credible.},
  keywords = {AI instructor,Credibility,Human-machine communication,Machine teacher,Machine voice,Social presence},
  file = {/Users/dape/Zotero/storage/A2EPU8GD/Kim et al. - 2022 - Perceived credibility of an AI instructor in onlin.pdf;/Users/dape/Zotero/storage/JAZM5DS7/S0747563222002059.html}
}

@online{kongHiFiGANGenerativeAdversarial2020,
  title = {{{HiFi-GAN}}: {{Generative Adversarial Networks}} for {{Efficient}} and {{High Fidelity Speech Synthesis}}},
  shorttitle = {{{HiFi-GAN}}},
  author = {Kong, Jungil and Kim, Jaehyeon and Bae, Jaekyoung},
  date = {2020-10-23},
  eprint = {2010.05646},
  eprinttype = {arxiv},
  eprintclass = {cs, eess},
  doi = {10.48550/arXiv.2010.05646},
  url = {http://arxiv.org/abs/2010.05646},
  urldate = {2023-11-24},
  abstract = {Several recent work on speech synthesis have employed generative adversarial networks (GANs) to produce raw waveforms. Although such methods improve the sampling efficiency and memory usage, their sample quality has not yet reached that of autoregressive and flow-based generative models. In this work, we propose HiFi-GAN, which achieves both efficient and high-fidelity speech synthesis. As speech audio consists of sinusoidal signals with various periods, we demonstrate that modeling periodic patterns of an audio is crucial for enhancing sample quality. A subjective human evaluation (mean opinion score, MOS) of a single speaker dataset indicates that our proposed method demonstrates similarity to human quality while generating 22.05 kHz high-fidelity audio 167.9 times faster than real-time on a single V100 GPU. We further show the generality of HiFi-GAN to the mel-spectrogram inversion of unseen speakers and end-to-end speech synthesis. Finally, a small footprint version of HiFi-GAN generates samples 13.4 times faster than real-time on CPU with comparable quality to an autoregressive counterpart.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing},
  file = {/Users/dape/Zotero/storage/ZBAY6NWL/Kong et al. - 2020 - HiFi-GAN Generative Adversarial Networks for Effi.pdf;/Users/dape/Zotero/storage/5BMJH3XZ/2010.html}
}

@inproceedings{krizhevskyImageNetClassificationDeep2012,
  title = {{{ImageNet Classification}} with {{Deep Convolutional Neural Networks}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  date = {2012},
  volume = {25},
  publisher = {{Curran Associates, Inc.}},
  url = {https://proceedings.neurips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html},
  urldate = {2023-12-04},
  abstract = {We trained a large, deep convolutional neural network to classify the 1.3 million high-resolution images in the LSVRC-2010 ImageNet training set into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 39.7\textbackslash\% and 18.9\textbackslash\% which is considerably better than the previous state-of-the-art results. The neural network, which has 60 million parameters and 500,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and two globally connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of convolutional nets. To reduce overfitting in the globally connected layers we employed a new regularization method that proved to be very effective.},
  file = {/Users/dape/Zotero/storage/YC8T5RID/Krizhevsky et al. - 2012 - ImageNet Classification with Deep Convolutional Ne.pdf}
}

@article{kuhneHumanTakesIt2020,
  title = {The {{Human Takes It All}}: {{Humanlike Synthesized Voices Are Perceived}} as {{Less Eerie}} and {{More Likable}}. {{Evidence From}} a {{Subjective Ratings Study}}},
  shorttitle = {The {{Human Takes It All}}},
  author = {Kühne, Katharina and Fischer, Martin H. and Zhou, Yuefang},
  date = {2020},
  journaltitle = {Frontiers in Neurorobotics},
  volume = {14},
  issn = {1662-5218},
  url = {https://www.frontiersin.org/articles/10.3389/fnbot.2020.593732},
  urldate = {2023-11-24},
  abstract = {Background: The increasing involvement of social robots in human lives raises the question as to how humans perceive social robots. Little is known about human perception of synthesized voices.Aim: To investigate which synthesized voice parameters predict the speaker's eeriness and voice likability; to determine if individual listener characteristics (e.g., personality, attitude toward robots, age) influence synthesized voice evaluations; and to explore which paralinguistic features subjectively distinguish humans from robots/artificial agents.Methods: 95 adults (62 females) listened to randomly presented audio-clips of three categories: synthesized (Watson, IBM), humanoid (robot Sophia, Hanson Robotics), and human voices (five clips/category). Voices were rated on intelligibility, prosody, trustworthiness, confidence, enthusiasm, pleasantness, human-likeness, likability, and naturalness. Speakers were rated on appeal, credibility, human-likeness, and eeriness. Participants' personality traits, attitudes to robots, and demographics were obtained.Results: The human voice and human speaker characteristics received reliably higher scores on all dimensions except for eeriness. Synthesized voice ratings were positively related to participants' agreeableness and neuroticism. Females rated synthesized voices more positively on most dimensions. Surprisingly, interest in social robots and attitudes toward robots played almost no role in voice evaluation. Contrary to the expectations of an uncanny valley, when the ratings of human-likeness for both the voice and the speaker characteristics were higher, they seemed less eerie to the participants. Moreover, when the speaker's voice was more humanlike, it was more liked by the participants. This latter point was only applicable to one of the synthesized voices. Finally, pleasantness and trustworthiness of the synthesized voice predicted the likability of the speaker's voice. Qualitative content analysis identified intonation, sound, emotion, and imageability/embodiment as diagnostic features.Discussion: Humans clearly prefer human voices, but manipulating diagnostic speech features might increase acceptance of synthesized voices and thereby support human-robot interaction. There is limited evidence that human-likeness of a voice is negatively linked to the perceived eeriness of the speaker.},
  file = {/Users/dape/Zotero/storage/YP2EL7DB/Kühne et al. - 2020 - The Human Takes It All Humanlike Synthesized Voic.pdf}
}

@article{kuschelPersoenlichkeitsrechtsverletzungenImInternet2022,
  title = {Persönlichkeitsrechtsverletzungen im Internet},
  author = {Kuschel, Linda},
  date = {2022-08-01},
  journaltitle = {JURA - Juristische Ausbildung},
  volume = {44},
  number = {8},
  pages = {904--914},
  publisher = {{De Gruyter}},
  issn = {1612-7021},
  doi = {10.1515/jura-2022-3149},
  url = {https://www.degruyter.com/document/doi/10.1515/jura-2022-3149/html},
  urldate = {2023-11-25},
  abstract = {Der Artikel Persönlichkeitsrechtsverletzungen im Internet wurde am 1. August 2022 in der Zeitschrift JURA - Juristische Ausbildung (Band 44, Heft 8) veröffentlicht.},
  langid = {ngerman},
  file = {/Users/dape/Zotero/storage/G72R9IE2/Kuschel - 2022 - Persönlichkeitsrechtsverletzungen im Internet.pdf}
}

@article{laasDeepfakesTrustTechnology2023,
  title = {Deepfakes and Trust in Technology},
  author = {Laas, Oliver},
  date = {2023-10-19},
  journaltitle = {Synthese},
  shortjournal = {Synthese},
  volume = {202},
  number = {5},
  pages = {132},
  issn = {1573-0964},
  doi = {10.1007/s11229-023-04363-4},
  url = {https://doi.org/10.1007/s11229-023-04363-4},
  urldate = {2023-11-28},
  abstract = {Deepfakes are fake recordings generated by machine learning algorithms. Various philosophical explanations have been proposed to account for their epistemic harmfulness. In this paper, I argue that deepfakes are epistemically harmful because they undermine trust in recording technology. As a result, we are no longer entitled to our default doxastic attitude of believing that P on the basis of a recording that supports the truth of P. Distrust engendered by deepfakes changes the epistemic status of recordings to resemble that of handmade images. Their credibility, like that of testimony, depends partly on the credibility of the source. I consider some proposed technical solutions from a philosophical perspective to show the practical relevance of these suggestions.},
  langid = {english},
  keywords = {Artificial intelligence,Deepfakes,Epistemic harms,Socio-technical systems,Trust in technology},
  file = {/Users/dape/Zotero/storage/8XWMN77F/Laas - 2023 - Deepfakes and trust in technology.pdf}
}

@online{landsiedelGamechanger2021,
  title = {Der Gamechanger},
  author = {Landsiedel, von Timo},
  date = {2021-06-30T10:00:05+02:00},
  url = {https://www.filmundtvkamera.de/technik/der-gamechanger/},
  urldate = {2023-12-09},
  abstract = {Einmal mehr erfindet Industrial Light \& Magic für eines seiner Vorhaben einfach eine neue Technologie. Für die Star-Wars-Serie „The Mandalorian“ hoben die Kalifornier mit Epic Games und Golem Creations für Disney+ die Virtual Production auf ein neues Level. Das Team drehte mehr als die Hälfte der Serie in „The Volume“ – einer Soundstage mit sechs...},
  langid = {ngerman},
  organization = {{Film \& TV Kamera}},
  file = {/Users/dape/Zotero/storage/LUZMJFN3/der-gamechanger.html}
}

@article{lazerScienceFakeNews2018,
  title = {The Science of Fake News},
  author = {Lazer, David M. J. and Baum, Matthew A. and Benkler, Yochai and Berinsky, Adam J. and Greenhill, Kelly M. and Menczer, Filippo and Metzger, Miriam J. and Nyhan, Brendan and Pennycook, Gordon and Rothschild, David and Schudson, Michael and Sloman, Steven A. and Sunstein, Cass R. and Thorson, Emily A. and Watts, Duncan J. and Zittrain, Jonathan L.},
  date = {2018-03-09},
  journaltitle = {Science},
  volume = {359},
  number = {6380},
  pages = {1094--1096},
  publisher = {{American Association for the Advancement of Science}},
  doi = {10.1126/science.aao2998},
  url = {https://www.science.org/doi/full/10.1126/science.aao2998},
  urldate = {2023-12-11},
  file = {/Users/dape/Zotero/storage/ZI6JDSTE/Lazer et al. - 2018 - The science of fake news.pdf}
}

@article{leeBelieveNotBelieve2021,
  title = {To {{Believe}} or {{Not}} to {{Believe}}: {{Framing Analysis}} of {{Content}} and {{Audience Response}} of {{Top}} 10 {{Deepfake Videos}} on {{YouTube}}},
  shorttitle = {To {{Believe}} or {{Not}} to {{Believe}}},
  author = {Lee, YoungAh and Huang, Kuo-Ting (Tim) and Blom, Robin and Schriner, Rebecca and Ciccarelli, Carl A.},
  date = {2021-03},
  journaltitle = {Cyberpsychology, Behavior, and Social Networking},
  volume = {24},
  number = {3},
  pages = {153--158},
  publisher = {{Mary Ann Liebert, Inc., publishers}},
  issn = {2152-2715},
  doi = {10.1089/cyber.2020.0176},
  url = {https://www.liebertpub.com/doi/10.1089/cyber.2020.0176},
  urldate = {2023-12-12},
  abstract = {This study explores popular deepfake media content and audience response in an effort to gain better understanding of the potential social and psychological impacts of deepfakes. A content analysis of the top 10 YouTube deepfake videos and their audience comments (n\,=\,2,689) was conducted to investigate the degree to which media meta-frame influenced audience response. The results suggested that media meta-frame, the type of video (deepfake videos with commentaries or original deepfake videos), and the number of dislikes on the video had considerable influence on audience response (attitudes and perceived realism), while the majority of the audience expressed neutral or irrelevant attitudes. Our exploratory observation revealed a dynamic interplay of how deepfake was presented and how others react to it might influence the public. Thus, it is necessary to appropriately caution the public about their vulnerability to the ever-advancing deepfake technologies.},
  keywords = {audience,deepfakes,framing,YouTube},
  file = {/Users/dape/Zotero/storage/NNLPU3DI/Lee et al. - 2021 - To Believe or Not to Believe Framing Analysis of .pdf}
}

@article{linardatosAufWegEuropaischen2022,
  title = {Auf Dem {{Weg}} Zu Einer Europäischen {{KI-Verordnung}} – Ein (Kritischer) {{Blick}} Auf Den Aktuellen {{Kommissionsentwurf}}},
  author = {Linardatos, Dimitrios},
  date = {2022-04-01},
  journaltitle = {Zeitschrift für das Privatrecht der Europäischen Union},
  volume = {19},
  number = {2},
  pages = {58--70},
  publisher = {{Verlag Dr. Otto Schmidt}},
  issn = {2364-7213},
  doi = {10.9785/gpr-2022-190204},
  url = {https://www.degruyter.com/document/doi/10.9785/gpr-2022-190204/html},
  urldate = {2023-11-25},
  abstract = {Der Artikel Auf dem Weg zu einer europäischen KI-Verordnung – ein (kritischer) Blick auf den aktuellen Kommissionsentwurf wurde am 1. April 2022 in der Zeitschrift Zeitschrift für das Privatrecht der Europäischen Union (Band 19, Heft 2) veröffentlicht.},
  langid = {english},
  file = {/Users/dape/Zotero/storage/DYJL855D/Linardatos - 2022 - Auf dem Weg zu einer europäischen KI-Verordnung – .pdf}
}

@online{liuDiffSingerSingingVoice2022,
  title = {{{DiffSinger}}: {{Singing Voice Synthesis}} via {{Shallow Diffusion Mechanism}}},
  shorttitle = {{{DiffSinger}}},
  author = {Liu, Jinglin and Li, Chengxi and Ren, Yi and Chen, Feiyang and Zhao, Zhou},
  date = {2022-03-22},
  eprint = {2105.02446},
  eprinttype = {arxiv},
  eprintclass = {cs, eess},
  doi = {10.48550/arXiv.2105.02446},
  url = {http://arxiv.org/abs/2105.02446},
  urldate = {2023-11-24},
  abstract = {Singing voice synthesis (SVS) systems are built to synthesize high-quality and expressive singing voice, in which the acoustic model generates the acoustic features (e.g., mel-spectrogram) given a music score. Previous singing acoustic models adopt a simple loss (e.g., L1 and L2) or generative adversarial network (GAN) to reconstruct the acoustic features, while they suffer from over-smoothing and unstable training issues respectively, which hinder the naturalness of synthesized singing. In this work, we propose DiffSinger, an acoustic model for SVS based on the diffusion probabilistic model. DiffSinger is a parameterized Markov chain that iteratively converts the noise into mel-spectrogram conditioned on the music score. By implicitly optimizing variational bound, DiffSinger can be stably trained and generate realistic outputs. To further improve the voice quality and speed up inference, we introduce a shallow diffusion mechanism to make better use of the prior knowledge learned by the simple loss. Specifically, DiffSinger starts generation at a shallow step smaller than the total number of diffusion steps, according to the intersection of the diffusion trajectories of the ground-truth mel-spectrogram and the one predicted by a simple mel-spectrogram decoder. Besides, we propose boundary prediction methods to locate the intersection and determine the shallow step adaptively. The evaluations conducted on a Chinese singing dataset demonstrate that DiffSinger outperforms state-of-the-art SVS work. Extensional experiments also prove the generalization of our methods on text-to-speech task (DiffSpeech). Audio samples: https://diffsinger.github.io. Codes: https://github.com/MoonInTheRiver/DiffSinger. The old title of this work: "Diffsinger: Diffusion acoustic model for singing voice synthesis".},
  pubstate = {preprint},
  version = {3},
  keywords = {Computer Science - Machine Learning,Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing},
  file = {/Users/dape/Zotero/storage/2EK26MX6/Liu et al. - 2022 - DiffSinger Singing Voice Synthesis via Shallow Di.pdf;/Users/dape/Zotero/storage/JBV9JZVF/2105.html}
}

@online{liuDiffSingerSingingVoice2022a,
  title = {{{DiffSinger}}: {{Singing Voice Synthesis}} via {{Shallow Diffusion Mechanism}}},
  shorttitle = {{{DiffSinger}}},
  author = {Liu, Jinglin and Li, Chengxi and Ren, Yi and Chen, Feiyang and Zhao, Zhou},
  date = {2022-03-22},
  eprint = {2105.02446},
  eprinttype = {arxiv},
  eprintclass = {cs, eess},
  url = {http://arxiv.org/abs/2105.02446},
  urldate = {2023-12-09},
  abstract = {Singing voice synthesis (SVS) systems are built to synthesize high-quality and expressive singing voice, in which the acoustic model generates the acoustic features (e.g., mel-spectrogram) given a music score. Previous singing acoustic models adopt a simple loss (e.g., L1 and L2) or generative adversarial network (GAN) to reconstruct the acoustic features, while they suffer from over-smoothing and unstable training issues respectively, which hinder the naturalness of synthesized singing. In this work, we propose DiffSinger, an acoustic model for SVS based on the diffusion probabilistic model. DiffSinger is a parameterized Markov chain that iteratively converts the noise into mel-spectrogram conditioned on the music score. By implicitly optimizing variational bound, DiffSinger can be stably trained and generate realistic outputs. To further improve the voice quality and speed up inference, we introduce a shallow diffusion mechanism to make better use of the prior knowledge learned by the simple loss. Specifically, DiffSinger starts generation at a shallow step smaller than the total number of diffusion steps, according to the intersection of the diffusion trajectories of the ground-truth mel-spectrogram and the one predicted by a simple mel-spectrogram decoder. Besides, we propose boundary prediction methods to locate the intersection and determine the shallow step adaptively. The evaluations conducted on a Chinese singing dataset demonstrate that DiffSinger outperforms state-of-the-art SVS work. Extensional experiments also prove the generalization of our methods on text-to-speech task (DiffSpeech). Audio samples: https://diffsinger.github.io. Codes: https://github.com/MoonInTheRiver/DiffSinger. The old title of this work: "Diffsinger: Diffusion acoustic model for singing voice synthesis".},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing},
  file = {/Users/dape/Zotero/storage/EPK36IY9/Liu et al. - 2022 - DiffSinger Singing Voice Synthesis via Shallow Di.pdf;/Users/dape/Zotero/storage/4UMCGB53/2105.html}
}

@inproceedings{longoniNewsGenerativeArtificial2022,
  title = {News from {{Generative Artificial Intelligence Is Believed Less}}},
  booktitle = {2022 {{ACM Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  author = {Longoni, Chiara and Fradkin, Andrey and Cian, Luca and Pennycook, Gordon},
  date = {2022-06-21},
  pages = {97--106},
  publisher = {{ACM}},
  location = {{Seoul Republic of Korea}},
  doi = {10.1145/3531146.3533077},
  url = {https://dl.acm.org/doi/10.1145/3531146.3533077},
  urldate = {2023-11-24},
  eventtitle = {{{FAccT}} '22: 2022 {{ACM Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  isbn = {978-1-4503-9352-2},
  langid = {english},
  file = {/Users/dape/Zotero/storage/UBXULHZA/Longoni et al. - 2022 - News from Generative Artificial Intelligence Is Be.pdf}
}

@article{maniaLegalProtectionRevenge2024,
  title = {Legal {{Protection}} of {{Revenge}} and {{Deepfake Porn Victims}} in the {{European Union}}: {{Findings From}} a {{Comparative Legal Study}}},
  shorttitle = {Legal {{Protection}} of {{Revenge}} and {{Deepfake Porn Victims}} in the {{European Union}}},
  author = {Mania, Karolina},
  date = {2024-01-01},
  journaltitle = {Trauma, Violence, \& Abuse},
  volume = {25},
  number = {1},
  pages = {117--129},
  publisher = {{SAGE Publications}},
  issn = {1524-8380},
  doi = {10.1177/15248380221143772},
  url = {https://doi.org/10.1177/15248380221143772},
  urldate = {2023-11-25},
  abstract = {The use of images of persons in a pornographic context (without the prior consent of the person concerned) on the internet is an increasingly widespread infringement. Unlawful activities carried out with the use of generated images and artificial intelligence are a variant of this phenomenon. “Revenge porn” and “deepfake porn” illustrate the inadequacy of legal systems vis a vis the fast-changing reality. Using the comparative law method, a comparison was made between the current laws of nine EU Member States to create a map of protection for victims of revenge porn. As the results showed, in three of the studied countries there is a separate incrimination of revenge porn; however, the conceptual scope of its definition is significantly different and it is these differences that determine the legal way for the victims to assert their rights. This article is a comparison of the current legal regulations of selected European Union countries and the means of legal protection used by the victims. The text presents the differences occurring in the legal systems adopted in the countries subject to analysis, as well as an assessment of possible solutions at the legal and technological level to face the existing problem.},
  langid = {english},
  file = {/Users/dape/Zotero/storage/AS9BHBUV/Mania - 2024 - Legal Protection of Revenge and Deepfake Porn Vict.pdf}
}

@article{mannisto-funkVoicesUncannyValley2018a,
  title = {Voices from the {{Uncanny Valley}}: {{Voices}} from the {{Uncanny Valley}}},
  shorttitle = {Voices from the {{Uncanny Valley}}},
  author = {Männistö-Funk, Tiina and Sihvonen, Tanja},
  date = {2018-03-01},
  journaltitle = {Digital Culture \& Society},
  volume = {4},
  number = {1},
  pages = {45--64},
  issn = {2364-2122, 2364-2114},
  doi = {10.14361/dcs-2018-0105},
  url = {https://www.degruyter.com/document/doi/10.14361/dcs-2018-0105/html},
  urldate = {2023-11-23},
  abstract = {Voice is a powerful tool of agency – for humans and non-humans alike. In this article, we go through the long history of talking heads and statues to publicly displayed robots and fortune-tellers, as well as consumer-oriented products such as the late 19th century talking dolls of Thomas Edison. We also analyse the attempts at making speaking machines commercially successful on various occasions. In the end, we investigate how speech producing devices such as the actual digital assistants that operate our current technological systems fit into this historical context. Our focus is on the gender aspects of the artificial, posthuman voice. On the basis of our study, we conclude that the female voice and other feminine characteristics as well as the figures of exoticized and racialized ‘Others’ have been applied to draw attention away from the uncanniness and other negative effects of these artificial humans and the machinic speech they produce. Technical problems associated with the commercialization of technologically produced speech have been considerable, but cultural issues have played an equally important role.},
  langid = {english},
  file = {/Users/dape/Zotero/storage/H68RZIH9/Männistö-Funk und Sihvonen - 2018 - Voices from the Uncanny Valley Voices from the Un.pdf}
}

@online{merriam-websterdictionaryRealStoryFake,
  title = {The {{Real Story}} of '{{Fake News}}'},
  author = {Merriam-Webster Dictionary},
  url = {https://www.merriam-webster.com/wordplay/the-real-story-of-fake-news},
  urldate = {2023-12-11},
  abstract = {The term seems to have emerged around the end of the 19th century},
  langid = {english},
  file = {/Users/dape/Zotero/storage/9NPE6BQP/the-real-story-of-fake-news.html}
}

@software{micaAudioSplitterUsing2023,
  title = {Audio {{Splitter}} Using {{Whisperx}}},
  author = {Mica, Jarod},
  date = {2023-12-21T19:28:28Z},
  origdate = {2023-06-30T19:35:29Z},
  url = {https://github.com/JarodMica/audiosplitter_whisper},
  urldate = {2023-12-22}
}

@online{midjourneyJoinMidjourneyDiscord,
  title = {Join the Midjourney Discord Server!},
  author = {Midjourney},
  url = {https://discord.com/invite/midjourney},
  urldate = {2023-12-08},
  abstract = {The official server for Midjourney, a text-to-image AI where your imagination is the only limit. | 17355269 members},
  langid = {ngerman},
  organization = {{Discord}},
  file = {/Users/dape/Zotero/storage/BEJN8WP9/midjourney.html}
}

@book{minskyPerceptronsIntroductionComputational2017,
  title = {Perceptrons: {{An Introduction}} to {{Computational Geometry}}},
  shorttitle = {Perceptrons},
  author = {Minsky, Marvin and Papert, Seymour A.},
  date = {2017},
  publisher = {{The MIT Press}},
  doi = {10.7551/mitpress/11301.001.0001},
  url = {https://direct.mit.edu/books/book/3132/perceptronsan-introduction-to-computational},
  urldate = {2023-12-04},
  isbn = {978-0-262-34393-0},
  langid = {english},
  file = {/Users/dape/Zotero/storage/ZJDAE9NZ/Minsky und Papert - 2017 - Perceptrons An Introduction to Computational Geom.pdf}
}

@online{montgomeryMARKERBOXFreeMarker,
  title = {{{MARKERBOX}} | the Free Marker Import Extension for {{Adobe Premiere Pro}}},
  author = {Montgomery, Tyron},
  url = {http://markerbox.pro/},
  urldate = {2023-12-22},
  abstract = {Import audio/video edit lists, client feedback an other timecode-related data from CSV files and create markers on your timeline with a few mouse clicks.},
  langid = {english},
  organization = {{MARKERBOX | the free marker import extension for Adobe Premiere Pro}},
  file = {/Users/dape/Zotero/storage/Y39QV5GD/markerbox.pro.html}
}

@inproceedings{moriseFastReliableF02009,
  title = {Fast and {{Reliable F0 Estimation Method Based}} on the {{Period Extraction}} of {{Vocal Fold Vibration}} of {{Singing Voice}} and {{Speech}}},
  author = {Morise, Masanori and Kawahara, Hideki and Katayose, Haruhiro},
  date = {2009-02-01},
  publisher = {{Audio Engineering Society}},
  url = {https://www.aes.org/e-lib/online/browse.cfm?elib=15165},
  urldate = {2023-11-24},
  abstract = {A fast and reliable fundamental frequency (F0) extraction method is proposed for real-time interactive applications using a singing voice. It is based on period detection of the vocal fold vibration, so it does not require expensive computation such as STFT or autocorrelation. Parallel processing architecture and a new cost function make this simple idea competitive with state of the art F0 estimation methods. A series of tests using publicly accessible F0 reference databases revealed that the...},
  eventtitle = {Audio {{Engineering Society Conference}}: 35th {{International Conference}}: {{Audio}} for {{Games}}},
  langid = {english}
}

@inproceedings{moriseHarvestHighPerformanceFundamental2017,
  title = {Harvest: {{A High-Performance Fundamental Frequency Estimator}} from {{Speech Signals}}},
  shorttitle = {Harvest},
  booktitle = {Interspeech 2017},
  author = {Morise, Masanori},
  date = {2017-08-20},
  pages = {2321--2325},
  publisher = {{ISCA}},
  doi = {10.21437/Interspeech.2017-68},
  url = {https://www.isca-speech.org/archive/interspeech_2017/morise17b_interspeech.html},
  urldate = {2023-11-24},
  eventtitle = {Interspeech 2017},
  langid = {english}
}

@article{moriUncannyValleyField2012,
  title = {The {{Uncanny Valley}} [{{From}} the {{Field}}]},
  author = {Mori, Masahiro and MacDorman, Karl F. and Kageki, Norri},
  date = {2012-06},
  journaltitle = {IEEE Robotics \& Automation Magazine},
  volume = {19},
  number = {2},
  pages = {98--100},
  issn = {1558-223X},
  doi = {10.1109/MRA.2012.2192811},
  url = {https://ieeexplore.ieee.org/abstract/document/6213238},
  urldate = {2023-11-23},
  abstract = {More than 40 years ago, Masahiro Mori, a robotics professor at the Tokyo Institute of Technology, wrote an essay [1] on how he envisioned people's reactions to robots that looked and acted almost like a human. In particular, he hypothesized that a person's response to a humanlike robot would abruptly shift from empathy to revulsion as it approached, but failed to attain, a lifelike appearance. This descent into eeriness is known as the uncanny valley. The essay appeared in an obscure Japanese journal called Energy in 1970, and in subsequent years, it received almost no attention. However, more recently, the concept of the uncanny valley has rapidly attracted interest in robotics and other scientific circles as well as in popular culture. Some researchers have explored its implications for human-robot interaction and computer-graphics animation, whereas others have investigated its biological and social roots. Now interest in the uncanny valley should only intensify, as technology evolves and researchers build robots that look human. Although copies of Mori's essay have circulated among researchers, a complete version hasn't been widely available. The following is the first publication of an English translation that has been authorized and reviewed by Mori. (See “Turning Point” in this issue for an interview with Mori.).},
  eventtitle = {{{IEEE Robotics}} \& {{Automation Magazine}}},
  file = {/Users/dape/Zotero/storage/337S5R3J/Mori et al. - 2012 - The Uncanny Valley [From the Field].pdf;/Users/dape/Zotero/storage/R4KSMZIZ/6213238.html}
}

@software{mukhopadhyayWav2LipAccuratelyLipsyncing2023,
  title = {{{Wav2Lip}}: {{Accurately Lip-syncing Videos In The Wild}}},
  shorttitle = {{{Wav2Lip}}},
  author = {Mukhopadhyay, Rudrabha},
  date = {2023-12-08T12:20:03Z},
  origdate = {2020-08-07T08:06:38Z},
  url = {https://github.com/Rudrabha/Wav2Lip},
  urldate = {2023-12-08},
  abstract = {This repository contains the codes of "A Lip Sync Expert Is All You Need for Speech to Lip Generation In the Wild", published at ACM Multimedia 2020.}
}

@software{mullerThorstenVoice2023,
  title = {Thorsten-{{Voice}}},
  author = {Müller, Thorsten and Kreutz, Dominik},
  date = {2023-12-21T07:20:42Z},
  origdate = {2019-10-29T17:52:17Z},
  url = {https://github.com/thorstenMueller/Thorsten-Voice},
  urldate = {2023-12-22},
  abstract = {Thorsten-Voice: A free to use, offline working, high quality german TTS voice should be available for every project without any license struggling.}
}

@article{naeemExplorationHowFake2021,
  title = {An Exploration of How Fake News Is Taking over Social Media and Putting Public Health at Risk},
  author = {Naeem, Salman Bin and Bhatti, Rubina and Khan, Aqsa},
  date = {2021},
  journaltitle = {Health Information \& Libraries Journal},
  volume = {38},
  number = {2},
  pages = {143--149},
  issn = {1471-1842},
  doi = {10.1111/hir.12320},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/hir.12320},
  urldate = {2023-11-24},
  abstract = {Recent statistics show that almost 1/4 of a million people have died and four million people are affected either with mild or serious health problems caused by coronavirus (COVID-19). These numbers are rapidly increasing (World Health Organization, May 3, 2020c). There is much concern during this pandemic about the spread of misleading or inaccurate information. This article reports on a small study which attempted to identify the types and sources of COVID-19 misinformation. The authors identified and analysed 1225 pieces of COVID-19 fake news stories taken from fact-checkers, myth-busters and COVID-19 dashboards. The study is significant given the concern raised by the WHO Director-General that ‘we are not just fighting the pandemic, we are also fighting infodemic’. The study concludes that the COVID-19 infodemic is full of false claims, half backed conspiracy theories and pseudoscientific therapies, regarding the diagnosis, treatment, prevention, origin and spread of the virus. Fake news is pervasive in social media, putting public health at risk. The scale of the crisis and ubiquity of the misleading information require that scientists, health information professionals and journalists exercise their professional responsibility to help the general public identify fake news stories. They should ensure that accurate information is published and disseminated.J.M.},
  langid = {english},
  keywords = {global health,information sources,public health,social media},
  file = {/Users/dape/Zotero/storage/23R5REC4/Naeem et al. - 2021 - An exploration of how fake news is taking over soc.pdf;/Users/dape/Zotero/storage/LUW66K46/hir.html}
}

@online{nightingaleAIsynthesizedFacesAre,
  title = {{{AI-synthesized}} Faces Are Indistinguishable from Real Faces and More Trustworthy},
  author = {Nightingale, Sophie J and Farid, Heny},
  doi = {10.1073/pnas.2120481119},
  url = {https://www.pnas.org/doi/10.1073/pnas.2120481119},
  urldate = {2023-11-23},
  langid = {english},
  file = {/Users/dape/Zotero/storage/74ZJ93TY/AI-synthesized faces are indistinguishable from re.pdf;/Users/dape/Zotero/storage/IQBHJD6M/pnas.html}
}

@article{obaidReflectionDeepfakesDigital2023,
  title = {The Reflection of Deepfakes in Digital Media on the Credibility of Television News Sources {{From}} the Viewpoint of Newsroom Workers},
  author = {Obaid, Dr Muhaned Hameed},
  date = {2023},
  journaltitle = {Journal of Media Studies and Research},
  volume = {3},
  number = {10},
  publisher = {{Iraqia University}},
  issn = {23080728 2957966x},
  url = {https://www.iasj.net/iasj/article/284097},
  urldate = {2023-11-24},
  langid = {english},
  file = {/Users/dape/Zotero/storage/DEMHLD5G/cdcddf5f4f5620cb.pdf;/Users/dape/Zotero/storage/WAP4SIKM/284097.html}
}

@article{opdahlTrustworthyJournalismAI2023,
  title = {Trustworthy Journalism through {{AI}}},
  author = {Opdahl, Andreas L and Tessem, Bjørnar and Dang-Nguyen, Duc-Tien and Motta, Enrico and Setty, Vinay and Throndsen, Eivind and Tverberg, Are and Trattner, Christoph},
  date = {2023-07-01},
  journaltitle = {Data \& Knowledge Engineering},
  shortjournal = {Data \& Knowledge Engineering},
  volume = {146},
  pages = {102182},
  issn = {0169-023X},
  doi = {10.1016/j.datak.2023.102182},
  url = {https://www.sciencedirect.com/science/article/pii/S0169023X23000423},
  urldate = {2023-11-24},
  abstract = {Quality journalism has become more important than ever due to the need for quality and trustworthy media outlets that can provide accurate information to the public and help to address and counterbalance the wide and rapid spread of disinformation. At the same time, quality journalism is under pressure due to loss of revenue and competition from alternative information providers. This vision paper discusses how recent advances in Artificial Intelligence (AI), and in Machine Learning (ML) in particular, can be harnessed to support efficient production of high-quality journalism. From a news consumer perspective, the key parameter here concerns the degree of trust that is engendered by quality news production. For this reason, the paper will discuss how AI techniques can be applied to all aspects of news, at all stages of its production cycle, to increase trust.},
  keywords = {Artificial Intelligence,Journalism,News Production,Trustworthiness},
  file = {/Users/dape/Zotero/storage/SQAQZTZ3/Opdahl et al. - 2023 - Trustworthy journalism through AI.pdf;/Users/dape/Zotero/storage/SQZD76GN/S0169023X23000423.html}
}

@report{parisDeepfakesCheapFakes2019,
  type = {Report},
  title = {Deepfakes and Cheap Fakes},
  author = {Paris, Britt and Donovan, Joan},
  date = {2019-09-18},
  institution = {{Data \& Society Research Institute}},
  url = {https://apo.org.au/node/259911},
  urldate = {2023-12-16},
  abstract = {In this report, the authors~trace decades of~audiovisual (AV) manipulation~to demonstrate how~evolving technologies aid consolidations of power~in society. Deepfakes, they find, are no new threat to democracy.},
  langid = {english},
  file = {/Users/dape/Zotero/storage/4HBUKB4G/Paris und Donovan - 2019 - Deepfakes and cheap fakes.pdf}
}

@incollection{pawelecDeepfakesAlsChance2022,
  title = {Deepfakes als Chance für die Demokratie?},
  booktitle = {Digitalisierung und die Zukunft der Demokratie},
  author = {Pawelec, Maria},
  editor = {Bogner, Alexander and Decker, Michael and Nentwich, Michael and Scherz, Constanze},
  date = {2022},
  pages = {89--102},
  publisher = {{Nomos Verlagsgesellschaft mbH \& Co. KG}},
  doi = {10.5771/9783748928928-89},
  url = {https://www.nomos-elibrary.de/index.php?doi=10.5771/9783748928928-89},
  urldate = {2023-11-25},
  isbn = {978-3-7489-2892-8},
  langid = {ngerman},
  file = {/Users/dape/Zotero/storage/BSPMCL4F/Pawelec - 2022 - Deepfakes als Chance für die Demokratie.pdf}
}

@book{pawelecDeepfakesTechnikfolgenUnd2021,
  title = {Deepfakes: Technikfolgen und Regulierungsfragen aus ethischer und sozialwissenschaftlicher Perspektive},
  shorttitle = {Deepfakes},
  author = {Pawelec, Maria and Bieß, Cora},
  date = {2021-10-27},
  eprint = {jHJxEAAAQBAJ},
  eprinttype = {googlebooks},
  publisher = {{Nomos Verlag}},
  abstract = {Deepfakes – manipulierte oder synthetische audiovisuelle Medien, meist erzeugt mit Hilfe von KI – finden in verschiedensten Kontexten Anwendung: von Politik über Pornografie und Kriminalität bis hin zu Wirtschaft, Strafverfolgung, Kunst, Satire, Bildung und Aktivismus. Die Studie bietet erstmals eine holistische Technikbewertung der gesellschaftlichen und ethischen Auswirkungen von Deepfakes in diesen Kontexten und untersucht mögliche Reaktionen auf die neue Technologie – von (supra-)nationaler Regulierung bis hin zu KI-basierter Deepfake-Detektion. Sie richtet zudem konkrete Handlungsempfehlungen etwa an Politik, Forschungsförderung und BürgerInnen. Die enthaltene interaktive Lehreinheit fördert die Medienkompetenz zu Deepfakes.},
  isbn = {978-3-7489-2807-2},
  langid = {ngerman},
  pagetotal = {226},
  keywords = {Social Science / Media Studies}
}

@online{pengDPHuBERTJointDistillation2023,
  title = {{{DPHuBERT}}: {{Joint Distillation}} and {{Pruning}} of {{Self-Supervised Speech Models}}},
  shorttitle = {{{DPHuBERT}}},
  author = {Peng, Yifan and Sudo, Yui and Muhammad, Shakeel and Watanabe, Shinji},
  date = {2023-05-28},
  eprint = {2305.17651},
  eprinttype = {arxiv},
  eprintclass = {cs, eess},
  doi = {10.48550/arXiv.2305.17651},
  url = {http://arxiv.org/abs/2305.17651},
  urldate = {2023-11-24},
  abstract = {Self-supervised learning (SSL) has achieved notable success in many speech processing tasks, but the large model size and heavy computational cost hinder the deployment. Knowledge distillation trains a small student model to mimic the behavior of a large teacher model. However, the student architecture usually needs to be manually designed and will remain fixed during training, which requires prior knowledge and can lead to suboptimal performance. Inspired by recent success of task-specific structured pruning, we propose DPHuBERT, a novel task-agnostic compression method for speech SSL based on joint distillation and pruning. Experiments on SUPERB show that DPHuBERT outperforms pure distillation methods in almost all tasks. Moreover, DPHuBERT requires little training time and performs well with limited training data, making it suitable for resource-constrained applications. Our method can also be applied to various speech SSL models. Our code and models will be publicly available.},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language,Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing},
  file = {/Users/dape/Zotero/storage/B2JU9DAT/Peng et al. - 2023 - DPHuBERT Joint Distillation and Pruning of Self-S.pdf;/Users/dape/Zotero/storage/DIZQ3J6U/2305.html}
}

@article{pennycookReceptionDetectionPseudoprofound2015,
  title = {On the Reception and Detection of Pseudo-Profound Bullshit},
  author = {Pennycook, Gordon and Cheyne, James Allan and Barr, Nathaniel and Koehler, Derek J. and Fugelsang, Jonathan A.},
  date = {2015-11},
  journaltitle = {Judgment and Decision Making},
  volume = {10},
  number = {6},
  pages = {549--563},
  publisher = {{Cambridge University Press}},
  issn = {1930-2975},
  doi = {10.1017/S1930297500006999},
  url = {https://www.cambridge.org/core/journals/judgment-and-decision-making/article/on-the-reception-and-detection-of-pseudoprofound-bullshit/0D3C87BCC238BCA38BC55E395BDC9999},
  urldate = {2023-12-17},
  abstract = {Although bullshit is common in everyday life and has attracted attention from philosophers, its reception (critical or ingenuous) has not, to our knowledge, been subject to empirical investigation. Here we focus on pseudo-profound bullshit, which consists of seemingly impressive assertions that are presented as true and meaningful but are actually vacuous. We presented participants with bullshit statements consisting of buzzwords randomly organized into statements with syntactic structure but no discernible meaning (e.g., “Wholeness quiets infinite phenomena”). Across multiple studies, the propensity to judge bullshit statements as profound was associated with a variety of conceptually relevant variables (e.g., intuitive cognitive style, supernatural belief). Parallel associations were less evident among profundity judgments for more conventionally profound (e.g., “A wet person does not fear the rain”) or mundane (e.g., “Newborn babies require constant attention”) statements. These results support the idea that some people are more receptive to this type of bullshit and that detecting it is not merely a matter of indiscriminate skepticism but rather a discernment of deceptive vagueness in otherwise impressive sounding claims. Our results also suggest that a bias toward accepting statements as true may be an important component of pseudo-profound bullshit receptivity.},
  langid = {english},
  keywords = {analytic thinking,bullshit,bullshit detection,complementary and alternative medicine,conspiratorial ideation,dual-process theories,religiosity,supernatural beliefs},
  file = {/Users/dape/Zotero/storage/G4AQE5RX/Pennycook et al. - 2015 - On the reception and detection of pseudo-profound .pdf}
}

@online{perovDeepFaceLabIntegratedFlexible2021,
  title = {{{DeepFaceLab}}: {{Integrated}}, Flexible and Extensible Face-Swapping Framework},
  shorttitle = {{{DeepFaceLab}}},
  author = {Perov, Ivan and Gao, Daiheng and Chervoniy, Nikolay and Liu, Kunlin and Marangonda, Sugasa and Umé, Chris and Dpfks, Mr and Facenheim, Carl Shift and RP, Luis and Jiang, Jian and Zhang, Sheng and Wu, Pingyu and Zhou, Bo and Zhang, Weiming},
  date = {2021-06-29},
  eprint = {2005.05535},
  eprinttype = {arxiv},
  eprintclass = {cs, eess},
  url = {http://arxiv.org/abs/2005.05535},
  urldate = {2023-11-26},
  abstract = {Deepfake defense not only requires the research of detection but also requires the efforts of generation methods. However, current deepfake methods suffer the effects of obscure workflow and poor performance. To solve this problem, we present DeepFaceLab, the current dominant deepfake framework for face-swapping. It provides the necessary tools as well as an easy-to-use way to conduct high-quality face-swapping. It also offers a flexible and loose coupling structure for people who need to strengthen their pipeline with other features without writing complicated boilerplate code. We detail the principles that drive the implementation of DeepFaceLab and introduce its pipeline, through which every aspect of the pipeline can be modified painlessly by users to achieve their customization purpose. It is noteworthy that DeepFaceLab could achieve cinema-quality results with high fidelity. We demonstrate the advantage of our system by comparing our approach with other face-swapping methods.For more information, please visit:https://github.com/iperov/DeepFaceLab/.},
  pubstate = {preprint},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Multimedia,Electrical Engineering and Systems Science - Image and Video Processing},
  file = {/Users/dape/Zotero/storage/XS9CH64A/Perov et al. - 2021 - DeepFaceLab Integrated, flexible and extensible f.pdf;/Users/dape/Zotero/storage/S2PEFWF6/2005.html}
}

@inproceedings{prajwalLipSyncExpert2020,
  title = {A {{Lip Sync Expert Is All You Need}} for {{Speech}} to {{Lip Generation In The Wild}}},
  booktitle = {Proceedings of the 28th {{ACM International Conference}} on {{Multimedia}}},
  author = {Prajwal, K. R. and Mukhopadhyay, Rudrabha and Namboodiri, Vinay and Jawahar, C. V.},
  date = {2020-10-12},
  eprint = {2008.10010},
  eprinttype = {arxiv},
  eprintclass = {cs, eess},
  pages = {484--492},
  doi = {10.1145/3394171.3413532},
  url = {http://arxiv.org/abs/2008.10010},
  urldate = {2023-11-24},
  abstract = {In this work, we investigate the problem of lip-syncing a talking face video of an arbitrary identity to match a target speech segment. Current works excel at producing accurate lip movements on a static image or videos of specific people seen during the training phase. However, they fail to accurately morph the lip movements of arbitrary identities in dynamic, unconstrained talking face videos, resulting in significant parts of the video being out-of-sync with the new audio. We identify key reasons pertaining to this and hence resolve them by learning from a powerful lip-sync discriminator. Next, we propose new, rigorous evaluation benchmarks and metrics to accurately measure lip synchronization in unconstrained videos. Extensive quantitative evaluations on our challenging benchmarks show that the lip-sync accuracy of the videos generated by our Wav2Lip model is almost as good as real synced videos. We provide a demo video clearly showing the substantial impact of our Wav2Lip model and evaluation benchmarks on our website: \textbackslash url\{cvit.iiit.ac.in/research/projects/cvit-projects/a-lip-sync-expert-is-all-you-need-for-speech-to-lip-generation-in-the-wild\}. The code and models are released at this GitHub repository: \textbackslash url\{github.com/Rudrabha/Wav2Lip\}. You can also try out the interactive demo at this link: \textbackslash url\{bhaasha.iiit.ac.in/lipsync\}.},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing},
  file = {/Users/dape/Zotero/storage/PTA2UBHZ/Prajwal et al. - 2020 - A Lip Sync Expert Is All You Need for Speech to Li.pdf;/Users/dape/Zotero/storage/HE3LR2FT/2008.html}
}

@online{ProjectOrigin,
  title = {Project {{Origin}}},
  url = {https://www.originproject.info},
  urldate = {2023-12-13},
  abstract = {An alliance of four leading organisations from the publishing and technology worlds working together to create a process where the provenance and technical integrity of content can be confirmed. Establishing a chain of trust from the publisher to the consumer.},
  langid = {american},
  file = {/Users/dape/Zotero/storage/EG2PCQAD/www.originproject.info.html}
}

@article{przybylaWhenClassificationAccuracy2021,
  title = {When Classification Accuracy Is Not Enough: {{Explaining}} News Credibility Assessment},
  shorttitle = {When Classification Accuracy Is Not Enough},
  author = {Przybyła, Piotr and Soto, Axel J.},
  date = {2021-09},
  journaltitle = {Information Processing \& Management},
  shortjournal = {Information Processing \& Management},
  volume = {58},
  number = {5},
  pages = {102653},
  issn = {03064573},
  doi = {10.1016/j.ipm.2021.102653},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0306457321001412},
  urldate = {2023-11-24},
  abstract = {Dubious credibility of online news has become a major problem with negative consequences for both readers and the whole society. Despite several efforts in the development of automatic methods for measuring credibility in news stories, there has been little previous work focusing on providing explanations that go beyond a black-box decision or score. In this work, we use two machine learning approaches for computing a credibility score for any given news story: one is a linear method trained on stylometric features and the other one is a recurrent neural network. Our goal is to study whether we can explain the rationale behind these automatic methods and improve a reader’s confidence in their credibility assessment. Therefore, we first adapted the classifiers to the constraints of a browser extension so that the text can be analysed while browsing online news. We also propose a set of interactive visualisations to explain to the user the rationale behind the automatic credibility assessment. We evaluated our adapted methods by means of standard machine learning performance metrics and through two user studies. The adapted neural classifier showed better performance on the test data than the stylometric classifier, despite the latter appearing to be easier to interpret by the participants. Also, users were significantly more accurate in their assessment after they interacted with the tool as well as more confident with their decisions.},
  langid = {english},
  file = {/Users/dape/Zotero/storage/WTIQXHXZ/Przybyła und Soto - 2021 - When classification accuracy is not enough Explai.pdf}
}

@online{qianContentVecImprovedSelfSupervised2022,
  title = {{{ContentVec}}: {{An Improved Self-Supervised Speech Representation}} by {{Disentangling Speakers}}},
  shorttitle = {{{ContentVec}}},
  author = {Qian, Kaizhi and Zhang, Yang and Gao, Heting and Ni, Junrui and Lai, Cheng-I. and Cox, David and Hasegawa-Johnson, Mark and Chang, Shiyu},
  date = {2022-06-23},
  eprint = {2204.09224},
  eprinttype = {arxiv},
  eprintclass = {cs, eess},
  doi = {10.48550/arXiv.2204.09224},
  url = {http://arxiv.org/abs/2204.09224},
  urldate = {2023-11-24},
  abstract = {Self-supervised learning in speech involves training a speech representation network on a large-scale unannotated speech corpus, and then applying the learned representations to downstream tasks. Since the majority of the downstream tasks of SSL learning in speech largely focus on the content information in speech, the most desirable speech representations should be able to disentangle unwanted variations, such as speaker variations, from the content. However, disentangling speakers is very challenging, because removing the speaker information could easily result in a loss of content as well, and the damage of the latter usually far outweighs the benefit of the former. In this paper, we propose a new SSL method that can achieve speaker disentanglement without severe loss of content. Our approach is adapted from the HuBERT framework, and incorporates disentangling mechanisms to regularize both the teacher labels and the learned representations. We evaluate the benefit of speaker disentanglement on a set of content-related downstream tasks, and observe a consistent and notable performance advantage of our speaker-disentangled representations.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing},
  file = {/Users/dape/Zotero/storage/7QSMBZ52/Qian et al. - 2022 - ContentVec An Improved Self-Supervised Speech Rep.pdf;/Users/dape/Zotero/storage/43F3J6UX/2204.html}
}

@online{radfordRobustSpeechRecognition2022,
  title = {Robust {{Speech Recognition}} via {{Large-Scale Weak Supervision}}},
  author = {Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya},
  date = {2022-12-06},
  eprint = {2212.04356},
  eprinttype = {arxiv},
  eprintclass = {cs, eess},
  doi = {10.48550/arXiv.2212.04356},
  url = {http://arxiv.org/abs/2212.04356},
  urldate = {2023-11-24},
  abstract = {We study the capabilities of speech processing systems trained simply to predict large amounts of transcripts of audio on the internet. When scaled to 680,000 hours of multilingual and multitask supervision, the resulting models generalize well to standard benchmarks and are often competitive with prior fully supervised results but in a zero-shot transfer setting without the need for any fine-tuning. When compared to humans, the models approach their accuracy and robustness. We are releasing models and inference code to serve as a foundation for further work on robust speech processing.},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning,Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing},
  file = {/Users/dape/Zotero/storage/MTWCBW4L/Radford et al. - 2022 - Robust Speech Recognition via Large-Scale Weak Sup.pdf;/Users/dape/Zotero/storage/N5MJHKSY/2212.html}
}

@article{rajiRechtlicheBewertungSynthetischer2021,
  title = {Rechtliche Bewertung synthetischer Daten für KI-Systeme},
  author = {Raji, Behrang},
  date = {2021-05-01},
  journaltitle = {Datenschutz und Datensicherheit - DuD},
  shortjournal = {Datenschutz Datensich},
  volume = {45},
  number = {5},
  pages = {303--309},
  issn = {1862-2607},
  doi = {10.1007/s11623-021-1439-9},
  url = {https://doi.org/10.1007/s11623-021-1439-9},
  urldate = {2023-11-25},
  abstract = {KI-Systeme benötigen im Trainingsprozess eine Menge an Daten. Sofern es sich um personenbezogeneDaten handelt, müssen dabei datenschutzrechtliche Pflichten eingehalten werden. Als neue Anonymisierungstechnikversprechen sogenannte synthetische Daten einen hohen Schutz für die Betroffenen und ermöglichenzugleich eine freie Nutzung dieser Daten. Der Beitrag untersucht die datenschutzrechtlichen Implikationenund Anforderungen an unüberwachtes maschinelles Lernen mit synthetisierten Daten.},
  langid = {ngerman},
  file = {/Users/dape/Zotero/storage/C2RDBMEK/Raji - 2021 - Rechtliche Bewertung synthetischer Daten für KI-Sy.pdf}
}

@online{rombachHighResolutionImageSynthesis2022,
  title = {High-{{Resolution Image Synthesis}} with {{Latent Diffusion Models}}},
  author = {Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Björn},
  date = {2022-04-13},
  eprint = {2112.10752},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2112.10752},
  url = {http://arxiv.org/abs/2112.10752},
  urldate = {2023-11-24},
  abstract = {By decomposing the image formation process into a sequential application of denoising autoencoders, diffusion models (DMs) achieve state-of-the-art synthesis results on image data and beyond. Additionally, their formulation allows for a guiding mechanism to control the image generation process without retraining. However, since these models typically operate directly in pixel space, optimization of powerful DMs often consumes hundreds of GPU days and inference is expensive due to sequential evaluations. To enable DM training on limited computational resources while retaining their quality and flexibility, we apply them in the latent space of powerful pretrained autoencoders. In contrast to previous work, training diffusion models on such a representation allows for the first time to reach a near-optimal point between complexity reduction and detail preservation, greatly boosting visual fidelity. By introducing cross-attention layers into the model architecture, we turn diffusion models into powerful and flexible generators for general conditioning inputs such as text or bounding boxes and high-resolution synthesis becomes possible in a convolutional manner. Our latent diffusion models (LDMs) achieve a new state of the art for image inpainting and highly competitive performance on various tasks, including unconditional image generation, semantic scene synthesis, and super-resolution, while significantly reducing computational requirements compared to pixel-based DMs. Code is available at https://github.com/CompVis/latent-diffusion .},
  pubstate = {preprint},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/dape/Zotero/storage/H6VG7W4R/Rombach et al. - 2022 - High-Resolution Image Synthesis with Latent Diffus.pdf;/Users/dape/Zotero/storage/YC67UYRZ/2112.html}
}

@online{rostamzadehEthicsCreativityComputer2021,
  title = {Ethics and {{Creativity}} in {{Computer Vision}}},
  author = {Rostamzadeh, Negar and Denton, Emily and Petrini, Linda},
  date = {2021-12-06},
  eprint = {2112.03111},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2112.03111},
  url = {http://arxiv.org/abs/2112.03111},
  urldate = {2023-12-06},
  abstract = {This paper offers a retrospective of what we learnt from organizing the workshop *Ethical Considerations in Creative applications of Computer Vision* at CVPR 2021 conference and, prior to that, a series of workshops on *Computer Vision for Fashion, Art and Design* at ECCV 2018, ICCV 2019, and CVPR 2020. We hope this reflection will bring artists and machine learning researchers into conversation around the ethical and social dimensions of creative applications of computer vision.},
  pubstate = {preprint},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Computers and Society,Computer Science - Machine Learning},
  file = {/Users/dape/Zotero/storage/YETZHXH4/Rostamzadeh et al. - 2021 - Ethics and Creativity in Computer Vision.pdf;/Users/dape/Zotero/storage/TTDXDVWQ/2112.html}
}

@software{RVCProjectRetrievalbasedVoiceConversionWebUI2023,
  title = {{{RVC-Project}}/{{Retrieval-based-Voice-Conversion-WebUI}}},
  date = {2023-12-09T14:54:16Z},
  origdate = {2023-03-27T09:59:10Z},
  url = {https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI},
  urldate = {2023-12-09},
  abstract = {Voice data {$<$}= 10 mins can also be used to train a good VC model!},
  organization = {{RVC-Project}},
  keywords = {audio-analysis,change,conversational-ai,conversion,converter,retrieval-model,retrieve-data,rvc,so-vits-svc,sovits,vc,vits,voice,voice-conversion,voice-converter,voiceconversion}
}

@software{sainyAjaysainyWav2LipGFPGAN2023,
  title = {Ajay-Sainy/{{Wav2Lip-GFPGAN}}},
  author = {Sainy, Ajay},
  date = {2023-12-27T13:34:43Z},
  origdate = {2022-08-18T03:11:21Z},
  url = {https://github.com/ajay-sainy/Wav2Lip-GFPGAN},
  urldate = {2023-12-27},
  abstract = {High quality Lip sync},
  keywords = {deepfakes,gfpgan,wav2lip}
}

@article{salemiDeepfakesImVideoIdentVerfahren2022,
  title = {Deepfakes im VideoIdent-Verfahren: (fehlende) Straf- und zivilrechtliche Konsequenzen für Täter},
  shorttitle = {Deepfakes im VideoIdent-Verfahren},
  author = {Salemi, Simone and Steffes, Bianca},
  date = {2022},
  publisher = {{Gesellschaft für Informatik, Bonn}},
  issn = {1617-5468},
  doi = {10.18420/INF2022_53},
  url = {http://dl.gi.de/handle/20.500.12116/39554},
  urldate = {2023-11-25},
  abstract = {Der Einsatz des sogenannten VideoIdent-Verfahrens zur Authentifzierung im Videochat erfreut sich wachsender Beliebtheit bei Banken und Versicherungen. Nach erfolgter Legitimation wird der Zugang zu neu eröffneten Bankkonten freigeschaltet. Gleichzeitig führen Fortschritte im Bereich des Deep Learnings dazu, dass Manipulationen von Videos mittels sogenannter Deepfakes kaum mehr erkennbar sind. Dieser Beitrag widmet sich der Frage, ob Deepfakes eine reale Gefahr für die Sicherheit des VideoIdent-Verfahrens darstellen und wie der Einsatz rechtlich zu bewerten ist.},
  isbn = {9783885797203},
  langid = {ngerman},
  keywords = {Deepfakes||Authentifizierung||VideoIdent},
  file = {/Users/dape/Zotero/storage/6MGNDEG4/Salemi und Steffes - 2022 - Deepfakes im VideoIdent-Verfahren (fehlende) Stra.pdf}
}

@software{sangwanRoop2023,
  title = {Roop},
  author = {Sangwan, Somdev},
  date = {2023-12-06T09:50:05Z},
  origdate = {2023-05-28T14:37:54Z},
  url = {https://github.com/s0md3v/roop},
  urldate = {2023-12-06},
  abstract = {one-click face swap},
  keywords = {ai,face-swap}
}

@online{schmidhuberAnnotatedHistoryModern2022,
  title = {Annotated {{History}} of {{Modern AI}} and {{Deep Learning}}},
  author = {Schmidhuber, Juergen},
  date = {2022-12-29},
  eprint = {2212.11279},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2212.11279},
  urldate = {2023-12-04},
  abstract = {Machine learning is the science of credit assignment: finding patterns in observations that predict the consequences of actions and help to improve future performance. Credit assignment is also required for human understanding of how the world works, not only for individuals navigating daily life, but also for academic professionals like historians who interpret the present in light of past events. Here I focus on the history of modern artificial intelligence (AI) which is dominated by artificial neural networks (NNs) and deep learning, both conceptually closer to the old field of cybernetics than to what's been called AI since 1956 (e.g., expert systems and logic programming). A modern history of AI will emphasize breakthroughs outside of the focus of traditional AI text books, in particular, mathematical foundations of today's NNs such as the chain rule (1676), the first NNs (linear regression, circa 1800), and the first working deep learners (1965-). From the perspective of 2022, I provide a timeline of the -- in hindsight -- most important relevant events in the history of NNs, deep learning, AI, computer science, and mathematics in general, crediting those who laid foundations of the field. The text contains numerous hyperlinks to relevant overview sites from my AI Blog. It supplements my previous deep learning survey (2015) which provides hundreds of additional references. Finally, to round it off, I'll put things in a broader historic context spanning the time since the Big Bang until when the universe will be many times older than it is now.},
  pubstate = {preprint},
  keywords = {Computer Science - Neural and Evolutionary Computing},
  file = {/Users/dape/Zotero/storage/MSSTZW8K/Schmidhuber - 2022 - Annotated History of Modern AI and Deep Learning.pdf;/Users/dape/Zotero/storage/YF78RPKD/2212.html}
}

@article{shinHowPeopleJudge2022,
  title = {How Do People Judge the Credibility of Algorithmic Sources?},
  author = {Shin, Donghee},
  date = {2022-03-01},
  journaltitle = {AI \& SOCIETY},
  shortjournal = {AI \& Soc},
  volume = {37},
  number = {1},
  pages = {81--96},
  issn = {1435-5655},
  doi = {10.1007/s00146-021-01158-4},
  url = {https://doi.org/10.1007/s00146-021-01158-4},
  urldate = {2023-11-24},
  abstract = {The exponential growth of algorithms has made establishing a trusted relationship between human and artificial intelligence increasingly important. Algorithm systems such as chatbots can play an important role in assessing a user’s credibility on algorithms. Unless users believe the chatbot’s information is credible, they are not likely to be willing to act on the recommendation. This study examines how literacy and user trust influence perceptions of chatbot information credibility. Results confirm that algorithmic literacy and users’ trust play a pivotal role in how users form perceptions of the credibility of chatbot messages and recommendations. Insights on how user trust is related to credibility provide a useful perspective on the conceptualization of algorithmic credibility. Algorithmic information processing that has been identified provides better foundations for algorithm design and development and a stronger basis for the design of sense-making chatbot journalism.},
  langid = {english},
  keywords = {Accountability,Algorithmic credibility,Algorithmic literacy,Chatbot journalism,Explainability,Fairness,Information seeking,Transparency,Trust},
  file = {/Users/dape/Zotero/storage/VGHKR6NX/Shin - 2022 - How do people judge the credibility of algorithmic.pdf}
}

@article{shinUncannyValleyNo2019,
  title = {The Uncanny Valley: {{No}} Need for Any Further Judgments When an Avatar Looks Eerie},
  shorttitle = {The Uncanny Valley},
  author = {Shin, Mincheol and Kim, Se Jung and Biocca, Frank},
  date = {2019-05},
  journaltitle = {Computers in Human Behavior},
  shortjournal = {Computers in Human Behavior},
  volume = {94},
  pages = {100--109},
  issn = {07475632},
  doi = {10.1016/j.chb.2019.01.016},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0747563219300251},
  urldate = {2023-11-23},
  abstract = {Considering that a 3D scanning technology allows to create avatars that embody more authentic and rich information about its users, it could be expected that enhancing avatar realism will increase the accuracy of thinslice judgments of the person represented by the avatar. However, previous studies suggest that the objective realism of avatars may not always lead to positive outcomes, and the activation of negative affect and the aversive motivational system through the uncanny valley effects may rather harm the accuracy of thin-slice judgments by making people distance themselves from available information in avatars. To validate this speculation, a 2 (Realism: Cartoonish vs. Hyper-realistic) x 2 (Animacy: Still vs. Animate) between-subjects experiment (N = 134) was conducted. In support of our prediction, results from an online experiment confirmed that hyper-realistic and animate avatars can induce a greater feeling of eeriness as compared to cartoonish and still avatars. This feeling of eeriness, evoked by the uncanny valley effects, suppressed the amount of information processing oriented for thin-slice judgments, and subsequently decreased the accuracy of extraversion and agreeableness judgments. Further theoretical implications of the findings are discussed.},
  langid = {english},
  file = {/Users/dape/Zotero/storage/WNKCHA8U/Shin et al. - 2019 - The uncanny valley No need for any further judgme.pdf}
}

@inproceedings{taigmanDeepFaceClosingGap2014,
  title = {{{DeepFace}}: {{Closing}} the {{Gap}} to {{Human-Level Performance}} in {{Face Verification}}},
  shorttitle = {{{DeepFace}}},
  booktitle = {2014 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Taigman, Yaniv and Yang, Ming and Ranzato, Marc'Aurelio and Wolf, Lior},
  date = {2014-06},
  pages = {1701--1708},
  publisher = {{IEEE}},
  location = {{Columbus, OH, USA}},
  doi = {10.1109/CVPR.2014.220},
  url = {https://ieeexplore.ieee.org/document/6909616},
  urldate = {2023-11-26},
  abstract = {In modern face recognition, the conventional pipeline consists of four stages: detect ⇒ align ⇒ represent ⇒ classify. We revisit both the alignment step and the representation step by employing explicit 3D face modeling in order to apply a piecewise affine transformation, and derive a face representation from a nine-layer deep neural network. This deep network involves more than 120 million parameters using several locally connected layers without weight sharing, rather than the standard convolutional layers. Thus we trained it on the largest facial dataset to-date, an identity labeled dataset of four million facial images belonging to more than 4,000 identities. The learned representations coupling the accurate model-based alignment with the large facial database generalize remarkably well to faces in unconstrained environments, even with a simple classifier. Our method reaches an accuracy of 97.35\% on the Labeled Faces in the Wild (LFW) dataset, reducing the error of the current state of the art by more than 27\%, closely approaching human-level performance.},
  eventtitle = {2014 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  isbn = {978-1-4799-5118-5},
  langid = {english},
  file = {/Users/dape/Zotero/storage/LVBC3A5V/Taigman et al. - 2014 - DeepFace Closing the Gap to Human-Level Performan.pdf}
}

@online{TensorboardPngMbarnig2022,
  title = {Tensorboard.Png · Mbarnig/Lb-de-Fr-En-Pt-Coqui-Vits-Tts at Main},
  date = {2022-07-12},
  url = {https://huggingface.co/mbarnig/lb-de-fr-en-pt-coqui-vits-tts/blob/main/tensorboard.png},
  urldate = {2023-12-22},
  abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
  file = {/Users/dape/Zotero/storage/9HG8ZURH/tensorboard.html}
}

@online{thiesFace2FaceRealtimeFace2020,
  title = {{{Face2Face}}: {{Real-time Face Capture}} and {{Reenactment}} of {{RGB Videos}}},
  shorttitle = {{{Face2Face}}},
  author = {Thies, Justus and Zollhöfer, Michael and Stamminger, Marc and Theobalt, Christian and Nießner, Matthias},
  date = {2020-07-29},
  eprint = {2007.14808},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2007.14808},
  url = {http://arxiv.org/abs/2007.14808},
  urldate = {2023-11-26},
  abstract = {We present Face2Face, a novel approach for real-time facial reenactment of a monocular target video sequence (e.g., Youtube video). The source sequence is also a monocular video stream, captured live with a commodity webcam. Our goal is to animate the facial expressions of the target video by a source actor and re-render the manipulated output video in a photo-realistic fashion. To this end, we first address the under-constrained problem of facial identity recovery from monocular video by non-rigid model-based bundling. At run time, we track facial expressions of both source and target video using a dense photometric consistency measure. Reenactment is then achieved by fast and efficient deformation transfer between source and target. The mouth interior that best matches the re-targeted expression is retrieved from the target sequence and warped to produce an accurate fit. Finally, we convincingly re-render the synthesized target face on top of the corresponding video stream such that it seamlessly blends with the real-world illumination. We demonstrate our method in a live setup, where Youtube videos are reenacted in real time.},
  pubstate = {preprint},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/dape/Zotero/storage/5LHS37QJ/Thies et al. - 2020 - Face2Face Real-time Face Capture and Reenactment .pdf;/Users/dape/Zotero/storage/FGSSD2UX/2007.html}
}

@article{TimelineGenerativeModels,
  title = {Timeline of Generative Models by Type},
  doi = {10.5281/zenodo.8165255},
  url = {https://zenodo.org/records/8165255},
  urldate = {2023-12-04},
  abstract = {Timeline of generative models by type. Part of the study "What do we mean by GenAI?"},
  langid = {english},
  file = {/Users/dape/Zotero/storage/C2J7QGKD/8165255.html}
}

@article{tinwellFacialExpressionEmotion2011,
  title = {Facial Expression of Emotion and Perception of the {{Uncanny Valley}} in Virtual Characters},
  author = {Tinwell, Angela and Grimshaw, Mark and Nabi, Debbie Abdel and Williams, Andrew},
  date = {2011-03},
  journaltitle = {Computers in Human Behavior},
  shortjournal = {Computers in Human Behavior},
  volume = {27},
  number = {2},
  pages = {741--749},
  issn = {07475632},
  doi = {10.1016/j.chb.2010.10.018},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S074756321000316X},
  urldate = {2023-11-23},
  abstract = {With technology allowing for increased realism in video games, realistic, human-like characters risk falling into the Uncanny Valley. The Uncanny Valley phenomenon implies that virtual characters approaching full human-likeness will evoke a negative reaction from the viewer, due to aspects of the character’s appearance and behavior differing from the human norm. This study investigates if ‘‘uncanniness” is increased for a character with a perceived lack of facial expression in the upper parts of the face. More important, our study also investigates if the magnitude of this increased uncanniness varies depending on which emotion is being communicated. Individual parameters for each facial muscle in a 3D model were controlled for the six emotions: anger, disgust, fear, happiness, sadness and surprise in addition to a neutral expression. The results indicate that even fully and expertly animated characters are rated as more uncanny than humans and that, in virtual characters, a lack of facial expression in the upper parts of the face during speech exaggerates the uncanny by inhibiting effective communication of the perceived emotion, significantly so for fear, sadness, disgust, and surprise but not for anger and happiness. Based on our results, we consider the implications for virtual character design.},
  langid = {english},
  file = {/Users/dape/Zotero/storage/H94LHIEK/Tinwell et al. - 2011 - Facial expression of emotion and perception of the.pdf}
}

@article{toffTheyCouldJust2023,
  title = {“{{Or}} They Could Just Not Use It?”: {{The Paradox}} of {{AI Disclosure}} for {{Audience Trust}} in {{News}}},
  shorttitle = {“{{Or}} They Could Just Not Use It?},
  author = {Toff, Benjamin and Simon, Felix M.},
  date = {2023-12-15},
  publisher = {{OSF}},
  doi = {10.31235/osf.io/mdvak},
  url = {https://osf.io/preprints/socarxiv/mdvak},
  urldate = {2023-12-15},
  abstract = {The adoption of artificial intelligence (AI) technologies in the production and distribution of news has generated theoretical, normative, and practical concerns around the erosion of journalistic authority and autonomy and the spread of misinformation. With trust in news already low in many places worldwide, both scholars and practitioners are wary of how the public will respond to news generated through automated methods, prompting calls for labeling of AI-generated content. In this study, we present results from a novel survey-experiment conducted using actual AI-generated journalistic content. We test whether audiences in the US, where trust is particularly polarized along partisan lines, perceive news labeled as AI- generated as more or less trustworthy. We find on average that audiences perceive news labeled as AI-generated as less trustworthy, not more, even when articles themselves are not evaluated as any less accurate or unfair. Furthermore, we find that these effects are largely concentrated among those whose pre-existing levels of trust in news are higher to begin with and among those who exhibit higher levels of knowledge about journalism. We also find that negative effects associated with perceived trustworthiness are largely counteracted when articles disclose the list of sources used to generate the content. As news organizations increasingly look toward adopting AI technologies in their newsrooms, our results hold implications for how disclosure about these techniques may contribute to or further undermine audience confidence in the institution of journalism at a time in which its standing with the public is especially tenuous.},
  langid = {american},
  keywords = {super interesting},
  file = {/Users/dape/Zotero/storage/MLMEWUV3/Toff und Simon - 2023 - “Or they could just not use it” The Paradox of A.pdf;/Users/dape/Zotero/storage/3TUY2UCH/mdvak.html}
}

@article{tolosanaDeepfakesSurveyFace2020,
  title = {Deepfakes and beyond: {{A Survey}} of Face Manipulation and Fake Detection},
  shorttitle = {Deepfakes and Beyond},
  author = {Tolosana, Ruben and Vera-Rodriguez, Ruben and Fierrez, Julian and Morales, Aythami and Ortega-Garcia, Javier},
  date = {2020-12-01},
  journaltitle = {Information Fusion},
  shortjournal = {Information Fusion},
  volume = {64},
  pages = {131--148},
  issn = {1566-2535},
  doi = {10.1016/j.inffus.2020.06.014},
  url = {https://www.sciencedirect.com/science/article/pii/S1566253520303110},
  urldate = {2023-12-12},
  abstract = {The free access to large-scale public databases, together with the fast progress of deep learning techniques, in particular Generative Adversarial Networks, have led to the generation of very realistic fake content with its corresponding implications towards society in this era of fake news. This survey provides a thorough review of techniques for manipulating face images including DeepFake methods, and methods to detect such manipulations. In particular, four types of facial manipulation are reviewed: i) entire face synthesis, ii) identity swap (DeepFakes), iii) attribute manipulation, and iv) expression swap. For each manipulation group, we provide details regarding manipulation techniques, existing public databases, and key benchmarks for technology evaluation of fake detection methods, including a summary of results from those evaluations. Among all the aspects discussed in the survey, we pay special attention to the latest generation of DeepFakes, highlighting its improvements and challenges for fake detection. In addition to the survey information, we also discuss open issues and future trends that should be considered to advance in the field.},
  keywords = {Benchmark,Databases,Deepfakes,Face manipulation,Face recognition,Fake news,Media forensics},
  file = {/Users/dape/Zotero/storage/BTLBST6B/Tolosana et al. - 2020 - Deepfakes and beyond A Survey of face manipulatio.pdf;/Users/dape/Zotero/storage/Z9JCIU4N/Tolosana et al. - 2020 - Deepfakes and beyond A Survey of face manipulatio.pdf;/Users/dape/Zotero/storage/77ZUA78G/S1566253520303110.html}
}

@article{twomeyDeepfakeVideosUndermine2023,
  title = {Do Deepfake Videos Undermine Our Epistemic Trust? {{A}} Thematic Analysis of Tweets That Discuss Deepfakes in the {{Russian}} Invasion of {{Ukraine}}},
  shorttitle = {Do Deepfake Videos Undermine Our Epistemic Trust?},
  author = {Twomey, John and Ching, Didier and Aylett, Matthew Peter and Quayle, Michael and Linehan, Conor and Murphy, Gillian},
  date = {2023-10-25},
  journaltitle = {PLOS ONE},
  shortjournal = {PLOS ONE},
  volume = {18},
  number = {10},
  pages = {e0291668},
  publisher = {{Public Library of Science}},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0291668},
  url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0291668},
  urldate = {2023-11-28},
  abstract = {Deepfakes are a form of multi-modal media generated using deep-learning technology. Many academics have expressed fears that deepfakes present a severe threat to the veracity of news and political communication, and an epistemic crisis for video evidence. These commentaries have often been hypothetical, with few real-world cases of deepfake’s political and epistemological harm. The Russo-Ukrainian war presents the first real-life example of deepfakes being used in warfare, with a number of incidents involving deepfakes of Russian and Ukrainian government officials being used for misinformation and entertainment. This study uses a thematic analysis on tweets relating to deepfakes and the Russo-Ukrainian war to explore how people react to deepfake content online, and to uncover evidence of previously theorised harms of deepfakes on trust. We extracted 4869 relevant tweets using the Twitter API over the first seven months of 2022. We found that much of the misinformation in our dataset came from labelling real media as deepfakes. Novel findings about deepfake scepticism emerged, including a connection between deepfakes and conspiratorial beliefs that world leaders were dead and/or replaced by deepfakes. This research has numerous implications for future research, societal media platforms, news media and governments. The lack of deepfake literacy in our dataset led to significant misunderstandings of what constitutes a deepfake, showing the need to encourage literacy in these new forms of media. However, our evidence demonstrates that efforts to raise awareness around deepfakes may undermine trust in legitimate videos. Consequentially, news media and governmental agencies need to weigh the benefits of educational deepfakes and pre-bunking against the risks of undermining truth. Similarly, news companies and media should be careful in how they label suspected deepfakes in case they cause suspicion for real media.},
  langid = {english},
  keywords = {Governments,Internet,Language,Propaganda,Social media,Twitter,Ukraine,War and civil unrest},
  file = {/Users/dape/Zotero/storage/6TZPKKNX/Twomey et al. - 2023 - Do deepfake videos undermine our epistemic trust .pdf}
}

@online{universityofvirginiaZelenskyySurrenderHoax2022,
  title = {Q\&{{A}}: {{With Zelenskyy Surrender Hoax}}, the {{Feared Future}} of {{Deepfakes Is Here}} | {{UVA Today}}},
  shorttitle = {Q\&{{A}}},
  author = {University of Virginia, News:},
  date = {2022-03-17T14:31:45-04:00},
  url = {https://news.virginia.edu/content/qa-zelenskyy-surrender-hoax-feared-future-deepfakes-here},
  urldate = {2023-11-27},
  langid = {english},
  file = {/Users/dape/Zotero/storage/JQCGTH64/qa-zelenskyy-surrender-hoax-feared-future-deepfakes-here.html}
}

@article{vaccariDeepfakesDisinformationExploring2020,
  title = {Deepfakes and {{Disinformation}}: {{Exploring}} the {{Impact}} of {{Synthetic Political Video}} on {{Deception}}, {{Uncertainty}}, and {{Trust}} in {{News}}},
  shorttitle = {Deepfakes and {{Disinformation}}},
  author = {Vaccari, Cristian and Chadwick, Andrew},
  date = {2020-01-01},
  journaltitle = {Social Media + Society},
  volume = {6},
  number = {1},
  pages = {2056305120903408},
  publisher = {{SAGE Publications Ltd}},
  issn = {2056-3051},
  doi = {10.1177/2056305120903408},
  url = {https://doi.org/10.1177/2056305120903408},
  urldate = {2023-11-24},
  abstract = {Artificial Intelligence (AI) now enables the mass creation of what have become known as “deepfakes”: synthetic videos that closely resemble real videos. Integrating theories about the power of visual communication and the role played by uncertainty in undermining trust in public discourse, we explain the likely contribution of deepfakes to online disinformation. Administering novel experimental treatments to a large representative sample of the United Kingdom population allowed us to compare people’s evaluations of deepfakes. We find that people are more likely to feel uncertain than to be misled by deepfakes, but this resulting uncertainty, in turn, reduces trust in news on social media. We conclude that deepfakes may contribute toward generalized indeterminacy and cynicism, further intensifying recent challenges to online civic culture in democratic societies.},
  langid = {english},
  file = {/Users/dape/Zotero/storage/BRU37J4G/Vaccari und Chadwick - 2020 - Deepfakes and Disinformation Exploring the Impact.pdf}
}

@inproceedings{vanniekerkComparisonDiscreteSoft2022,
  title = {A {{Comparison}} of {{Discrete}} and {{Soft Speech Units}} for {{Improved Voice Conversion}}},
  booktitle = {{{ICASSP}} 2022 - 2022 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}} ({{ICASSP}})},
  author = {family=Niekerk, given=Benjamin, prefix=van, useprefix=true and Carbonneau, Marc-André and Zaïdi, Julian and Baas, Matthew and Seuté, Hugo and Kamper, Herman},
  date = {2022-05},
  pages = {6562--6566},
  issn = {2379-190X},
  doi = {10.1109/ICASSP43922.2022.9746484},
  url = {https://ieeexplore.ieee.org/abstract/document/9746484},
  urldate = {2023-11-24},
  abstract = {The goal of voice conversion is to transform source speech into a target voice, keeping the content unchanged. In this paper, we focus on self-supervised representation learning for voice conversion. Specifically, we compare discrete and soft speech units as input features. We find that discrete representations effectively remove speaker information but discard some linguistic content – leading to mispronunciations. As a solution, we propose soft speech units learned by predicting a distribution over the discrete units. By modeling uncertainty, soft units capture more content information, improving the intelligibility and naturalness of converted speech.12},
  eventtitle = {{{ICASSP}} 2022 - 2022 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}} ({{ICASSP}})},
  file = {/Users/dape/Zotero/storage/XB2DHY65/van Niekerk et al. - 2022 - A Comparison of Discrete and Soft Speech Units for.pdf;/Users/dape/Zotero/storage/WJEY5TGA/9746484.html}
}

@online{vaswaniAttentionAllYou2023,
  title = {Attention {{Is All You Need}}},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
  date = {2023-08-01},
  eprint = {1706.03762},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1706.03762},
  urldate = {2023-12-04},
  abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/dape/Zotero/storage/I8GIDZUF/Vaswani et al. - 2023 - Attention Is All You Need.pdf;/Users/dape/Zotero/storage/SNMDBXZH/1706.html}
}

@article{verdolivaMediaForensicsDeepFakes2020,
  title = {Media {{Forensics}} and {{DeepFakes}}: {{An Overview}}},
  shorttitle = {Media {{Forensics}} and {{DeepFakes}}},
  author = {Verdoliva, Luisa},
  date = {2020-08},
  journaltitle = {IEEE Journal of Selected Topics in Signal Processing},
  volume = {14},
  number = {5},
  pages = {910--932},
  issn = {1941-0484},
  doi = {10.1109/JSTSP.2020.3002101},
  url = {https://ieeexplore.ieee.org/abstract/document/9115874},
  urldate = {2023-11-24},
  abstract = {With the rapid progress in recent years, techniques that generate and manipulate multimedia content can now provide a very advanced level of realism. The boundary between real and synthetic media has become very thin. On the one hand, this opens the door to a series of exciting applications in different fields such as creative arts, advertising, film production, and video games. On the other hand, it poses enormous security threats. Software packages freely available on the web allow any individual, without special skills, to create very realistic fake images and videos. These can be used to manipulate public opinion during elections, commit fraud, discredit or blackmail people. Therefore, there is an urgent need for automated tools capable of detecting false multimedia content and avoiding the spread of dangerous false information. This review paper aims to present an analysis of the methods for visual media integrity verification, that is, the detection of manipulated images and videos. Special emphasis will be placed on the emerging phenomenon of deepfakes, fake media created through deep learning tools, and on modern data-driven forensic methods to fight them. The analysis will help highlight the limits of current forensic tools, the most relevant issues, the upcoming challenges, and suggest future directions for research.},
  eventtitle = {{{IEEE Journal}} of {{Selected Topics}} in {{Signal Processing}}},
  file = {/Users/dape/Zotero/storage/FCH7VN5E/Verdoliva - 2020 - Media Forensics and DeepFakes An Overview.pdf;/Users/dape/Zotero/storage/JSLGADBU/9115874.html}
}

@online{vincentTomCruiseDeepfake2021,
  title = {Tom {{Cruise}} Deepfake Creator Says Public Shouldn’t Be Worried about ‘One-Click Fakes’},
  author = {Vincent, James},
  date = {2021-03-05T15:00:00},
  url = {https://www.theverge.com/2021/3/5/22314980/tom-cruise-deepfake-tiktok-videos-ai-impersonator-chris-ume-miles-fisher},
  urldate = {2023-11-29},
  abstract = {‘You can’t do it by just pressing a button.’},
  langid = {english},
  organization = {{The Verge}},
  file = {/Users/dape/Zotero/storage/RQ97AYV9/tom-cruise-deepfake-tiktok-videos-ai-impersonator-chris-ume-miles-fisher.html}
}

@online{vincentWatchJordanPeele2018,
  title = {Watch {{Jordan Peele}} Use {{AI}} to Make {{Barack Obama}} Deliver a {{PSA}} about Fake News},
  author = {Vincent, James},
  date = {2018-04-17T17:14:44},
  url = {https://www.theverge.com/tldr/2018/4/17/17247334/ai-fake-news-video-barack-obama-jordan-peele-buzzfeed},
  urldate = {2023-11-29},
  abstract = {AI fake news is funny now, but it’ll be scary later},
  langid = {english},
  organization = {{The Verge}},
  file = {/Users/dape/Zotero/storage/83X5JVSB/ai-fake-news-video-barack-obama-jordan-peele-buzzfeed.html}
}

@online{wangNeuralSourcefilterbasedWaveform2019,
  title = {Neural Source-Filter-Based Waveform Model for Statistical Parametric Speech Synthesis},
  author = {Wang, Xin and Takaki, Shinji and Yamagishi, Junichi},
  date = {2019-04-26},
  eprint = {1810.11946},
  eprinttype = {arxiv},
  eprintclass = {cs, eess, stat},
  doi = {10.48550/arXiv.1810.11946},
  url = {http://arxiv.org/abs/1810.11946},
  urldate = {2023-11-24},
  abstract = {Neural waveform models such as the WaveNet are used in many recent text-to-speech systems, but the original WaveNet is quite slow in waveform generation because of its autoregressive (AR) structure. Although faster non-AR models were recently reported, they may be prohibitively complicated due to the use of a distilling training method and the blend of other disparate training criteria. This study proposes a non-AR neural source-filter waveform model that can be directly trained using spectrum-based training criteria and the stochastic gradient descent method. Given the input acoustic features, the proposed model first uses a source module to generate a sine-based excitation signal and then uses a filter module to transform the excitation signal into the output speech waveform. Our experiments demonstrated that the proposed model generated waveforms at least 100 times faster than the AR WaveNet and the quality of its synthetic speech is close to that of speech generated by the AR WaveNet. Ablation test results showed that both the sine-wave excitation signal and the spectrum-based training criteria were essential to the performance of the proposed model.},
  pubstate = {preprint},
  keywords = {Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing,Statistics - Machine Learning},
  file = {/Users/dape/Zotero/storage/QQ42NTJF/Wang et al. - 2019 - Neural source-filter-based waveform model for stat.pdf;/Users/dape/Zotero/storage/84YHRD9B/1810.html}
}

@online{wangRealWorldBlindFace2021,
  title = {Towards {{Real-World Blind Face Restoration}} with {{Generative Facial Prior}}},
  author = {Wang, Xintao and Li, Yu and Zhang, Honglun and Shan, Ying},
  date = {2021-06-10},
  eprint = {2101.04061},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2101.04061},
  url = {http://arxiv.org/abs/2101.04061},
  urldate = {2023-12-08},
  abstract = {Blind face restoration usually relies on facial priors, such as facial geometry prior or reference prior, to restore realistic and faithful details. However, very low-quality inputs cannot offer accurate geometric prior while high-quality references are inaccessible, limiting the applicability in real-world scenarios. In this work, we propose GFP-GAN that leverages rich and diverse priors encapsulated in a pretrained face GAN for blind face restoration. This Generative Facial Prior (GFP) is incorporated into the face restoration process via novel channel-split spatial feature transform layers, which allow our method to achieve a good balance of realness and fidelity. Thanks to the powerful generative facial prior and delicate designs, our GFP-GAN could jointly restore facial details and enhance colors with just a single forward pass, while GAN inversion methods require expensive image-specific optimization at inference. Extensive experiments show that our method achieves superior performance to prior art on both synthetic and real-world datasets.},
  pubstate = {preprint},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/dape/Zotero/storage/7P6C78F9/Wang et al. - 2021 - Towards Real-World Blind Face Restoration with Gen.pdf;/Users/dape/Zotero/storage/TYY2W5ZA/2101.html}
}

@online{wangTacotronEndtoEndSpeech2017,
  title = {Tacotron: {{Towards End-to-End Speech Synthesis}}},
  shorttitle = {Tacotron},
  author = {Wang, Yuxuan and Skerry-Ryan, R. J. and Stanton, Daisy and Wu, Yonghui and Weiss, Ron J. and Jaitly, Navdeep and Yang, Zongheng and Xiao, Ying and Chen, Zhifeng and Bengio, Samy and Le, Quoc and Agiomyrgiannakis, Yannis and Clark, Rob and Saurous, Rif A.},
  date = {2017-04-06},
  eprint = {1703.10135},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1703.10135},
  url = {http://arxiv.org/abs/1703.10135},
  urldate = {2023-12-04},
  abstract = {A text-to-speech synthesis system typically consists of multiple stages, such as a text analysis frontend, an acoustic model and an audio synthesis module. Building these components often requires extensive domain expertise and may contain brittle design choices. In this paper, we present Tacotron, an end-to-end generative text-to-speech model that synthesizes speech directly from characters. Given {$<$}text, audio{$>$} pairs, the model can be trained completely from scratch with random initialization. We present several key techniques to make the sequence-to-sequence framework perform well for this challenging task. Tacotron achieves a 3.82 subjective 5-scale mean opinion score on US English, outperforming a production parametric system in terms of naturalness. In addition, since Tacotron generates speech at the frame level, it's substantially faster than sample-level autoregressive methods.},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning,Computer Science - Sound},
  file = {/Users/dape/Zotero/storage/DTPB3IWK/Wang et al. - 2017 - Tacotron Towards End-to-End Speech Synthesis.pdf;/Users/dape/Zotero/storage/TY6KFLFT/1703.html}
}

@online{weiRMVPERobustModel2023,
  title = {{{RMVPE}}: {{A Robust Model}} for {{Vocal Pitch Estimation}} in {{Polyphonic Music}}},
  shorttitle = {{{RMVPE}}},
  author = {Wei, Haojie and Cao, Xueke and Dan, Tangpeng and Chen, Yueguo},
  date = {2023-06-27},
  eprint = {2306.15412},
  eprinttype = {arxiv},
  eprintclass = {cs, eess},
  doi = {10.48550/arXiv.2306.15412},
  url = {http://arxiv.org/abs/2306.15412},
  urldate = {2023-11-24},
  abstract = {Vocal pitch is an important high-level feature in music audio processing. However, extracting vocal pitch in polyphonic music is more challenging due to the presence of accompaniment. To eliminate the influence of the accompaniment, most previous methods adopt music source separation models to obtain clean vocals from polyphonic music before predicting vocal pitches. As a result, the performance of vocal pitch estimation is affected by the music source separation models. To address this issue and directly extract vocal pitches from polyphonic music, we propose a robust model named RMVPE. This model can extract effective hidden features and accurately predict vocal pitches from polyphonic music. The experimental results demonstrate the superiority of RMVPE in terms of raw pitch accuracy (RPA) and raw chroma accuracy (RCA). Additionally, experiments conducted with different types of noise show that RMVPE is robust across all signal-to-noise ratio (SNR) levels. The code of RMVPE is available at https://github.com/Dream-High/RMVPE.},
  pubstate = {preprint},
  version = {2},
  keywords = {Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing},
  file = {/Users/dape/Zotero/storage/KMGN5LH3/Wei et al. - 2023 - RMVPE A Robust Model for Vocal Pitch Estimation i.pdf;/Users/dape/Zotero/storage/TXCJQM5Z/2306.html}
}

@article{weismanFaceUncannyEffects2021,
  title = {Face the {{Uncanny}}: {{The Effects}} of {{Doppelganger Talking Head Avatars}} on {{Affect-Based Trust Toward Artificial Intelligence Technology}} Are {{Mediated}} by {{Uncanny Valley Perceptions}}},
  shorttitle = {Face the {{Uncanny}}},
  author = {Weisman, William D. and Peña, Jorge F.},
  date = {2021-03},
  journaltitle = {Cyberpsychology, Behavior, and Social Networking},
  volume = {24},
  number = {3},
  pages = {182--187},
  publisher = {{Mary Ann Liebert, Inc., publishers}},
  issn = {2152-2715},
  doi = {10.1089/cyber.2020.0175},
  url = {https://www.liebertpub.com/doi/10.1089/cyber.2020.0175},
  urldate = {2023-12-12},
  abstract = {This experiment (N\,=\,228) examined how exposure to a talking head doppelganger created by an artificial intelligence (AI) program influenced affect-based trust toward AIs. Using a 3 (talking head featuring the participant's or a stranger's face, audio-only condition) by 2 (pro-AI pitch and anti-AI pitch playback) design, we uncovered that exposure to a talking head featuring the participant's face instead of a stranger's face increased uncanny valley perceptions. Furthermore, uncanny valley perceptions mediated the link between exposure to a talking head with the participant's face on affect-based trust. Overall, exposure to a doppelganger talking head, who delivered a persuasive pitch, triggered discomfort on the participant whose features were sourced to craft a synthetic talking head, which in turn decreased affect-based trust attributed to AIs. This phenomenon is rooted in basic psychological mechanisms that underpin the uncanny valley hypothesis. Future studies may test for these findings across different platforms and also provide evidence regarding user mental processing.},
  keywords = {avatar,talking head,transformed self,trust in AIs,uncanny valley},
  file = {/Users/dape/Zotero/storage/YMNJ735D/Weisman und Peña - 2021 - Face the Uncanny The Effects of Doppelganger Talk.pdf}
}

@article{westerlundEmergenceDeepfakeTechnology2019a,
  title = {The {{Emergence}} of {{Deepfake Technology}}: {{A Review}}},
  shorttitle = {The {{Emergence}} of {{Deepfake Technology}}},
  author = {Westerlund, Mika},
  date = {2019},
  journaltitle = {Technology Innovation Management Review},
  volume = {9},
  number = {11},
  pages = {40--53},
  publisher = {{Talent First Network}},
  location = {{Ottawa}},
  issn = {1927-0321},
  doi = {10.22215/timreview/1282},
  file = {/Users/dape/Zotero/storage/6S2VGPYX/Westerlund - 2019 - The Emergence of Deepfake Technology A Review.pdf}
}

@online{WokadaVoicechangerVoice,
  title = {W-Okada/Voice-Changer: {{Voice Changer}}},
  url = {https://github.com/w-okada/voice-changer/tree/master},
  urldate = {2023-12-09},
  file = {/Users/dape/Zotero/storage/2GH62ZIB/w-okadavoice-changer ー Realtime Voice Changer.html}
}

@article{wuCanLikertScales2017a,
  title = {Can {{Likert Scales}} Be {{Treated}} as {{Interval Scales}}?—{{A Simulation Study}}},
  shorttitle = {Can {{Likert Scales}} Be {{Treated}} as {{Interval Scales}}?},
  author = {Wu, Huiping and Leung, Shing-On},
  date = {2017-08-08},
  journaltitle = {Journal of Social Service Research},
  volume = {43},
  number = {4},
  pages = {527--532},
  publisher = {{Routledge}},
  issn = {0148-8376},
  doi = {10.1080/01488376.2017.1329775},
  url = {https://doi.org/10.1080/01488376.2017.1329775},
  urldate = {2024-01-19},
  abstract = {The Likert scale is widely used in social work research, and is commonly constructed with four to seven points. It is usually treated as an interval scale, but strictly speaking it is an ordinal scale, where arithmetic operations cannot be conducted. There are pros and cons in using the Likert scale as an interval scale, but the controversy can be handled by increasing the number of points. Several researchers have suggested bringing the number up to eleven, on the basis of empirical data. In this article the authors explore this rational and share the same view, but simulate artificial data from both symmetrical normal and skewed distributions where the underlying metric is known in advance. Results show that more Likert scale points will result in a closer approach to the underlying distribution, and hence normality and interval scales. To increase generalizability social work practitioners are encouraged to use 11-point Likert scales from 0 to 10, a natural and easily comprehensible range.},
  keywords = {interval scale,Likert scale,normality,ordinal scale},
  file = {/Users/dape/Zotero/storage/J74FKXA3/Wu und Leung - 2017 - Can Likert Scales be Treated as Interval Scales—A.pdf}
}

@article{wuFoundMoreAttractive2021,
  title = {“{{I Found}} a {{More Attractive Deepfaked Self}}”: {{The Self-Enhancement Effect}} in {{Deepfake Video Exposure}}},
  shorttitle = {“{{I Found}} a {{More Attractive Deepfaked Self}}”},
  author = {Wu, Fuzhong and Ma, Yueran and Zhang, Zheng},
  date = {2021-03},
  journaltitle = {Cyberpsychology, Behavior, and Social Networking},
  volume = {24},
  number = {3},
  pages = {173--181},
  publisher = {{Mary Ann Liebert, Inc., publishers}},
  issn = {2152-2715},
  doi = {10.1089/cyber.2020.0173},
  url = {https://www.liebertpub.com/doi/10.1089/cyber.2020.0173},
  urldate = {2023-12-12},
  abstract = {With the introduction of deepfake technology, which enables digital face-swapping between two individuals, young women are no longer passive viewers of attractive celebrities, but are able to become part of the perfect images. This study used the ZAO app as the apparatus to investigate the impact of viewing the self-celebrity deepfaked videos (SCDV) on young female users' appearance self-evaluation (i.e., body image and state appearance self-esteem). A sample of 128 young women 18–31 years of age was randomly assigned to view either 10 SCDV or 10 purely celebrity videos (PCV). All videos were sourced from the ZAO app. Results showed that participants in the SCDV condition perceived themselves as more physically attractive, experienced greater satisfaction with their own facial features, and reported marginally higher state appearance self-esteem than those in the PCV condition, whereas body shape satisfaction did not differ between the conditions. In addition, SCDV exposure increased perceived overall physical attractiveness and facial features satisfaction, but did not impact body shape satisfaction, whereas PCV exposure decreased facial features satisfaction, but did not impact perceived overall physical attractiveness or body shape satisfaction. “Attractive possible self” (APS) perception positively mediated the effect of SCDV exposure on perceived overall physical attractiveness, facial features satisfaction, body shape satisfaction, and state appearance self-esteem, while state appearance comparison only negatively mediated the effect of SCDV exposure on facial features satisfaction. This study reveals the potential of deepfake technology as an intervention technique for body image disturbances.},
  keywords = {appearance self-esteem,body image,deepfake,possible self,self-enhancement,social comparison},
  file = {/Users/dape/Zotero/storage/CJRWHNII/Wu et al. - 2021 - “I Found a More Attractive Deepfaked Self” The Se.pdf}
}

@online{zdf-politbarometerVertrauenGlaubwuerdigkeitBerichterstattung2023,
  title = {Vertrauen in die Glaubwürdigkeit der Berichterstattung ARD/ZDF},
  author = {ZDF-Politbarometer},
  date = {2023-10-25},
  url = {https://www.zdf.de/uri/f002e182-91f6-4a03-9c4c-9c76dad1e117},
  urldate = {2023-11-24},
  abstract = {Aus den Umfragen der Forschungsgruppe Wahlen für das ZDF-Politbarometer},
  langid = {ngerman},
  file = {/Users/dape/Zotero/storage/LAC8KLYR/medienforschung-studien-122.html}
}

@online{zdfDeepfakeMitZDFModerator,
  title = {Deepfake mit ZDF-Moderator: Wie man KI-Videos erkennt},
  shorttitle = {Deepfake mit ZDF-Moderator},
  author = {ZDF},
  url = {https://www.zdf.de/nachrichten/politik/politik-sievers-ki-fake-102.html},
  urldate = {2023-11-27},
  abstract = {Immer mehr Videos sind KI-Generiert. Sie sind mittlerweile einfach zu fälschen. Wie und woran man sie erkennen kann.},
  langid = {ngerman},
  organization = {{ZDFheute}},
  file = {/Users/dape/Zotero/storage/P9FLMVQ3/politik-sievers-ki-fake-102.html}
}

@online{zdfKunstinstallationDeepfakeScholzVerkuendet,
  title = {Kunstinstallation: Deepfake-Scholz verkündet AfD-Verbot},
  shorttitle = {Kunstinstallation},
  author = {ZDF},
  url = {https://www.zdf.de/nachrichten/politik/aktion-gefaengnis-afd-verbot-100.html},
  urldate = {2023-11-27},
  abstract = {Mit einer Aktion fordert das "Zentrum für Politische Schönheit" ein Verbot der AfD - inklusive Gefängnis und Deepfake-Video von Kanzler Scholz.},
  langid = {ngerman},
  organization = {{ZDFheute}},
  file = {/Users/dape/Zotero/storage/2Q5668XU/aktion-gefaengnis-afd-verbot-100.html}
}

@online{zdfPropagandaImKrieg,
  title = {Propaganda im Krieg: Fake-Video von Selenskyj im Umlauf},
  shorttitle = {Propaganda im Krieg},
  author = {ZDF},
  url = {https://www.zdf.de/nachrichten/video/panorama-fake-video-selenskyj-100.html},
  urldate = {2023-11-27},
  abstract = {Unbekannte verbreiten im Netz ein Deepfake-Video, in dem der ukrainische Präsident Selenskyj vermeintlich zur Kapitulation aufruft.},
  langid = {ngerman},
  organization = {{ZDFheute}},
  file = {/Users/dape/Zotero/storage/UUBDLMDE/panorama-fake-video-selenskyj-100.html}
}

@article{zeeuwTracingNormieficationCrossplatform2020,
  title = {Tracing Normiefication: {{A}} Cross-Platform Analysis of the {{QAnon}} Conspiracy Theory},
  shorttitle = {Tracing Normiefication},
  author = {family=Zeeuw, given=Daniel, prefix=de, useprefix=false and Hagen, Sal and Peeters, Stijn and Jokubauskaite, Emilija},
  date = {2020-10-26},
  journaltitle = {First Monday},
  issn = {1396-0466},
  doi = {10.5210/fm.v25i11.10643},
  url = {https://firstmonday.org/ojs/index.php/fm/article/view/10643},
  urldate = {2023-11-29},
  abstract = {This article presents a cross-platform analysis of the QAnon conspiracy theory that was popularized online from 2017 onward. It theorizes its diffusion as one of normiefication: a term drawing from Web vernacular indicating how ideas and objects travel from fringe online subcultures to large audiences on mainstream platforms and news outlets. It finds that QAnon had a clear incubation period on 4chan/pol/ after which it quickly migrated to larger platforms, notably YouTube and Reddit. News media started covering the online phenomenon only when it moved off-line, which in turn briefly amplified engagement on the other platforms. Through these data-driven insights, we aim to demonstrate how this cross-platform approach can be replicated and thus help make sense of the complexity of contemporary media ecologies and their role in the diffusion of conspiracy theories as well as other forms of mis- and disinformation.},
  langid = {english},
  keywords = {conspiracy theories,cross-platform analysis,diffusion,online subcultures,QAnon},
  file = {/Users/dape/Zotero/storage/5EQLB3BL/Zeeuw et al. - 2020 - Tracing normiefication A cross-platform analysis .pdf}
}

@online{ziyinNeuralNetworksFail2020,
  title = {Neural {{Networks Fail}} to {{Learn Periodic Functions}} and {{How}} to {{Fix It}}},
  author = {Ziyin, Liu and Hartwig, Tilman and Ueda, Masahito},
  date = {2020-10-24},
  eprint = {2006.08195},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.2006.08195},
  url = {http://arxiv.org/abs/2006.08195},
  urldate = {2023-11-24},
  abstract = {Previous literature offers limited clues on how to learn a periodic function using modern neural networks. We start with a study of the extrapolation properties of neural networks; we prove and demonstrate experimentally that the standard activations functions, such as ReLU, tanh, sigmoid, along with their variants, all fail to learn to extrapolate simple periodic functions. We hypothesize that this is due to their lack of a "periodic" inductive bias. As a fix of this problem, we propose a new activation, namely, \$x + \textbackslash sin\^2(x)\$, which achieves the desired periodic inductive bias to learn a periodic function while maintaining a favorable optimization property of the ReLU-based activations. Experimentally, we apply the proposed method to temperature and financial data prediction.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/dape/Zotero/storage/IBPQ9RV2/Ziyin et al. - 2020 - Neural Networks Fail to Learn Periodic Functions a.pdf;/Users/dape/Zotero/storage/99A5MZZI/2006.html}
}
